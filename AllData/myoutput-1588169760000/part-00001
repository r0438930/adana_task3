{"title_page": "High-dynamic-range imaging", "text_new": "{{Redirect|HDRI|the form of iron|Direct reduced iron}}\n{{distinguish|Range imaging}}\n[[File:St Kentigerns Church HDR (8226826999).jpg|thumb|upright=1.2|right|Tone mapped high-dynamic-range (HDR) image of St. Kentigern's Church in [[Blackpool]], Lancashire, England]]\n\n{{Plain English|date=February 2020}}\n\n'''High-dynamic-range imaging''' ('''HDRI''') is a [[high dynamic range]] (HDR) technique used in imaging and films to reproduce a greater [[dynamic range#Photography|dynamic range]] of [[luminosity function|luminosity]] than what is possible with standard [[digital imaging]] or photographic techniques. Standard techniques allow differentiation only within a certain range of brightness. Outside of this range, no features are visible because there is no differentiation in bright areas as everything appears just pure white, and there is no differentiation in darker areas as everything appears pure black.  \n\nHDR images can record and represent a greater range of luminance levels than can be achieved using more traditional methods, such as many real-world scenes containing very bright, direct sunlight to extreme shade, or very faint [[Nebula|nebulae]]. This is often achieved by capturing and then combining several different, narrower range, [[Exposure (photography)|exposures]] of the same subject matter.<ref name=\"mann1993\" /><ref name=\"mann1995\" /><ref>{{cite book |author1=Reinhard, Erik |author2=Ward, Greg |author3=Pattanaik, Sumanta |author4=Debevec, Paul |title=High dynamic range imaging: acquisition, display, and image-based lighting |year=2005 |quote=Images that store a depiction of the scene in a range of intensities commensurate with the scene are what we call HDR, or \"radiance maps\". On the other hand, we call images suitable for display with current display technology LDR. |publisher=Elsevier/Morgan Kaufmann |location=Amsterdam |page=7 |isbn=978-0-12-585263-0}}</ref><ref>{{cite book |author1=Banterle, Francesco |author2=Artusi, Alessandro |author3=Debattista, Kurt |author4=Chalmers, Alanl |title=Advanced High dynamic Range Imaging: theory and practiceg |year=2011 |publisher=AK Peters/CRC Press|isbn=978-156881-719-4}}</ref> Non-HDR cameras take [[Photograph|photographs]] with a limited exposure range, referred to as low dynamic range (LDR), resulting in the loss of detail in highlights or [[shadow#Photography|shadows]].\n\nThe two primary types of HDR images are [[high-dynamic-range rendering|computer renderings]] and images resulting from merging multiple low-dynamic-range (LDR)<ref>{{cite journal |title=Real-Time High Dynammic Range Texture Mapping |author=Cohen, Jonathan and Tchou, Chris and Hawkins, Tim and Debevec, Paul E. |journal=Proceedings of the 12th Eurographics Workshop on Rendering Techniques |editor1=Steven Jacob Gortler |editor2=Karol Myszkowski |publisher=Springer |year=2001 |isbn=3-211-83709-4 |pages=313\u2013320}}</ref> or standard-dynamic-range (SDR)<ref>{{cite book |title=Advances in image and video technology: Second Pacific Rim Symposium (PSIVT)'' 2007, Santiago, Chile, December 17\u201319, 2007'' |chapter=Fast automatic compensation of under/over-exposured image regions |author1=Vassilios Vonikakis |author2=Ioannis Andreadis |editor1=Domingo Mery |editor2=Luis Rueda |publisher= |year=2008 |isbn=978-3-540-77128-9 |page=510 |url=https://books.google.com/books?id=vkNfw8SsU3oC&pg=PA510&dq=hdr+sdr+%22standard+dynamic+range%22&q=hdr%20sdr%20%22standard%20dynamic%20range%22}}</ref> photographs. HDR images can also be acquired using special [[Image sensor|image sensors]], such as an [[oversampled binary image sensor]].\n\nDue to the limitations of printing and [[display contrast]], the extended luminosity range of input HDR images has to be compressed to be made visible. The method of rendering an HDR image to a standard monitor or printing device is called [[tone mapping]]. This method reduces the overall contrast of an HDR image to facilitate display on devices or printouts with lower dynamic range, and can be applied to produce images with preserved local contrast (or exaggerated for artistic effect).\n\n\"HDR\" may refer to the overall process, to the HDR imaging process, or to HDR imaging represented on a low dynamic range display such as a screen or standard .jpg image.\n\n\n== Emulating the human vision system==\nOne aim of HDR is to present a similar range of [[luminance]] to that experienced through the human [[visual system]]. The human eye, through non-linear response, [[adaptation (eye)|adaptation]] of the [[Iris (anatomy)|iris]] and other methods, adjusts constantly to adapt to a broad range of luminance present in the environment. The brain continuously interprets this information so that a viewer can see in a wide range of light conditions.\n\nStandard photographic and image techniques allow differentiation only within a certain range of brightness. Outside of this range, no features are visible because there is no differentiation in bright areas as everything appears just pure white, and there is no differentiation in darker areas as everything appears pure black.  Non-HDR cameras take photographs with a limited exposure range, referred to as low dynamic range (LDR), resulting in the loss of detail in highlights or [[shadow#Photography|shadows]].\n\n== Photography ==\n\n{|class=\"wikitable unsortable floatright\"\n|+ '''Dynamic ranges of common devices'''\n|-\n! Device\n! Stops\n! Contrast Ratio\n|- style=\"background-color:#DDF;\"\n| colspan=\"4\" | '''Single exposure'''\n|-\n| Human eye: close objects\n| {{0}}7.5\n| {{0|00}}150...200\n|-\n| Human eye: 4\u00b0 angular separation\n| 13\n| {{0}}8000...10000\n|-\n| Human eye (static)\n| 10...14&nbsp;<ref>{{cite web |url=http://www.cambridgeincolour.com/tutorials/dynamic-range.htm|title=Dynamic Range in Digital Photography|accessdate=2010-12-30}}</ref>\n| {{0}}1000...15000\n|-\n| Negative film ([[List of motion picture film stocks#VISION3 color negative (ECN-2 process 2007\u2013present)|Kodak VISION3]])\n| 13&nbsp;<ref name=\"Kodak v3\">{{cite web|url=http://motion.kodak.com/motion/About/The_Storyboard/17788/index.htm|title=Dynamic Range}}{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes }}</ref>\n| {{0}}8000\n|-\n| best 1/1.7\" camera ([[Nikon Coolpix P340]])\n| 11.9{{cn|date=May 2018}}\n| {{0}}3800\n|-\n| best 1\" camera ([[Canon PowerShot G7 X]])\n| 12.7{{cn|date=May 2018}}\n| {{0}}6600\n|-\n| best Four-Thirds DSLR camera ([[Panasonic Lumix DC-GH5]])\n| 13.0{{cn|date=May 2018}}\n| {{0}}8200\n|-\n| best APS DSLR camera ([[Nikon D7200]])\n| 14.6&nbsp;<ref name=DXOMark>{{cite web | url=http://www.dxomark.com/Cameras/Camera-Sensor-Ratings/%28type%29/usecase_landscape | title=Camera Sensor Ratings by DxOMark | publisher=[[DxO Labs]] | accessdate=February 2, 2015}}</ref>\n| 24800\n|-\n| best Full Frame DSLR camera ([[Nikon D810]])\n| 14.8&nbsp;<ref name=DXOMark>{{cite web | url=http://www.dxomark.com/Cameras/Camera-Sensor-Ratings/%28type%29/usecase_landscape | title=Camera Sensor Ratings by DxOMark | publisher=[[DxO Labs]] | accessdate=February 2, 2015}}</ref>\n| 28500 <!-- Calculated from formula: Contrast Ratio = 2^(Dynamic Range) -->\n|- style=\"background-color:#DDF;\"\n|}\n\nIn photography, dynamic range is measured in exposure value ([[exposure value|EV]]) differences (known as ''stops''). An increase of one EV, or 'one stop', represents a doubling of the amount of light. Conversely, a decrease of one EV represents a halving of the amount of light. Therefore, revealing detail in the darkest of shadows requires high exposures, while preserving detail in very bright situations requires very low exposures. Most cameras cannot provide this range of exposure values within a single exposure, due to their low dynamic range.\nHigh-dynamic-range photographs are generally achieved by capturing multiple standard-exposure images, often using [[Bracketing#Exposure bracketing|exposure bracketing]], and then later [[Exposure fusion|merging them]] into a single HDR image, usually within a [[photo manipulation]] program.\n\nAny camera that allows manual exposure control can make images for HDR work, although one equipped with [[Autobracketing|auto exposure bracketing (AEB)]] is far better suited. Images from film cameras are less suitable as they often must first be digitized, so that they can later be processed using software HDR methods.\n\nIn most imaging devices, the degree of exposure to light applied to the active element (be it film or [[Charge-coupled device|CCD]]) can be altered in one of two ways: by either increasing/decreasing the size of the [[aperture]] or by increasing/decreasing the time of each [[exposure (photography)|exposure]]. Exposure variation in an HDR set is only done by altering the '''exposure time''' and ''not'' the aperture size; this is because altering the aperture size also affects the [[depth of field]] and so the resultant multiple images would be quite different, preventing their final combination into a single HDR image.\n\nAn important limitation for HDR photography is that any movement between successive images will impede or prevent success in combining them afterward. Also, as one must create several images (often three or five and sometimes more) to obtain the desired [[luminance]] range, such a full 'set' of images takes extra time. HDR photographers have developed calculation methods and techniques to partially overcome these problems, but the use of a sturdy tripod is, at least, advised.\n\nSome cameras have an [[Autobracketing|auto exposure bracketing (AEB)]] feature with a far greater dynamic range than others, from the 3 EV of the [[Canon EOS 40D]], to the 18 EV of the [[Canon EOS-1D Mark II]].<ref>{{cite web |title=Auto Exposure Bracketing by camera model |url=http://hdr-photography.com/aeb.html |accessdate=18 August 2009}}</ref> As the popularity of this imaging method grows, several camera manufacturers are now offering built-in HDR features. For example, the [[Pentax K-7]] DSLR has an HDR mode that captures an HDR image and outputs (only) a tone mapped JPEG file.<ref>{{cite web |title=The Pentax K-7: The era of in-camera High Dynamic Range Imaging has arrived! |url=http://www.adorama.com/alc/0011608/blogarticle/The-Pentax-K-7-The-era-of-in-camera-High-Dynamic-Range-Imaging-has-arrived |accessdate=18 August 2009 |archive-url=https://web.archive.org/web/20120424063346/http://www.adorama.com/alc/0011608/blogarticle/The-Pentax-K-7-The-era-of-in-camera-High-Dynamic-Range-Imaging-has-arrived |archive-date=24 April 2012 |url-status=dead }}</ref> The [[Canon PowerShot G12]], [[Canon PowerShot S95]] and [[Canon PowerShot S100]] offer similar features in a smaller format.<ref>{{cite web |title=Canon PowerShot G12 picks up HD video recording, built-in HDR |url=http://www.digitaltrends.com/photography/cameras/canon-powershot-g12-picks-up-hd-video-recording-built-in-hdr/?news=123}}</ref> Nikon's approach is called 'Active D-Lighting' which applies exposure compensation and tone mapping to the image as it comes from the sensor, with the emphasis being on creating a realistic effect.<ref>{{cite web |title=Balancing Photo Exposures with Active D-lighting |url=http://www.nikonusa.com/en/learn-and-explore/a/ideas-and-inspiration/balancing-photo-exposures-with-nikons-active-d-lighting.html |accessdate=2 August 2017}}</ref> Some [[smartphone]]s provide HDR modes, and most [[mobile platform]]s have apps that provide HDR picture taking.<ref>[https://play.google.com/store/search?q=hdr%20mode&c=apps HDR apps for Android] Google Play</ref>\n\nCamera characteristics such as [[Gamma correction|gamma curves]], sensor resolution, noise, [[photometry (optics)|photometric]] calibration and [[color calibration]] affect resulting high-dynamic-range images.<ref name=\"SCV2007\">{{cite book |title=High Dynamic Range |edition=First |author1=Asla M. S\u00e1 |author2=Paulo Cezar Carvalho |author3=Luiz Velho |publisher=Focal Press |year=2007 |isbn=978-1-59829-562-7 |page=11 |url=https://books.google.com/books?id=mDsFgWPhWWYC&printsec=frontcover&dq=ISBN:+9781598295627#v=onepage&q=ISBN%3A%209781598295627&f=}}</ref>\n\nColor film negatives and slides consist of multiple film layers that respond to light differently. Original film (especially negatives versus transparencies or 'slides') feature a very high dynamic range (in the order of 8 for negatives and 4 to 4.5 for slides).\n=== Tone mapping ===\n{{Main article|Tone mapping}}\n\nTone mapping reduces the dynamic range, or contrast ratio, of an entire image while retaining localized contrast. Although it is a distinct operation, tone mapping is often applied to HDRI files by the same software package.\n\nSeveral software applications are available on the PC, Mac and Linux platforms for producing HDR files and tone mapped images. Notable titles include\n{{Div col}}\n* [[Adobe Photoshop]]\n* [[Aurora HDR]]\n* [[Dynamic Photo HDR]]\n* [[EasyHDR]]\n* [[GIMP]]\n* [[Nik Collection|HDR Efex Pro]]\n* [[HDR PhotoStudio]]\n* [[Luminance HDR]]\n* [[MagicRaw]]\n* [[Oloneo PhotoEngine]]\n* [[PTGui]]\n* [[Affinity Photo]]\n* [[SNS-HDR]]\n*[[HDRSoft - Photomatix]]{{Div col end}}\n\n=== Comparison with traditional digital images ===\nInformation stored in high-dynamic-range images typically corresponds to the physical values of [[luminance]] or [[radiance]] that can be observed in the real world. This is different from traditional [[digital images]], which represent colors as they should appear on a monitor or a paper print. Therefore, HDR image formats are often called ''scene-referred'', in contrast to traditional digital images, which are ''device-referred'' or ''output-referred''. Furthermore, traditional images are usually encoded for the human [[visual system]] (maximizing the visual information stored in the fixed number of bits), which is usually called ''gamma encoding'' or ''[[gamma correction]]''. The values stored for HDR images are often [[gamma correction|gamma compressed]] ([[power law]]) or [[logarithm]]ically encoded, or [[floating point|floating-point]] linear values, since [[fixed-point arithmetic|fixed-point]] linear encodings are increasingly inefficient over higher dynamic ranges.<ref name=gregward/><ref>{{cite web |url=http://radsite.lbl.gov/radiance/refer/Notes/picture_format.html |accessdate=2009-08-21 |title=The Radiance Picture File Format}}</ref><ref>{{cite book |last=Fernando |first=Randima |title=GPU Gems |publisher=Addison-Wesley |location=Boston |year=2004 |chapter=26.5 Linear Pixel Values |url=http://http.developer.nvidia.com/GPUGems/gpugems_ch26.html |isbn=0-321-22832-4 |url-status=dead |archiveurl=https://web.archive.org/web/20100412001848/http://http.developer.nvidia.com/GPUGems/gpugems_ch26.html |archivedate=2010-04-12 }}</ref>\n\nHDR images often don't use fixed ranges per color [[channel (digital image)|channel]]\u2014other than traditional images\u2014to represent many more colors over a much wider dynamic range. For that purpose, they do not use integer values to represent the single color channels (e.g., 0-255 in an 8 bit per pixel interval for red, green and blue) but instead use a floating point representation. Common are 16-bit (''[[half precision]]'') or 32-bit [[floating point]] numbers to represent HDR pixels. However, when the appropriate [[transfer function]] is used, HDR pixels for some applications can be represented with a [[color depth]] that has as few as 10\u201312&nbsp;bits for luminance and 8&nbsp;bits for [[chrominance]] without introducing any visible quantization artifacts.<ref name=gregward>{{cite web |url=http://www.anyhere.com/gward/hdrenc/hdr_encodings.html |title=High Dynamic Range Image Encodings |author1=Greg Ward |author2=Anyhere Software }}</ref><ref>{{cite web |url=http://www.mpi-sb.mpg.de/resources/hdrvideo/ |title=Perception-motivated High Dynamic Range Video Encoding |author=[[Max Planck Institute for Computer Science]]}}</ref>\n\n== History of HDR photography ==\n\n=== Mid 19th century ===\n[[File:Gustave Le Gray - Brig upon the Water - Google Art Project.jpg|thumb|right|upright=1.2|An 1856 photo by [[Gustave Le Gray]]]]\nThe idea of using several exposures to adequately reproduce a too-extreme range of [[luminance]] was pioneered as early as the 1850s by [[Gustave Le Gray]] to render seascapes showing both the sky and the sea. Such rendering was impossible at the time using standard methods, as the luminosity range was too extreme. Le Gray used one negative for the sky, and another one with a longer exposure for the sea, and combined the two into one picture in positive.<ref name=GettyExh>[[J. Paul Getty Museum]]. [http://www.getty.edu/art/exhibitions/le_gray Gustave Le Gray, Photographer. July 9&nbsp;\u2013 September 29, 2002.] Retrieved September 14, 2008.</ref>\n\n=== Mid 20th century ===\n{{external media |image1=[https://web.archive.org/web/20170315033441/http://www.cybergrain.com/tech/hdr/images1/eugene_smith.jpg Schweitzer at the Lamp], by [[W. Eugene Smith]]<ref>[http://www.cybergrain.com/tech/hdr/ The Future of Digital Imaging \u2013 High Dynamic Range Photography], Jon Meyer, Feb 2004</ref><ref name=\"durand\">[http://people.csail.mit.edu/fredo/ArtAndScienceOfDepiction/ 4.209: The Art and Science of Depiction], Fr\u00e9do Durand and [[Julie Dorsey]], [http://people.csail.mit.edu/fredo/ArtAndScienceOfDepiction/12_Contrast/contrast.html Limitations of the Medium: Compensation and accentuation&nbsp;\u2013 The Contrast is Limited], lecture of Monday, April 9. 2001, [http://people.csail.mit.edu/fredo/ArtAndScienceOfDepiction/12_Contrast/contrast6.pdf slide 57\u201359]; image on slide 57, depiction of dodging and burning on slide 58</ref>\n}}\n\nManual tone mapping was accomplished by [[dodging and burning]]&nbsp;\u2013 selectively increasing or decreasing the exposure of regions of the photograph to yield better tonality reproduction. This was effective because the dynamic range of the negative is significantly higher than would be available on the finished positive paper print when that is exposed via the negative in a uniform manner. An excellent example is the photograph ''Schweitzer at the Lamp'' by [[W. Eugene Smith]], from his 1954 [[photo essay]] ''A Man of Mercy'' on Dr. [[Albert Schweitzer]] and his humanitarian work in French Equatorial Africa. The image took 5 days to reproduce the tonal range of the scene, which ranges from a bright lamp (relative to the scene) to a dark shadow.<ref name=\"durand\"/>\n\n[[Ansel Adams]] elevated dodging and burning to an art form. Many of his famous prints were manipulated in the darkroom with these two methods. Adams wrote a comprehensive book on producing prints called ''The Print,'' which prominently features dodging and burning, in the context of his [[Zone System]].\n\nWith the advent of color photography, tone mapping in the darkroom was no longer possible due to the specific timing needed during the developing process of color film. Photographers looked to film manufacturers to design new film stocks with improved response, or continued to shoot in black and white to use tone mapping methods.{{citation needed|date=November 2013}}\n\n[[File:Wyckoff HDR Curve.tif|thumb|left|upright=2.4|Exposure/Density Characteristics of Wyckoff's Extended Exposure Response Film]]\nColor film capable of directly recording high-dynamic-range images was developed by [[Charles Wyckoff]] and [[EG&G]] \"in the course of a contract with the Department of the Air Force\".<ref>{{cite patent | inventor-last = Wyckoff | inventor-first = Charles W.\n | inventorlink = Charles Wyckoff | inventor2-last = EG&G Inc., assignee | inventor2-first = | inventorlink2 = EG&G | publication-date = March 24, 1961 | issue-date = June 17, 1969 | title = Silver Halide Photographic Film having Increased Exposure-response Characteristics | country-code = US | description = | patent-number = 3450536 | url = http://www.google.com/patents?hl=en&lr=&vid=USPAT3450536&id=43RzAAAAEBAJ&oi=fnd&dq=%22Extended+exposure%22+Wyckoff&printsec=abstract#v=onepage&q=%22Extended%20exposure%22%20Wyckoff&f=false | accessdate = June 1, 2012}}</ref> This XR film had three [[Photographic emulsion|emulsion]] layers, an upper layer having an [[Film speed#ASA|ASA]] speed rating of 400, a middle layer with an intermediate rating, and a lower layer with an ASA rating of 0.004. The film was processed in a manner similar to [[Color photography#\"Modern\" color film|color films]], and each layer produced a different color.<ref>C. W. Wyckoff. Experimental extended exposure response film. ''Society of Photographic Instrumentation Engineers Newsletter'', June\u2013July, 1962, pp. 16-20.</ref> The dynamic range of this extended range film has been estimated as 1:10<sup>8</sup>.<ref>Michael Goesele, et al., \"High Dynamic Range Techniques in Graphics: from Acquisition to Display\", [http://www.mpi-inf.mpg.de/resources/tmo/EG05_HDRTutorial_Complete.pdf Eurographics 2005 Tutorial T7]</ref> It has been used to photograph nuclear explosions,<ref>[http://www.fas.org/irp/threat/mctl98-2/p2sec05.pdf ''The Militarily Critical Technologies List''] (1998), pages II-5-100 and II-5-107.</ref> for astronomical photography,<ref>Andrew T. Young and Harold Boeschenstein, Jr., ''Isotherms in the region of Proclus at a phase angle of 9.8 degrees'', Scientific Report No. 5, Harvard, College Observatory: Cambridge, Massachusetts, 1964.</ref> for spectrographic research,<ref>{{cite journal |first=R. L. |last=Bryant |first2=G. J. |last2=Troup |first3=R. G. |last3=Turner |title=The use of a high-intensity-range photographic film for recording extended diffraction patterns and for spectrographic work |journal=Journal of Scientific Instruments |volume=42 |issue=2 |year=1965 |pages=116 |doi=10.1088/0950-7671/42/2/315 }}</ref> and for medical imaging.<ref>{{cite journal |first=Leslie M. |last=Eber |first2=Haervey M. |last2=Greenberg |first3=John M. |last3=Cooke |first4=Richard |last4=Gorlin |title=Dynamic Changes in Left Ventricular Free Wall Thickness in the Human Heart |journal=Circulation |volume=39 |year=1969 |issue=4 |pages=455\u2013464 |doi=10.1161/01.CIR.39.4.455 |doi-access=free }}</ref> Wyckoff's detailed pictures of nuclear explosions appeared on the cover of ''[[Life magazine|Life]]'' magazine in the mid-1950s.\n\n=== Late 20th century ===\nGeorges Cornu\u00e9jols and licensees of his patents (Brdi, Hymatom) introduced the principle of HDR video image, in 1986, by interposing a matricial LCD screen in front of the camera's image sensor,<ref>{{Cite web|url=https://worldwide.espacenet.com/publicationDetails/biblio?II=0&ND=3&adjacent=true&locale=en_EP&FT=D&date=19910924&CC=US&NR=5051770A&KC=A#|title=Image processing device for controlling the transfer function of an optical system|last=|first=|date=|website=espacenet.com|publisher=|access-date=}}</ref> increasing the sensors dynamic by five stops. The concept of neighborhood tone mapping was applied to video cameras by a group from the [[Technion]] in Israel led by Dr. Oliver Hilsenrath and Prof. Y.Y.Zeevi who filed for a patent on this concept in 1988.<ref name=\"WDR Patent\">{{Ref patent |country=US |status=granted |number=5144442 |title=Wide dynamic range camera |pubdate=1992-09-01 |fdate=1991-11-21 |inventor=Ginosar, R., Hilsenrath, O., Zeevi, Y.}}</ref>\n\nIn February and April 1990, Georges Cornu\u00e9jols introduced the first real-time HDR camera that combined two images captured by a sensor<ref name=espacenet1>{{Cite web|url=https://worldwide.espacenet.com/publicationDetails/biblio?II=0&ND=3&adjacent=true&locale=en_EP&FT=D&date=19970610&CC=US&NR=5638119A&KC=A#|title=Device for increasing the dynamic range of a camera|last=|first=|date=|website=|publisher=|access-date=}}</ref>or simultaneously<ref>{{Cite web|url=https://worldwide.espacenet.com/publicationDetails/biblio?II=0&ND=3&adjacent=true&locale=en_EP&FT=D&date=19970610&CC=US&NR=5638119A&KC=A#|title=Camera with very wide dynamic range|last=|first=|date=|website=espacenet.com|publisher=|access-date=}}</ref> by two sensors of the camera. This process is known as [[bracketing]] used for a video stream.\n\nIn 1991, the first commercial video camera was introduced that performed real-time capturing of multiple images with different exposures, and producing an HDR video image, by Hymatom, licensee of Georges Cornu\u00e9jols.\n\nAlso in 1991, Georges Cornu\u00e9jols introduced the HDR+ image principle by non-linear accumulation of images to increase the sensitivity of the camera:<ref name=espacenet1/> for low-light environments, several successive images are accumulated, thus increasing the signal to noise ratio.\n\nIn 1993, another commercial medical camera  producing an HDR video image, by the Technion.<ref name=\"AdaptiveSens\">{{cite journal |author=Technion&nbsp;\u2013 Israel Institute of Technology |title=Adaptive Sensitivity |url=http://visl.technion.ac.il/research/isight/AS/ |year=1993 |access-date=2019-01-27 |archive-url=https://web.archive.org/web/20140907142738/http://visl.technion.ac.il/research/isight/AS/ |archive-date=2014-09-07 |url-status=dead }}</ref>\n\nModern HDR imaging uses a completely different approach, based on making a high-dynamic-range luminance or light map using only global image operations (across the entire image), and then [[tone mapping]] the result. Global HDR was first introduced in 1993<ref name=\"mann1993\">\"Compositing Multiple Pictures of the Same Scene\", by Steve Mann, in IS&T's 46th Annual Conference, Cambridge, Massachusetts, May 9\u201314, 1993</ref> resulting in a mathematical theory of differently exposed pictures of the same subject matter that was published in 1995 by [[Steve Mann (inventor)|Steve Mann]] and Rosalind Picard.<ref name=\"mann1995\">{{cite web |url=http://wearcam.org/is_t95_myversion.pdf |title=On Being \u2018Undigital\u2019 With Digital Cameras: Extending Dynamic Range By Combining Differently Exposed Pictures |author1=S. Mann |author2=R. W. Picard }}</ref>\n\nOn October 28, 1998, Ben Sarao created one of the first nighttime HDR+G (High Dynamic Range + Graphic image) of STS-95 on the\nlaunch pad at [[NASA]]'s [[Kennedy Space Center]]. It consisted of four film images of the [[Space Shuttle|space shuttle]] at night that were [[Digital compositing|digitally composited]] with additional digital graphic elements. The image was first exhibited at [[NASA Headquarters]] Great Hall, Washington DC in 1999 and then published in ''Hasselblad Forum'', Issue 3 1993, Volume 35 ISSN 0282-5449.<ref name=\"sarao1999\">{{cite book |work=Hasselblad Forum | issue=3 | year=1999 | volume=35 | issn=0282-5449 |title=Ben Sarao, Trenton, NJ |author=B. M. Sarao |editor=S. Gunnarsson}}</ref>\n\nThe advent of consumer digital cameras produced a new demand for HDR imaging to improve the light response of digital camera sensors, which had a much smaller dynamic range than film. [[Steve Mann (inventor)|Steve Mann]] developed and patented the global-HDR method for producing digital images having extended dynamic range at the [[MIT Media Lab|MIT Media Laboratory]].<ref name=\"MannPatent\">{{ref patent |country=US |number=5828793 |status=application |title=Method and apparatus for producing digital images having extended dynamic ranges |pubdate=1998-10-27 |fdate=1996-05-06 |inventor=Steve Mann}}</ref> Mann's method involved a two-step procedure: (1) generate one floating point image array by global-only image operations (operations that affect all pixels identically, without regard to their local neighborhoods); and then (2) convert this image array, using local neighborhood processing (tone-remapping, etc.), into an HDR image. The image array generated by the first step of Mann's process is called a ''lightspace image'', ''lightspace picture'', or ''radiance map''. Another benefit of global-HDR imaging is that it provides access to the intermediate light or radiance map, which has been used for [[Computer vision|computer vision]], and other [[Digital image processing|image processing]] operations.<ref name=\"MannPatent\"/>\n\n=== 21st century ===\nIn 2005, [[Adobe Systems]] introduced several new features in [[Photoshop CS2]] including ''Merge to HDR'', 32 bit floating point image support, and HDR tone mapping.<ref name=\"llcs2hdr\">{{cite web |url=http://luminous-landscape.com/tutorials/hdr.shtml |archive-url=https://web.archive.org/web/20100102063950/http://luminous-landscape.com/tutorials/hdr.shtml |url-status=dead |archive-date=2010-01-02 |title=Merge to HDR in Photoshop CS2 |accessdate=2009-08-27}}</ref>\n\nOn June 30, 2016, [[Microsoft]] added support for the digital compositing of HDR images to [[Windows 10]] using the [[Universal Windows Platform]].<ref name=\"2016HDRphotographyWindows10\">{{cite news |title=Microsoft talks up the advantages of HDR photography and videography in Universal Windows Platform apps |author=Kareem Anderson |publisher=winbeta.org |url=http://www.winbeta.org/news/microsoft-talks-advantages-hdr-photography-videography-universal-windows-platform-apps |date=2016-06-30 |accessdate=2016-09-24}}</ref>\n\n== Examples ==\n\n=== HDR processing ===\nThis is an example of four standard dynamic range images that are combined to produce three resulting [[Tone mapping|tone mapped]] images.\n;Original images\n<div style=\"float:left\">\n<gallery mode=\"packed\">\nImage:StLouisArchMultExpEV-4.72.JPG|\u20134 stops\nImage:StLouisArchMultExpEV-1.82.JPG|\u20132 stops\nImage:StLouisArchMultExpEV+1.51.JPG|+2 stops\nImage:StLouisArchMultExpEV+4.09.JPG|+4 stops\n</gallery>\n;Results after processing\n<gallery heights=\"240\" mode=\"packed\">\nFile:StLouisArchMultExpCDR.jpg|Simple contrast reduction\nFile:StLouisArchMultExpToneMapped.jpg|Local tone mapping\nFile:StLouisArchMultExpEV SNS-HDR.jpg|alt=Natural tone mapping|Natural tone mapping\n</gallery>\n<br>\nThis is an example of a scene with a very wide dynamic range.\n;Source images\n<gallery mode=\"packed\">\nImage:HDRI Sample Scene Window - 01.jpg\nImage:HDRI Sample Scene Window - 02.jpg\nImage:HDRI Sample Scene Window - 03.jpg\nImage:HDRI Sample Scene Window - 04.jpg\n</gallery>\n<gallery mode=\"packed\">\nImage:HDRI Sample Scene Window - 05.jpg\nImage:HDRI Sample Scene Window - 06.jpg\nImage:HDRI Sample Scene Window - 07.jpg\nImage:HDRI Sample Scene Window - 08.jpg\n</gallery>\n<gallery mode=\"packed\">\nImage:HDRI Sample Scene Window - 09.jpg\nImage:HDRI Sample Scene Window - 10.jpg\nImage:HDRI Sample Scene Window - 11.jpg\nImage:HDRI Sample Scene Window - 12.jpg\n</gallery>\n;Results after processing\n<gallery heights=\"240\" mode=\"packed\">\nImage:HDRI Sample Scene Window.jpg|Natural tone mapping\n</gallery>\n</div>\n{{clear}}\n\n[[File:Hdr capture golf swing ghost effect.jpg|thumb|upright=1.8|Multiple exposures merging of images created a ghost effect from the fast moving subject.]]\n\n=== Multiple exposures anomalies ===\nThis fast-moving subject captured by an Apple iPhone 6 benefited from HDR by exposing both the shaded grass and the bright sky. However, the merging of images from a fast moving golf swing lead to a ghost effect.\n\n== HDR sensors ==\nModern [[CMOS]] [[Image sensor|image sensors]] can often capture a high dynamic range from a single exposure. The wide dynamic range of the captured image is non-linearly compressed into a smaller dynamic range electronic representation.<ref>{{cite book |title=High Dynamic Range Imaging: Sensors and Architectures |edition=First |author=Arnaud Darmont |publisher=SPIE press |year=2012 |isbn=978-0-81948-830-5 |url=http://spie.org/x648.html?product_id=903927}}</ref> However, with proper processing, the information from a single exposure can be used to create an HDR image.\n\nSuch HDR imaging is used in extreme dynamic range applications like welding or automotive work. Some other cameras designed for use in security applications can automatically provide two or more images for each frame, with changing exposure {{Citation needed|date=November 2017}}. For example, a sensor for 30fps video will give out 60fps with the odd frames at a short exposure time and the even frames at a longer exposure time. Some of the sensors on modern phones and cameras may even combine the two images on-chip so that a wider dynamic range without in-pixel compression is directly available to the user for display or processing{{Citation needed|date=November 2017}}.\n\n== See also ==\n{{Commons category|High-dynamic-range imaging}}\n* [[Comparison of graphics file formats]]\n* [[HDRi (data format)]]\n* [[High-dynamic-range rendering]]\n* [[High-dynamic-range video]]\n* [[JPEG XT]]\n* [[Logluv TIFF]]\n* [[OpenEXR]]\n* [[RGBE image format]]\n* [[scRGB colorspace]]\n* [[Wide dynamic range]]\n* [[Ultra-high-definition television]]\n\n== References ==\n{{Reflist|32 ^ Benjamin Sarao (1999). Ben Sarao, Trenton, NJ, USA: Space Shuttle Discovery, pages 16\u201317 (English ed.). Victor Hasselblad AB, Goteborg, Sweden. ISSN 0282-5449.em}}\n\n{{Photography}}\n{{Display technology}}\n\n[[Category:Articles containing video clips]]\n[[Category:Computer graphics]]\n[[Category:High dynamic range]]\n[[Category:High dynamic range imaging]]\n[[Category:Photographic techniques]]\n", "text_old": "{{Redirect|HDRI|the form of iron|Direct reduced iron}}\n{{distinguish|Range imaging}}\n[[File:St Kentigerns Church HDR (8226826999).jpg|thumb|upright=1.2|right|Tone mapped high-dynamic-range (HDR) image of St. Kentigern's Church in [[Blackpool]], Lancashire, England]]\n\n{{Plain English|date=February 2020}}\n\n'''High-dynamic-range imaging''' ('''HDRI''') is a [[high dynamic range]] (HDR) technique used in imaging and films to reproduce a greater [[dynamic range#Photography|dynamic range]] of [[luminosity function|luminosity]] than what is possible with standard [[digital imaging]] or photographic techniques. Standard techniques allow differentiation only within a certain range of brightness. Outside of this range, no features are visible because there is no differentiation in bright areas as everything appears just pure white, and there is no differentiation in darker areas as everything appears pure black.  \n\nHDR images can record and represent a greater range of luminance levels than can be achieved using more traditional methods, such as many real-world scenes containing very bright, direct sunlight to extreme shade, or very faint [[Nebula|nebulae]]. This is often achieved by capturing and then combining several different, narrower range, [[Exposure (photography)|exposures]] of the same subject matter.<ref name=\"mann1993\" /><ref name=\"mann1995\" /><ref>{{cite book |author1=Reinhard, Erik |author2=Ward, Greg |author3=Pattanaik, Sumanta |author4=Debevec, Paul |title=High dynamic range imaging: acquisition, display, and image-based lighting |year=2005 |quote=Images that store a depiction of the scene in a range of intensities commensurate with the scene are what we call HDR, or \"radiance maps\". On the other hand, we call images suitable for display with current display technology LDR. |publisher=Elsevier/Morgan Kaufmann |location=Amsterdam |page=7 |isbn=978-0-12-585263-0}}</ref><ref>{{cite book |author1=Banterle, Francesco |author2=Artusi, Alessandro |author3=Debattista, Kurt |author4=Chalmers, Alanl |title=Advanced High dynamic Range Imaging: theory and practiceg |year=2011 |publisher=AK Peters/CRC Press|isbn=978-156881-719-4}}</ref> Non-HDR cameras take [[Photograph|photographs]] with a limited exposure range, referred to as low dynamic range (LDR), resulting in the loss of detail in highlights or [[shadow#Photography|shadows]].\n\nThe two primary types of HDR images are [[high-dynamic-range rendering|computer renderings]] and images resulting from merging multiple low-dynamic-range (LDR)<ref>{{cite journal |title=Real-Time High Dynammic Range Texture Mapping |author=Cohen, Jonathan and Tchou, Chris and Hawkins, Tim and Debevec, Paul E. |journal=Proceedings of the 12th Eurographics Workshop on Rendering Techniques |editor1=Steven Jacob Gortler |editor2=Karol Myszkowski |publisher=Springer |year=2001 |isbn=3-211-83709-4 |pages=313\u2013320}}</ref> or standard-dynamic-range (SDR)<ref>{{cite book |title=Advances in image and video technology: Second Pacific Rim Symposium (PSIVT)'' 2007, Santiago, Chile, December 17\u201319, 2007'' |chapter=Fast automatic compensation of under/over-exposured image regions |author1=Vassilios Vonikakis |author2=Ioannis Andreadis |editor1=Domingo Mery |editor2=Luis Rueda |publisher= |year=2008 |isbn=978-3-540-77128-9 |page=510 |url=https://books.google.com/books?id=vkNfw8SsU3oC&pg=PA510&dq=hdr+sdr+%22standard+dynamic+range%22&q=hdr%20sdr%20%22standard%20dynamic%20range%22}}</ref> photographs. HDR images can also be acquired using special [[Image sensor|image sensors]], such as an [[oversampled binary image sensor]].\n\nDue to the limitations of printing and [[display contrast]], the extended luminosity range of input HDR images has to be compressed to be made visible. The method of rendering an HDR image to a standard monitor or printing device is called [[tone mapping]]. This method reduces the overall contrast of an HDR image to facilitate display on devices or printouts with lower dynamic range, and can be applied to produce images with preserved local contrast (or exaggerated for artistic effect).\n\n\"HDR\" may refer to the overall process, to the HDR imaging process, or to HDR imaging represented on a low dynamic range display such as a screen or standard .jpg image.\n\n\n== Emulating the human vision system==\nOne aim of HDR is to present a similar range of [[luminance]] to that experienced through the human [[visual system]]. The human eye, through non-linear response, [[adaptation (eye)|adaptation]] of the [[Iris (anatomy)|iris]] and other methods, adjusts constantly to adapt to a broad range of luminance present in the environment. The brain continuously interprets this information so that a viewer can see in a wide range of light conditions.\n\nStandard photographic and image techniques allow differentiation only within a certain range of brightness. Outside of this range, no features are visible because there is no differentiation in bright areas as everything appears just pure white, and there is no differentiation in darker areas as everything appears pure black.  Non-HDR cameras take photographs with a limited exposure range, referred to as low dynamic range (LDR), resulting in the loss of detail in highlights or [[shadow#Photography|shadows]].\n\n== Photography ==\n\n{|class=\"wikitable unsortable floatright\"\n|+ '''Dynamic ranges of common devices'''\n|-\n! Device\n! Stops\n! Contrast Ratio\n|- style=\"background-color:#DDF;\"\n| colspan=\"4\" | '''Single exposure'''\n|-\n| Human eye: close objects\n| {{0}}7.5\n| {{0|00}}150...200\n|-\n| Human eye: 4\u00b0 angular separation\n| 13\n| {{0}}8000...10000\n|-\n| Human eye (static)\n| 10...14&nbsp;<ref>{{cite web |url=http://www.cambridgeincolour.com/tutorials/dynamic-range.htm|title=Dynamic Range in Digital Photography|accessdate=2010-12-30}}</ref>\n| {{0}}1000...15000\n|-\n| Negative film ([[List of motion picture film stocks#VISION3 color negative (ECN-2 process 2007\u2013present)|Kodak VISION3]])\n| 13&nbsp;<ref name=\"Kodak v3\">{{cite web|url=http://motion.kodak.com/motion/About/The_Storyboard/17788/index.htm|title=Dynamic Range}}{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes }}</ref>\n| {{0}}8000\n|-\n| best 1/1.7\" camera ([[Nikon Coolpix P340]])\n| 11.9{{cn|date=May 2018}}\n| {{0}}3800\n|-\n| best 1\" camera ([[Canon PowerShot G7 X]])\n| 12.7{{cn|date=May 2018}}\n| {{0}}6600\n|-\n| best Four-Thirds DSLR camera ([[Panasonic Lumix DC-GH5]])\n| 13.0{{cn|date=May 2018}}\n| {{0}}8200\n|-\n| best APS DSLR camera ([[Nikon D7200]])\n| 14.6&nbsp;<ref name=DXOMark>{{cite web | url=http://www.dxomark.com/Cameras/Camera-Sensor-Ratings/%28type%29/usecase_landscape | title=Camera Sensor Ratings by DxOMark | publisher=[[DxO Labs]] | accessdate=February 2, 2015}}</ref>\n| 24800\n|-\n| best Full Frame DSLR camera ([[Nikon D810]])\n| 14.8&nbsp;<ref name=DXOMark>{{cite web | url=http://www.dxomark.com/Cameras/Camera-Sensor-Ratings/%28type%29/usecase_landscape | title=Camera Sensor Ratings by DxOMark | publisher=[[DxO Labs]] | accessdate=February 2, 2015}}</ref>\n| 28500 <!-- Calculated from formula: Contrast Ratio = 2^(Dynamic Range) -->\n|- style=\"background-color:#DDF;\"\n|}\n\nIn photography, dynamic range is measured in exposure value ([[exposure value|EV]]) differences (known as ''stops''). An increase of one EV, or 'one stop', represents a doubling of the amount of light. Conversely, a decrease of one EV represents a halving of the amount of light. Therefore, revealing detail in the darkest of shadows requires high exposures, while preserving detail in very bright situations requires very low exposures. Most cameras cannot provide this range of exposure values within a single exposure, due to their low dynamic range.\nHigh-dynamic-range photographs are generally achieved by capturing multiple standard-exposure images, often using [[Bracketing#Exposure bracketing|exposure bracketing]], and then later [[Exposure fusion|merging them]] into a single HDR image, usually within a [[photo manipulation]] program.\n\nAny camera that allows manual exposure control can make images for HDR work, although one equipped with [[Autobracketing|auto exposure bracketing (AEB)]] is far better suited. Images from film cameras are less suitable as they often must first be digitized, so that they can later be processed using software HDR methods.\n\nIn most imaging devices, the degree of exposure to light applied to the active element (be it film or [[Charge-coupled device|CCD]]) can be altered in one of two ways: by either increasing/decreasing the size of the [[aperture]] or by increasing/decreasing the time of each [[exposure (photography)|exposure]]. Exposure variation in an HDR set is only done by altering the '''exposure time''' and ''not'' the aperture size; this is because altering the aperture size also affects the [[depth of field]] and so the resultant multiple images would be quite different, preventing their final combination into a single HDR image.\n\nAn important limitation for HDR photography is that any movement between successive images will impede or prevent success in combining them afterward. Also, as one must create several images (often three or five and sometimes more) to obtain the desired [[luminance]] range, such a full 'set' of images takes extra time. HDR photographers have developed calculation methods and techniques to partially overcome these problems, but the use of a sturdy tripod is, at least, advised.\n\nSome cameras have an [[Autobracketing|auto exposure bracketing (AEB)]] feature with a far greater dynamic range than others, from the 3 EV of the [[Canon EOS 40D]], to the 18 EV of the [[Canon EOS-1D Mark II]].<ref>{{cite web |title=Auto Exposure Bracketing by camera model |url=http://hdr-photography.com/aeb.html |accessdate=18 August 2009}}</ref> As the popularity of this imaging method grows, several camera manufacturers are now offering built-in HDR features. For example, the [[Pentax K-7]] DSLR has an HDR mode that captures an HDR image and outputs (only) a tone mapped JPEG file.<ref>{{cite web |title=The Pentax K-7: The era of in-camera High Dynamic Range Imaging has arrived! |url=http://www.adorama.com/alc/0011608/blogarticle/The-Pentax-K-7-The-era-of-in-camera-High-Dynamic-Range-Imaging-has-arrived |accessdate=18 August 2009 |archive-url=https://web.archive.org/web/20120424063346/http://www.adorama.com/alc/0011608/blogarticle/The-Pentax-K-7-The-era-of-in-camera-High-Dynamic-Range-Imaging-has-arrived |archive-date=24 April 2012 |url-status=dead }}</ref> The [[Canon PowerShot G12]], [[Canon PowerShot S95]] and [[Canon PowerShot S100]] offer similar features in a smaller format.<ref>{{cite web |title=Canon PowerShot G12 picks up HD video recording, built-in HDR |url=http://www.digitaltrends.com/photography/cameras/canon-powershot-g12-picks-up-hd-video-recording-built-in-hdr/?news=123}}</ref> Nikon's approach is called 'Active D-Lighting' which applies exposure compensation and tone mapping to the image as it comes from the sensor, with the emphasis being on creating a realistic effect.<ref>{{cite web |title=Balancing Photo Exposures with Active D-lighting |url=http://www.nikonusa.com/en/learn-and-explore/a/ideas-and-inspiration/balancing-photo-exposures-with-nikons-active-d-lighting.html |accessdate=2 August 2017}}</ref> Some [[smartphone]]s provide HDR modes, and most [[mobile platform]]s have apps that provide HDR picture taking.<ref>[https://play.google.com/store/search?q=hdr%20mode&c=apps HDR apps for Android] Google Play</ref>\n\nCamera characteristics such as [[Gamma correction|gamma curves]], sensor resolution, noise, [[photometry (optics)|photometric]] calibration and [[color calibration]] affect resulting high-dynamic-range images.<ref name=\"SCV2007\">{{cite book |title=High Dynamic Range |edition=First |author1=Asla M. S\u00e1 |author2=Paulo Cezar Carvalho |author3=Luiz Velho |publisher=Focal Press |year=2007 |isbn=978-1-59829-562-7 |page=11 |url=https://books.google.com/books?id=mDsFgWPhWWYC&printsec=frontcover&dq=ISBN:+9781598295627#v=onepage&q=ISBN%3A%209781598295627&f=}}</ref>\n\nColor film negatives and slides consist of multiple film layers that respond to light differently. Original film (especially negatives versus transparencies or 'slides') feature a very high dynamic range (in the order of 8 for negatives and 4 to 4.5 for slides).\n=== Tone mapping ===\n{{Main article|Tone mapping}}\n\nTone mapping reduces the dynamic range, or contrast ratio, of an entire image while retaining localized contrast. Although it is a distinct operation, tone mapping is often applied to HDRI files by the same software package.\n\nSeveral software applications are available on the PC, Mac and Linux platforms for producing HDR files and tone mapped images. Notable titles include\n{{Div col}}\n* [[Adobe Photoshop]]\n* [[Aurora HDR]]\n* [[Dynamic Photo HDR]]\n* [[EasyHDR]]\n* [[GIMP]]\n* [[Nik Collection|HDR Efex Pro]]\n* [[HDR PhotoStudio]]\n* [[Luminance HDR]]\n* [[MagicRaw]]\n* [[Oloneo PhotoEngine]]\n* [[PTGui]]\n* [[Affinity Photo]]\n* [[SNS-HDR]]\n*[[HDRSoft - Photomatix]]{{Div col end}}\n\n=== Comparison with traditional digital images ===\nInformation stored in high-dynamic-range images typically corresponds to the physical values of [[luminance]] or [[radiance]] that can be observed in the real world. This is different from traditional [[digital images]], which represent colors as they should appear on a monitor or a paper print. Therefore, HDR image formats are often called ''scene-referred'', in contrast to traditional digital images, which are ''device-referred'' or ''output-referred''. Furthermore, traditional images are usually encoded for the human [[visual system]] (maximizing the visual information stored in the fixed number of bits), which is usually called ''gamma encoding'' or ''[[gamma correction]]''. The values stored for HDR images are often [[gamma correction|gamma compressed]] ([[power law]]) or [[logarithm]]ically encoded, or [[floating point|floating-point]] linear values, since [[fixed-point arithmetic|fixed-point]] linear encodings are increasingly inefficient over higher dynamic ranges.<ref name=gregward/><ref>{{cite web |url=http://radsite.lbl.gov/radiance/refer/Notes/picture_format.html |accessdate=2009-08-21 |title=The Radiance Picture File Format}}</ref><ref>{{cite book |last=Fernando |first=Randima |title=GPU Gems |publisher=Addison-Wesley |location=Boston |year=2004 |chapter=26.5 Linear Pixel Values |url=http://http.developer.nvidia.com/GPUGems/gpugems_ch26.html |isbn=0-321-22832-4 |url-status=dead |archiveurl=https://web.archive.org/web/20100412001848/http://http.developer.nvidia.com/GPUGems/gpugems_ch26.html |archivedate=2010-04-12 }}</ref>\n\nHDR images often don't use fixed ranges per color [[channel (digital image)|channel]]\u2014other than traditional images\u2014to represent many more colors over a much wider dynamic range. For that purpose, they do not use integer values to represent the single color channels (e.g., 0-255 in an 8 bit per pixel interval for red, green and blue) but instead use a floating point representation. Common are 16-bit (''[[half precision]]'') or 32-bit [[floating point]] numbers to represent HDR pixels. However, when the appropriate [[transfer function]] is used, HDR pixels for some applications can be represented with a [[color depth]] that has as few as 10\u201312&nbsp;bits for luminance and 8&nbsp;bits for [[chrominance]] without introducing any visible quantization artifacts.<ref name=gregward>{{cite web |url=http://www.anyhere.com/gward/hdrenc/hdr_encodings.html |title=High Dynamic Range Image Encodings |author1=Greg Ward |author2=Anyhere Software }}</ref><ref>{{cite web |url=http://www.mpi-sb.mpg.de/resources/hdrvideo/ |title=Perception-motivated High Dynamic Range Video Encoding |author=[[Max Planck Institute for Computer Science]]}}</ref>\n\n== History of HDR photography ==\n\n=== Mid 19th century ===\n[[File:Gustave Le Gray - Brig upon the Water - Google Art Project.jpg|thumb|right|upright=1.2|An 1856 photo by [[Gustave Le Gray]]]]\nThe idea of using several exposures to adequately reproduce a too-extreme range of [[luminance]] was pioneered as early as the 1850s by [[Gustave Le Gray]] to render seascapes showing both the sky and the sea. Such rendering was impossible at the time using standard methods, as the luminosity range was too extreme. Le Gray used one negative for the sky, and another one with a longer exposure for the sea, and combined the two into one picture in positive.<ref name=GettyExh>[[J. Paul Getty Museum]]. [http://www.getty.edu/art/exhibitions/le_gray Gustave Le Gray, Photographer. July 9&nbsp;\u2013 September 29, 2002.] Retrieved September 14, 2008.</ref>\n\n=== Mid 20th century ===\n{{external media |image1=[https://web.archive.org/web/20170315033441/http://www.cybergrain.com/tech/hdr/images1/eugene_smith.jpg Schweitzer at the Lamp], by [[W. Eugene Smith]]<ref>[http://www.cybergrain.com/tech/hdr/ The Future of Digital Imaging \u2013 High Dynamic Range Photography], Jon Meyer, Feb 2004</ref><ref name=\"durand\">[http://people.csail.mit.edu/fredo/ArtAndScienceOfDepiction/ 4.209: The Art and Science of Depiction], Fr\u00e9do Durand and [[Julie Dorsey]], [http://people.csail.mit.edu/fredo/ArtAndScienceOfDepiction/12_Contrast/contrast.html Limitations of the Medium: Compensation and accentuation&nbsp;\u2013 The Contrast is Limited], lecture of Monday, April 9. 2001, [http://people.csail.mit.edu/fredo/ArtAndScienceOfDepiction/12_Contrast/contrast6.pdf slide 57\u201359]; image on slide 57, depiction of dodging and burning on slide 58</ref>\n}}\n\nManual tone mapping was accomplished by [[dodging and burning]]&nbsp;\u2013 selectively increasing or decreasing the exposure of regions of the photograph to yield better tonality reproduction. This was effective because the dynamic range of the negative is significantly higher than would be available on the finished positive paper print when that is exposed via the negative in a uniform manner. An excellent example is the photograph ''Schweitzer at the Lamp'' by [[W. Eugene Smith]], from his 1954 [[photo essay]] ''A Man of Mercy'' on Dr. [[Albert Schweitzer]] and his humanitarian work in French Equatorial Africa. The image took 5 days to reproduce the tonal range of the scene, which ranges from a bright lamp (relative to the scene) to a dark shadow.<ref name=\"durand\"/>\n\n[[Ansel Adams]] elevated dodging and burning to an art form. Many of his famous prints were manipulated in the darkroom with these two methods. Adams wrote a comprehensive book on producing prints called ''The Print,'' which prominently features dodging and burning, in the context of his [[Zone System]].\n\nWith the advent of color photography, tone mapping in the darkroom was no longer possible due to the specific timing needed during the developing process of color film. Photographers looked to film manufacturers to design new film stocks with improved response, or continued to shoot in black and white to use tone mapping methods.{{citation needed|date=November 2013}}\n\n[[File:Wyckoff HDR Curve.tif|thumb|left|upright=2.4|Exposure/Density Characteristics of Wyckoff's Extended Exposure Response Film]]\nColor film capable of directly recording high-dynamic-range images was developed by [[Charles Wyckoff]] and [[EG&G]] \"in the course of a contract with the Department of the Air Force\".<ref>{{cite patent | inventor-last = Wyckoff | inventor-first = Charles W.\n | inventorlink = Charles Wyckoff | inventor2-last = EG&G Inc., assignee | inventor2-first = | inventorlink2 = EG&G | publication-date = March 24, 1961 | issue-date = June 17, 1969 | title = Silver Halide Photographic Film having Increased Exposure-response Characteristics | country-code = US | description = | patent-number = 3450536 | url = http://www.google.com/patents?hl=en&lr=&vid=USPAT3450536&id=43RzAAAAEBAJ&oi=fnd&dq=%22Extended+exposure%22+Wyckoff&printsec=abstract#v=onepage&q=%22Extended%20exposure%22%20Wyckoff&f=false | accessdate = June 1, 2012}}</ref> This XR film had three [[Photographic emulsion|emulsion]] layers, an upper layer having an [[Film speed#ASA|ASA]] speed rating of 400, a middle layer with an intermediate rating, and a lower layer with an ASA rating of 0.004. The film was processed in a manner similar to [[Color photography#\"Modern\" color film|color films]], and each layer produced a different color.<ref>C. W. Wyckoff. Experimental extended exposure response film. ''Society of Photographic Instrumentation Engineers Newsletter'', June\u2013July, 1962, pp. 16-20.</ref> The dynamic range of this extended range film has been estimated as 1:10<sup>8</sup>.<ref>Michael Goesele, et al., \"High Dynamic Range Techniques in Graphics: from Acquisition to Display\", [http://www.mpi-inf.mpg.de/resources/tmo/EG05_HDRTutorial_Complete.pdf Eurographics 2005 Tutorial T7]</ref> It has been used to photograph nuclear explosions,<ref>[http://www.fas.org/irp/threat/mctl98-2/p2sec05.pdf ''The Militarily Critical Technologies List''] (1998), pages II-5-100 and II-5-107.</ref> for astronomical photography,<ref>Andrew T. Young and Harold Boeschenstein, Jr., ''Isotherms in the region of Proclus at a phase angle of 9.8 degrees'', Scientific Report No. 5, Harvard, College Observatory: Cambridge, Massachusetts, 1964.</ref> for spectrographic research,<ref>{{cite journal |first=R. L. |last=Bryant |first2=G. J. |last2=Troup |first3=R. G. |last3=Turner |title=The use of a high-intensity-range photographic film for recording extended diffraction patterns and for spectrographic work |journal=Journal of Scientific Instruments |volume=42 |issue=2 |year=1965 |pages=116 |doi=10.1088/0950-7671/42/2/315 }}</ref> and for medical imaging.<ref>{{cite journal |first=Leslie M. |last=Eber |first2=Haervey M. |last2=Greenberg |first3=John M. |last3=Cooke |first4=Richard |last4=Gorlin |title=Dynamic Changes in Left Ventricular Free Wall Thickness in the Human Heart |journal=Circulation |volume=39 |year=1969 |issue=4 |pages=455\u2013464 |doi=10.1161/01.CIR.39.4.455 |doi-access=free }}</ref> Wyckoff's detailed pictures of nuclear explosions appeared on the cover of ''[[Life magazine|Life]]'' magazine in the mid-1950s.\n\n=== Late 20th century ===\nGeorges Cornu\u00e9jols and licensees of his patents (Brdi, Hymatom) introduced the principle of HDR video image, in 1986, by interposing a matricial LCD screen in front of the camera's image sensor,<ref>{{Cite web|url=https://worldwide.espacenet.com/publicationDetails/biblio?II=0&ND=3&adjacent=true&locale=en_EP&FT=D&date=19910924&CC=US&NR=5051770A&KC=A#|title=Image processing device for controlling the transfer function of an optical system|last=|first=|date=|website=espacenet.com|publisher=|access-date=}}</ref> increasing the sensors dynamic by five stops. The concept of neighborhood tone mapping was applied to video cameras by a group from the [[Technion]] in Israel led by Dr. Oliver Hilsenrath and Prof. Y.Y.Zeevi who filed for a patent on this concept in 1988.<ref name=\"WDR Patent\">{{Ref patent |country=US |status=granted |number=5144442 |title=Wide dynamic range camera |pubdate=1992-09-01 |fdate=1991-11-21 |inventor=Ginosar, R., Hilsenrath, O., Zeevi, Y.}}</ref>\n\nIn February and April 1990, Georges Cornu\u00e9jols introduced the first real-time HDR camera that combined two images captured by a sensor<ref name=espacenet1>{{Cite web|url=https://worldwide.espacenet.com/publicationDetails/biblio?II=0&ND=3&adjacent=true&locale=en_EP&FT=D&date=19970610&CC=US&NR=5638119A&KC=A#|title=Device for increasing the dynamic range of a camera|last=|first=|date=|website=|publisher=|access-date=}}</ref>or simultaneously<ref>{{Cite web|url=https://worldwide.espacenet.com/publicationDetails/biblio?II=0&ND=3&adjacent=true&locale=en_EP&FT=D&date=19970610&CC=US&NR=5638119A&KC=A#|title=Camera with very wide dynamic range|last=|first=|date=|website=espacenet.com|publisher=|access-date=}}</ref> by two sensors of the camera. This process is known as [[bracketing]] used for a video stream.\n\nIn 1991, the first commercial video camera was introduced that performed real-time capturing of multiple images with different exposures, and producing an HDR video image, by Hymatom, licensee of Georges Cornu\u00e9jols.\n\nAlso in 1991, Georges Cornu\u00e9jols introduced the HDR+ image principle by non-linear accumulation of images to increase the sensitivity of the camera:<ref name=espacenet1/> for low-light environments, several successive images are accumulated, thus increasing the signal to noise ratio.\n\nIn 1993, another commercial medical camera  producing an HDR video image, by the Technion.<ref name=\"AdaptiveSens\">{{cite journal |author=Technion&nbsp;\u2013 Israel Institute of Technology |title=Adaptive Sensitivity |url=http://visl.technion.ac.il/research/isight/AS/ |year=1993 |access-date=2019-01-27 |archive-url=https://web.archive.org/web/20140907142738/http://visl.technion.ac.il/research/isight/AS/ |archive-date=2014-09-07 |url-status=dead }}</ref>\n\nModern HDR imaging uses a completely different approach, based on making a high-dynamic-range luminance or light map using only global image operations (across the entire image), and then [[tone mapping]] the result. Global HDR was first introduced in 1993<ref name=\"mann1993\">\"Compositing Multiple Pictures of the Same Scene\", by Steve Mann, in IS&T's 46th Annual Conference, Cambridge, Massachusetts, May 9\u201314, 1993</ref> resulting in a mathematical theory of differently exposed pictures of the same subject matter that was published in 1995 by [[Steve Mann (inventor)|Steve Mann]] and Rosalind Picard.<ref name=\"mann1995\">{{cite web |url=http://wearcam.org/is_t95_myversion.pdf |title=On Being \u2018Undigital\u2019 With Digital Cameras: Extending Dynamic Range By Combining Differently Exposed Pictures |author1=S. Mann |author2=R. W. Picard }}</ref>\n\nOn October 28, 1998, Ben Sarao created one of the first nighttime HDR+G (High Dynamic Range + Graphic image) of STS-95 on the\nlaunch pad at [[NASA]]'s [[Kennedy Space Center]]. It consisted of four film images of the [[Space Shuttle|space shuttle]] at night that were [[Digital compositing|digitally composited]] with additional digital graphic elements. The image was first exhibited at [[NASA Headquarters]] Great Hall, Washington DC in 1999 and then published in ''Hasselblad Forum'', Issue 3 1993, Volume 35 ISSN 0282-5449.<ref name=\"sarao1999\">{{cite book |work=Hasselblad Forum | issue=3 | year=1999 | volume=35 | issn=0282-5449 |title=Ben Sarao, Trenton, NJ |author=B. M. Sarao |editor=S. Gunnarsson}}</ref>\n\nThe advent of consumer digital cameras produced a new demand for HDR imaging to improve the light response of digital camera sensors, which had a much smaller dynamic range than film. [[Steve Mann (inventor)|Steve Mann]] developed and patented the global-HDR method for producing digital images having extended dynamic range at the [[MIT Media Lab|MIT Media Laboratory]].<ref name=\"MannPatent\">{{ref patent |country=US |number=5828793 |status=application |title=Method and apparatus for producing digital images having extended dynamic ranges |pubdate=1998-10-27 |fdate=1996-05-06 |inventor=Steve Mann}}</ref> Mann's method involved a two-step procedure: (1) generate one floating point image array by global-only image operations (operations that affect all pixels identically, without regard to their local neighborhoods); and then (2) convert this image array, using local neighborhood processing (tone-remapping, etc.), into an HDR image. The image array generated by the first step of Mann's process is called a ''lightspace image'', ''lightspace picture'', or ''radiance map''. Another benefit of global-HDR imaging is that it provides access to the intermediate light or radiance map, which has been used for [[Computer vision|computer vision]], and other [[Digital image processing|image processing]] operations.<ref name=\"MannPatent\"/>\n\n=== 21st century ===\nIn 2005, [[Adobe Systems]] introduced several new features in [[Photoshop CS2]] including ''Merge to HDR'', 32 bit floating point image support, and HDR tone mapping.<ref name=\"llcs2hdr\">{{cite web |url=http://luminous-landscape.com/tutorials/hdr.shtml |archive-url=https://web.archive.org/web/20100102063950/http://luminous-landscape.com/tutorials/hdr.shtml |url-status=dead |archive-date=2010-01-02 |title=Merge to HDR in Photoshop CS2 |accessdate=2009-08-27}}</ref>\n\nOn June 30, 2016, [[Microsoft]] added support for the digital compositing of HDR images to [[Windows 10]] using the [[Universal Windows Platform]].<ref name=\"2016HDRphotographyWindows10\">{{cite news |title=Microsoft talks up the advantages of HDR photography and videography in Universal Windows Platform apps |author=Kareem Anderson |publisher=winbeta.org |url=http://www.winbeta.org/news/microsoft-talks-advantages-hdr-photography-videography-universal-windows-platform-apps |date=2016-06-30 |accessdate=2016-09-24}}</ref>\n\n== Examples ==\n\n=== HDR processing ===\nThis is an example of four standard dynamic range images that are combined to produce three resulting [[Tone mapping|tone mapped]] images.\n;Original images\n<div style=\"float:left\">\n<gallery mode=\"packed\">\nImage:StLouisArchMultExpEV-4.72.JPG|\u20134 stops\nImage:StLouisArchMultExpEV-1.82.JPG|\u20132 stops\nImage:StLouisArchMultExpEV+1.51.JPG|+2 stops\nImage:StLouisArchMultExpEV+4.09.JPG|+4 stops\n</gallery>\n;Results after processing\n<gallery widths=\"303\" heights=\"202\" mode=\"packed\">\nFile:StLouisArchMultExpCDR.jpg|Simple contrast reduction\nFile:StLouisArchMultExpToneMapped.jpg|Local tone mapping\nFile:StLouisArchMultExpEV SNS-HDR.jpg|alt=Natural tone mapping|Natural tone mapping\n</gallery>\n<br>\nThis is an example of a scene with a very wide dynamic range.\n;Source images\n<gallery mode=\"packed\">\nImage:HDRI Sample Scene Window - 01.jpg\nImage:HDRI Sample Scene Window - 02.jpg\nImage:HDRI Sample Scene Window - 03.jpg\nImage:HDRI Sample Scene Window - 04.jpg\n</gallery>\n<gallery mode=\"packed\">\nImage:HDRI Sample Scene Window - 05.jpg\nImage:HDRI Sample Scene Window - 06.jpg\nImage:HDRI Sample Scene Window - 07.jpg\nImage:HDRI Sample Scene Window - 08.jpg\n</gallery>\n<gallery mode=\"packed\">\nImage:HDRI Sample Scene Window - 09.jpg\nImage:HDRI Sample Scene Window - 10.jpg\nImage:HDRI Sample Scene Window - 11.jpg\nImage:HDRI Sample Scene Window - 12.jpg\n</gallery>\n;Results after processing\n<gallery heights=\"300\" mode=\"packed\">\nImage:HDRI Sample Scene Window.jpg|Natural tone mapping\n</gallery>\n</div>\n{{clear}}\n\n[[File:Hdr capture golf swing ghost effect.jpg|thumb|upright=1.8|Multiple exposures merging of images created a ghost effect from the fast moving subject.]]\n\n=== Multiple exposures anomalies ===\nThis fast-moving subject captured by an Apple iPhone 6 benefited from HDR by exposing both the shaded grass and the bright sky. However, the merging of images from a fast moving golf swing lead to a ghost effect.\n\n== HDR sensors ==\nModern [[CMOS]] [[Image sensor|image sensors]] can often capture a high dynamic range from a single exposure. The wide dynamic range of the captured image is non-linearly compressed into a smaller dynamic range electronic representation.<ref>{{cite book |title=High Dynamic Range Imaging: Sensors and Architectures |edition=First |author=Arnaud Darmont |publisher=SPIE press |year=2012 |isbn=978-0-81948-830-5 |url=http://spie.org/x648.html?product_id=903927}}</ref> However, with proper processing, the information from a single exposure can be used to create an HDR image.\n\nSuch HDR imaging is used in extreme dynamic range applications like welding or automotive work. Some other cameras designed for use in security applications can automatically provide two or more images for each frame, with changing exposure {{Citation needed|date=November 2017}}. For example, a sensor for 30fps video will give out 60fps with the odd frames at a short exposure time and the even frames at a longer exposure time. Some of the sensors on modern phones and cameras may even combine the two images on-chip so that a wider dynamic range without in-pixel compression is directly available to the user for display or processing{{Citation needed|date=November 2017}}.\n\n== See also ==\n{{Commons category|High-dynamic-range imaging}}\n* [[Comparison of graphics file formats]]\n* [[HDRi (data format)]]\n* [[High-dynamic-range rendering]]\n* [[High-dynamic-range video]]\n* [[JPEG XT]]\n* [[Logluv TIFF]]\n* [[OpenEXR]]\n* [[RGBE image format]]\n* [[scRGB colorspace]]\n* [[Wide dynamic range]]\n* [[Ultra-high-definition television]]\n\n== References ==\n{{Reflist|32 ^ Benjamin Sarao (1999). Ben Sarao, Trenton, NJ, USA: Space Shuttle Discovery, pages 16\u201317 (English ed.). Victor Hasselblad AB, Goteborg, Sweden. ISSN 0282-5449.em}}\n\n{{Photography}}\n{{Display technology}}\n\n[[Category:Articles containing video clips]]\n[[Category:Computer graphics]]\n[[Category:High dynamic range]]\n[[Category:High dynamic range imaging]]\n[[Category:Photographic techniques]]\n", "name_user": "Sebastian Nibisz", "label": "safe", "comment": "\u2192\u200eHDR processing:Images size has been changed.", "url_page": "//en.wikipedia.org/wiki/High-dynamic-range_imaging"}
