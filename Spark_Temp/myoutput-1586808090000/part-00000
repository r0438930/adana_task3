{"title_page": "Overclocking", "text_new": "''Not to be confused with [[Odometer#Clocking/busting_miles_and_legality|overclocking (mileometer/odometer)]]''\n\n[[Image:Overclock.jpg|thumb|upright=1.5|Overclocking [[BIOS]] setup on an ABIT NF7-S [[motherboard]] with an AMD [[Athlon&nbsp;XP]] processor. [[Front side bus]] (FSB) frequency (external clock) has been increased from 133&nbsp;[[Hertz|MHz]] to 148&nbsp;MHz, and the CPU [[clock multiplier]] factor has been changed from 13.5 to 16.5. This corresponds to an overclocking of the FSB by 11.3% and of the CPU by 36%.]]\n\nIn [[computing]], '''overclocking''' is the practice of increasing the [[clock rate]] of a computer to exceed that certified by the manufacturer. Commonly operating voltage is also increased to maintain a component's operational stability at accelerated speeds. [[Semiconductor device]]s operated at higher frequencies and voltages increase power consumption and heat.<ref>{{cite web|url=https://software.intel.com/en-us/blogs/2014/02/19/why-has-cpu-frequency-ceased-to-grow|author= Victoria Zhislina|date=2014-02-19|title=Why has CPU frequency ceased to grow?|publisher=Intel}}</ref> An overclocked device may be unreliable or fail completely if the additional heat load is not removed or power delivery components cannot meet increased power demands. Many device warranties state that overclocking and/or over-specification voids any warranty, however there are an increasing number of manufacturers that will allow overclocking as long as performed [relatively] safely.\n\n== Overview ==\n\nThe purpose of overclocking is to increase the operating speed of a given component. Normally, on modern systems, the target of overclocking is increasing the performance of a major chip or subsystem, such as the main processor or graphics controller, but other components, such as system memory ([[Random-access memory|RAM]]) or [[Bus (computing)|system buses]] (generally on the [[motherboard]]), are commonly involved. The trade-offs are an increase in power consumption (heat), fan noise (cooling), and shortened lifespan for the targeted components. Most components are designed with a margin of safety to deal with operating conditions outside of a manufacturer's control; examples are ambient temperature and fluctuations in operating voltage. Overclocking techniques in general aim to trade this safety margin by setting the device to run in the higher end of the margin, with the understanding that temperature and voltage must be more strictly monitored and controlled by the user. Examples are that operating temperature would need to be more strictly controlled with increased cooling, as the part will be less tolerant of increased temperatures at the higher speeds. Also base operating voltage may be increased to compensate for unexpected voltage drops and to strengthen signalling and timing signals, as low-voltage excursions are more likely to cause malfunctions at higher operating speeds.\n\nWhile most modern devices are fairly tolerant of overclocking, all devices have finite limits. Generally for any given voltage most parts will have a maximum \"stable\" speed where they still operate correctly. Past this speed the device starts giving incorrect results, which can cause malfunctions and sporadic behavior in any system depending on it. While in a PC context the usual result is a system crash, more subtle errors can go undetected, which over a long enough time can give unpleasant surprises such as [[data corruption]] (incorrectly calculated results, or worse ''writing to storage'' incorrectly) or the system failing only during certain specific tasks (general usage such as internet browsing and [[word processing]] appear fine, but any application wanting advanced graphics crashes the system).\n\nAt this point an increase in operating voltage of a part may allow more headroom for further increases in clock speed, but the increased voltage can also significantly increase heat output, as well as shorten the lifespan further. At some point there will be a limit imposed by the ability to supply the device with sufficient power, the user's ability to cool the part, and the device's own maximum voltage tolerance before it achieves [[Failure of electronic components|destructive failure]]. Overzealous use of voltage and/or inadequate cooling can rapidly degrade a device's performance to the point of failure, or in extreme cases outright [[Thermal runaway|destroy it]].\n\nThe speed gained by overclocking depends largely upon the applications and workloads being run on the system, and what components are being overclocked by the user; [[Benchmark (computing)|benchmark]]s for different purposes are published.\n\n===Underclocking===\n{{Main|Underclocking}}\nConversely, the primary goal of [[underclocking]] is to reduce power consumption and the resultant heat generation of a device, with the trade-offs being lower clock speeds and reductions in performance. Reducing the cooling requirements needed to keep hardware at a given operational temperature has knock-on benefits such as lowering the number and speed of fans to allow [[Quiet PC|quieter operation]], and in mobile devices increase the length of battery life per charge. Some manufacturers underclock components of battery-powered equipment to improve battery life, or implement systems that detect when a device is operating under battery power and reduce clock frequency accordingly.\n\nUnderclocking is almost always involved in the latter stages of [[Undervolting]], which seeks to find the highest clock speed that a processor will stably operate at a given voltage. That is, while overclocking seeks to maximize clock speed with temperature and power as constraints, underclocking seeks to find the highest clock speed that a device can reliably operate at a fixed, arbitrary power limit. A given device may operate correctly at its stock speed even when undervolted, in which case underclocking would only be employed after further reductions in voltage finally destabilizes the part. At that point the user would need to determine if the last working voltage and speed have satisfactorily lowered power consumption for their needs \u2013 if not then performance must be sacrificed, a lower clock is chosen (the underclock) and testing at progressively lower voltages would continue from that point. A lower bound is where the device itself fails to function and/or the supporting circuitry cannot reliably communicate with the part.\n\nUnderclocking and undervolting would be attempted on a desktop system to have it operate silently (such as for a home entertainment center) while potentially offering higher performance than currently offered by low-voltage processor offerings. This would use a \"standard-voltage\" part and attempt to run with lower voltages (while attempting to keep the desktop speeds) to meet an acceptable performance/noise target for the build. This was also attractive as using a \"standard voltage\" processor in a \"low voltage\" application avoided paying the traditional price premium for an officially certified low voltage version. However again like overclocking there is no guarantee of success, and the builder's time researching given system/processor combinations and especially the time and tedium of performing many iterations of stability testing need to be considered. The usefulness of underclocking (again like overclocking) is determined by what processor offerings, prices, and availability are at the specific time of the build. Underclocking is also sometimes used when [[troubleshooting]].\n\n===Enthusiast culture===\n\nOverclocking has become more accessible with motherboard makers offering overclocking as a marketing feature on their mainstream product lines. However, the practice is embraced more by [[enthusiast computing|enthusiasts]] than professional users, as overclocking carries a risk of reduced reliability, accuracy and damage to data and equipment. Additionally, most manufacturer warranties and service agreements do not cover overclocked components nor any incidental damages caused by their use. While overclocking can still be an option for increasing personal computing capacity, and thus workflow productivity for professional users, the importance of stability testing components thoroughly ''before'' employing them into a production environment cannot be overstated.\n\nOverclocking offers several draws for overclocking enthusiasts. Overclocking allows testing of components at speeds not currently offered by the manufacturer, or at speeds only officially offered on specialized, higher-priced versions of the product. A general trend in the computing industry is that new technologies tend to debut in the high-end market first, then later trickle down to the performance and mainstream market. If the high-end part only differs by an increased clock speed, an enthusiast can attempt to overclock a mainstream part to simulate the high-end offering. This can give insight on how over-the-horizon technologies will perform before they are officially available on the mainstream market, which can be especially helpful for other users considering if they should plan ahead to purchase or upgrade to the new feature when it is officially released.\n\nSome hobbyists enjoy building, tuning, and \"Hot-Rodding\" their systems in competitive benchmarking competitions, competing with other like-minded users for high scores in standardized computer benchmark suites. Others will purchase a low-cost model of a component in a given product line, and attempt to overclock that part to match a more expensive model's stock performance. Another approach is overclocking older components to attempt to keep pace with increasing [[system requirements]] and extend the useful service life of the older part or at least delay a purchase of new hardware solely for performance reasons. Another rationale for overclocking older equipment is even if overclocking stresses equipment to the point of failure earlier, little is lost as it is already [[Depreciation|depreciated]], and would have needed to be replaced in any case.<ref>{{cite book | title = The Book of Overclocking | first = Scott | last = Wainner | author2 = Robert Richmond | pages = [https://archive.org/details/bookofoverclocki0000wain/page/1 1\u20132] | isbn = 978-1-886411-76-0 | publisher = No Starch Press | year = 2003 | url = https://archive.org/details/bookofoverclocki0000wain/page/1 }}</ref>\n\n===Components===\n\nTechnically any component that uses a timer (or clock) to synchronize its internal operations can be overclocked. Most efforts for computer components however focus on specific components, such as, [[Central processing unit|processors]] (a.k.a. CPU), [[video card]]s, [[motherboard]] [[chipset]]s, and [[random-access memory|RAM]]. Most modern processors derive their effective operating speeds by multiplying a base clock (processor bus speed) by an internal multiplier within the processor (the [[CPU multiplier]]) to attain their final speed.\n\nComputer processors generally are overclocked by manipulating the [[CPU multiplier]] if that option is available, but the processor and other components can also be overclocked by increasing the base speed of the [[front-side bus|bus clock]]. Some systems allow additional tuning of other clocks (such as a [[Clock rate|system clock]]) that influence the bus clock speed that, again is multiplied by the processor to allow for finer adjustments of the final processor speed.\n\nMost [[OEM systems|OEM]] systems do not expose to the user the adjustments needed to change processor clock speed or voltage in the BIOS of the OEM's motherboard, which precludes overclocking (for warranty and support reasons). The same processor installed on a different motherboard offering adjustments will allow the user to change them.\n\nAny given component will ultimately stop operating reliably past a certain clock speed. Components will generally show some sort of malfunctioning behavior or other indication of compromised stability that alerts the user that a given speed is not stable, but there is always a possibility that a component will permanently fail without warning, even if voltages are kept within some pre-determined safe values. The maximum speed is determined by overclocking to the point of first instability, then accepting the last stable slower setting. Components are only guaranteed to operate correctly up to their rated values; beyond that different samples may have different overclocking potential. The end-point of a given overclock is determined by parameters such as available CPU multipliers, bus dividers, [[voltage]]s; the user's ability to manage thermal loads, cooling techniques; and several other factors of the individual devices themselves such as semiconductor clock and thermal tolerances, interaction with other components and the rest of the system.\n\n==Considerations==\nThere are several things to be considered when overclocking. First is to ensure that the component is supplied with adequate power at a voltage sufficient to operate at the new [[clock rate]]. Supplying the power with improper settings or applying excessive [[voltage]] can permanently damage a component.\n\nIn a professional production environment, overclocking is only likely to be used where the increase in speed justifies the cost of the expert support required, the possibly reduced reliability, the consequent effect on maintenance contracts and warranties, and the higher power consumption. If faster speed is required it is often cheaper when all costs are considered to buy faster hardware.\n\n=== Cooling ===\n{{Main|Computer cooling}}\n[[Image:Copper heat sink with pipes.jpg|thumb|High quality [[heat sink]]s are often made of [[copper]].]]\n\nAll [[Electrical network|electronic circuits]] produce heat generated by the movement of electric current. As clock frequencies in [[digital circuit]]s and voltage applied increase, the heat generated by components running at the higher performance levels also increases. The relationship between clock frequencies and [[thermal design power]] (TDP) are linear. However, there is a limit to the maximum frequency which is called a \"wall\". To overcome this issue, overclockers raise the chip voltage to increase the overclocking potential. Voltage increases power consumption and consequently heat generation significantly (proportionally to the square of the voltage in a linear circuit, for example); this requires more cooling to avoid damaging the hardware by overheating. In addition, some digital circuits slow down at high temperatures due to changes in [[MOSFET]] device characteristics. Conversely, the overclocker may decide to ''decrease'' the chip voltage while overclocking (a process known as undervolting), to reduce heat emissions while performance remains optimal.\n\nStock cooling systems are designed for the amount of power produced during non-overclocked use; overclocked circuits can require more cooling, such as by powerful [[fan (mechanical)|fans]], larger [[heat sink]]s, [[heat pipe]]s and [[water cooling]]. Mass, shape, and material all influence the ability of a heatsink to dissipate heat. Efficient heatsinks are often made entirely of [[copper]], which has high [[thermal conductivity]], but is expensive.<ref name=Wainner38>{{cite book | title = The Book of Overclocking | first = Scott | last = Wainner | author2 = Robert Richmond | page = [https://archive.org/details/bookofoverclocki0000wain/page/38 38] | isbn = 978-1-886411-76-0 | publisher = No Starch Press | year = 2003 | url = https://archive.org/details/bookofoverclocki0000wain/page/38 }}</ref> [[Aluminium]] is more widely used; it has good thermal characteristics, though not as good as copper, and is significantly cheaper. Cheaper materials such as steel do not have good thermal characteristics. [[Heat pipe]]s can be used to improve conductivity. Many heatsinks combine two or more materials to achieve a balance between performance and cost.<ref name=Wainner38/>\n\n[[File:DIY PC watercooling T-Line.JPG|Interior of a water-cooled computer, showing CPU [[water block]], tubing, and pump|left|thumb]]\n\nWater cooling carries [[waste heat]] to a [[radiator]]. [[Thermoelectric cooling]] devices which actually refrigerate using the [[Peltier effect]] can help with high [[thermal design power]] (TDP) processors made by Intel and AMD in the early twenty-first century. Thermoelectric cooling devices create temperature differences between two plates by running an [[electric current]] through the plates. This method of cooling is highly effective, but itself generates significant heat elsewhere which must be carried away, often by a convection-based heatsink or a [[water cooling#Computer usage|water cooling]] system.\n\n[[Image:2007TaipeiITMonth IntelOCLiveTest Overclocking-6.jpg|right|thumb|[[Liquid nitrogen]] may be used for cooling an overclocked system, when an extreme measure of cooling is needed.]]\n\nOther cooling methods are [[forced convection]] and [[phase transition]] cooling which is used in [[refrigerator]]s and can be adapted for computer use. [[Liquid nitrogen]], [[liquid helium]], and [[dry ice]] are used as coolants in extreme cases,<ref name=Wainner44>{{cite book | title = The Book of Overclocking | first = Scott | last = Wainner | author2 = Robert Richmond | page = [https://archive.org/details/bookofoverclocki0000wain/page/44 44] | isbn = 978-1-886411-76-0 | publisher = No Starch Press | year = 2003 | url = https://archive.org/details/bookofoverclocki0000wain/page/44 }}</ref> such as record-setting attempts or one-off experiments rather than cooling an everyday system. In June 2006, [[IBM]] and [[Georgia Institute of Technology]] jointly announced a new record in silicon-based chip [[clock rate]] (the rate a transistor can be switched at, not the CPU clock rate<ref>{{cite web|last=Stokes|first=Jon|title=IBM's 500GHz processor? Not so fast\u2026|url=https://arstechnica.com/uncategorized/2006/06/7117-2/|website=Ars Technica}}</ref>) above 500&nbsp;GHz, which was done by cooling the chip to {{Convert|4.5|K|C F|1|lk=on}} using liquid helium.<ref>{{cite web| last = Toon| first = John| date = 20 June 2006| url = http://gtresearchnews.gatech.edu/georgia-techibm-team-demonstrates-first-500-ghz-silicon-germanium-transistors/| title = Georgia Tech/IBM Announce New Chip Speed Record| publisher = Georgia Institute of Technology| accessdate = 2 February 2009| url-status = dead| archiveurl = https://web.archive.org/web/20100701230256/http://gtresearchnews.gatech.edu/georgia-techibm-team-demonstrates-first-500-ghz-silicon-germanium-transistors/| archivedate = 1 July 2010}}</ref> CPU Frequency World Record is 8.794&nbsp;GHz as of November 2012.<ref>{{cite web|url=http://valid.x86.fr/lpza4n|access-date=2018-03-02|title=AMD FX-8350 Breaks CPU Frequency World Record}}</ref> These extreme methods are generally impractical in the long term, as they require refilling reservoirs of vaporizing coolant, and [[condensation]] can form on chilled components.<ref name=Wainner44/> Moreover, [[silicon]]-based [[junction gate field-effect transistor]]s (JFET) will degrade below temperatures of roughly {{convert|100|K|C F|0}} and eventually cease to function or \"freeze out\" at {{convert|40|K|C F|0}} since the silicon ceases to be semiconducting,<ref>{{cite web | title = Extreme-Temperature Electronics: Tutorial \u2013 Part 3 | url = http://www.extremetemperatureelectronics.com/tutorial3.html | year = 2003 | accessdate = 2007-11-04}}</ref> so using extremely cold coolants may cause devices to fail.\n\nSubmersion cooling, used by the [[Cray-2]] [[supercomputer]], involves sinking a part of computer system directly into a chilled liquid that is thermally conductive but has low [[electrical conductivity]]. The advantage of this technique is that no condensation can form on components.<ref name=Wainner48/> A good submersion liquid is [[Fluorinert]] made by [[3M]], which is expensive. Another option is [[mineral oil]], but impurities such as those in water might cause it to conduct electricity.<ref name=Wainner48>{{cite book | title = The Book of Overclocking | first = Scott | last = Wainner | author2 = Robert Richmond | page = [https://archive.org/details/bookofoverclocki0000wain/page/48 48] | isbn = 978-1-886411-76-0 | publisher = No Starch Press | year = 2003 | url = https://archive.org/details/bookofoverclocki0000wain/page/48 }}</ref>\n\nAmateur overclocking enthusiasts have used a mixture of [[dry ice]] and [[acetone]] (or some other liquid with low freezing point, such as [[isopropyl alcohol]]).<ref>[https://www.techpowerup.com/forums/threads/overclocking-with-dry-ice.101545/]</ref>  This [[cooling bath]], often used in laboratries, achieves a temperature of \u221278 \u00b0C.<ref>[http://chemwiki.ucdavis.edu/VV_Lab_Techniques/Cooling_baths Cooling baths \u2013 ChemWiki]. Chemwiki.ucdavis.edu. Retrieved on 2013-06-17.</ref>  However, this practice is discouraged since acetone is extremely flammable and volatile.\n\n=== Stability and functional correctness ===\n\n{{See also| Stress testing#Hardware }}\n\nAs an overclocked component operates outside of the manufacturer's recommended operating conditions, it may function incorrectly, leading to system instability. Another risk is [[Reliability, availability and serviceability (computer hardware)|silent data corruption]] by undetected errors.  Such failures might never be correctly diagnosed and may instead be incorrectly attributed to software bugs in applications, [[device drivers]], or the operating system. Overclocked use may permanently damage components enough to cause them to misbehave (even under normal operating conditions) without becoming totally unusable.\n\nA large-scale 2011 field study of hardware faults causing a system crash for consumer PCs and laptops showed a four to 20 times increase (depending on CPU manufacturer) in system crashes due to CPU failure for overclocked computers over an eight-month period.<ref>{{cite web|url=http://research.microsoft.com/pubs/144888/eurosys84-nightingale.pdf|title=Cycles, cells and platters: an empirical analysis of hardware failures on a million consumer PCs. Proceedings of the sixth conference on Computer systems (EuroSys '11). pp 343-356|year=2011}}</ref>\n\nIn general, overclockers claim that testing can ensure that an overclocked system is stable and functioning correctly. Although software tools are available for testing hardware stability, it is generally impossible for any private individual to thoroughly test the functionality of a processor.<ref>{{cite web | citeseerx = 10.1.1.62.9086 | title = Coverage Metrics for Functional Validation of Hardware Designs | publisher = IEEE Design & Test of Computers | year = 2001 | first = Charles M. | last = Kurt Keutzer }}</ref> Achieving good [[fault coverage]] requires immense engineering effort; even with all of the resources dedicated to validation by manufacturers, faulty components and even design faults are not always detected.\n\nA particular \"stress test\" can verify only the functionality of the specific instruction sequence used in combination with the data and may not detect faults in those operations. For example, an arithmetic operation may produce the correct result but incorrect [[status register|flags]]; if the flags are not checked, the error will go undetected.\n\nTo further complicate matters, in process technologies such as [[silicon on insulator]] (SOI), devices display [[hysteresis]]&mdash;a circuit's performance is affected by the events of the past, so without carefully targeted tests it is possible for a particular sequence of state changes to work at overclocked rates in one situation but not another even if the voltage and temperature are the same.  Often, an overclocked system which passes stress tests experiences instabilities in other programs.<ref>{{cite web | url = http://blogs.msdn.com/oldnewthing/archive/2005/04/12/407562.aspx | first = Raymond | last = Chen | title = The Old New Thing: There's an awful lot of overclocking out there | date = April 12, 2005 | accessdate = 2007-03-17 }}</ref>\n\nIn overclocking circles, \"stress tests\" or \"torture tests\" are used to check for correct operation of a component.  These workloads are selected as they put a very high load on the component of interest (e.g. a graphically intensive application for testing video cards, or different math-intensive applications for testing general CPUs).  Popular stress tests include [[Prime95]], [[Lavalys|Everest]], [[Superpi]], OCCT, AIDA64, [[Linpack]] (via the LinX and IntelBurnTest [[GUI]]s), [[Sisoft Sandra|SiSoftware Sandra]], [[BOINC]], Intel Thermal Analysis Tool and [[Memtest86]].  The hope is that any functional-correctness issues with the overclocked component will show up during these tests, and if no errors are detected during the test, the component is then deemed \"stable\". Since fault coverage is important in [[Software testing|stability testing]], the tests are often run for long periods of time, hours or even days. An overclocked computer is sometimes described using the number of hours and the stability program used, such as \"prime 12 hours stable\".\n\n===Factors allowing overclocking===\nOverclockability arises in part due to the economics of the manufacturing processes of CPUs and other components. In many cases components are manufactured by the same process, and tested after manufacture to determine their actual maximum ratings. Components are then marked with a rating chosen by the market needs of the semiconductor manufacturer.  If [[Semiconductor device fabrication#Device test|manufacturing yield]] is high, more higher-rated components than required may be produced, and the manufacturer may mark and sell higher-performing components as lower-rated for marketing reasons.  In some cases, the true maximum rating of the component may exceed even the highest rated component sold.  Many devices sold with a lower rating may behave in all ways as higher-rated ones, while in the worst case operation at the higher rating may be more problematical.\n\nNotably, higher clocks must always mean greater waste heat generation, as semiconductors set to high must dump to ground more often.  In some cases, this means that the chief drawback of the overclocked part is far more heat dissipated than the maximums published by the manufacturer.  Pentium architect [[Bob Colwell]] calls overclocking an \"uncontrolled experiment in better-than-worst-case system operation\".<ref>{{cite journal|first1=Bob|last1=Colwell|title=The Zen of Overclocking|journal=[[Computer (magazine)|Computer]]|volume=37|issue=3|date=March 2004|pages=9\u201312|publisher=[[Institute of Electrical and Electronics Engineers]]|doi=10.1109/MC.2004.1273994}}</ref>\n\n=== Measuring effects of overclocking ===\n\n[[Benchmark (computing)|Benchmarks]] are used to evaluate performance, and they can become a kind of \"sport\" in which users compete for the highest scores.  As discussed above, stability and functional correctness may be compromised when overclocking, and meaningful benchmark results depend on the correct execution of the benchmark.  Because of this, benchmark scores may be qualified with stability and correctness notes (e.g. an overclocker may report a score, noting that the benchmark only runs to completion 1 in 5 times, or that signs of incorrect execution such as display corruption are visible while running the benchmark). A widely used test of stability is Prime95, which has built-in error checking that fails if the computer is unstable.\n\nUsing only the benchmark scores, it may be difficult to judge the difference overclocking makes to the overall performance of a computer. For example, some benchmarks test only one aspect of the system, such as memory [[Bandwidth (computing)|bandwidth]], without taking into consideration how higher [[clock rate]]s in this aspect will improve the system performance as a whole. Apart from demanding applications such as video encoding, high-demand [[database]]s and [[scientific computing]], [[memory bandwidth]] is typically not a [[bottleneck (engineering)|bottleneck]], so a great increase in memory bandwidth may be unnoticeable to a user depending on the applications used. Other benchmarks, such as [[3D Mark|3DMark]], attempt to replicate game conditions.\n\n== Manufacturer and vendor overclocking ==\n\nCommercial system builders or component resellers sometimes overclock to sell items at higher profit margins. The seller makes more money by overclocking lower-priced components which are found to operate correctly and selling equipment at prices appropriate for higher-rated components. While the equipment will normally operate correctly, this practice may be considered [[fraud]]ulent if the buyer is unaware of it.\n\nOverclocking is sometimes offered as a legitimate service or feature for consumers, in which a manufacturer or retailer tests the overclocking capability of processors, memory, video cards, and other hardware products. Several video card manufactures now offer factory-overclocked versions of their graphics accelerators, complete with a warranty, usually at a price intermediate between that of the standard product and a non-overclocked product of higher performance.\n\nIt is speculated that manufacturers implement overclocking prevention mechanisms such as [[CPU locking|CPU multiplier locking]] to prevent users from buying lower-priced items and overclocking them. These measures are sometimes marketed as a [[consumer protection]] benefit, but are often criticized by buyers.\n\nMany motherboards are sold, and advertised, with extensive facilities for overclocking implemented in hardware and controlled by [[BIOS]] settings.<ref>[http://www.asus.com/Motherboards/AMD_AM3Plus/M5A78LUSB3/ Web page for a typical motherboard claiming overclocking support]</ref>\n\n== CPU multiplier locking ==\n\n'''CPU multiplier locking''' is the process of permanently setting a [[Central processing unit|CPU]]'s [[clock multiplier]].  [[AMD]] CPUs are unlocked in early editions of a model and locked in later editions, but nearly all [[Intel]] CPUs are locked and recent models are very resistant to unlocking to prevent overclocking by users. AMD ships unlocked CPUs with their Opteron, FX, Ryzen and Black Series line-up, while Intel uses the monikers of \"Extreme Edition\" and \"K-Series.\" Intel usually has one or two Extreme Edition CPUs on the market as well as X series and K series CPUs analogous to AMD's Black Edition. AMD has the majority of their desktop range in a Black Edition.\n\nUsers usually unlock CPUs to allow overclocking, but sometimes to allow for [[underclocking]] in order to maintain the [[front side bus]] speed (on older CPUs) compatibility with certain motherboards. Unlocking generally invalidates the manufacturer's warranty, and mistakes can cripple or destroy a CPU. Locking a chip's clock multiplier does not necessarily prevent users from overclocking, as the speed of the front-side bus or PCI multiplier (on newer CPUs) may still be changed to provide a performance increase. AMD Athlon and Athlon XP CPUs are generally unlocked by connecting bridges ([[jumper (computing)|jumper]]-like points) on the top of the CPU with [[electrical conduction|conductive]] paint or [[Graphite|pencil lead]].  Other CPU models may require different procedures.\n\nIncreasing front-side bus and/or northbridge/PCI clocks can overclock locked CPUs, but this throws many system frequencies out of sync, since the RAM and PCI frequencies are modified as well.\n\nOne of the easiest ways to unlock older AMD Athlon XP CPUs was called the ''pin mod'' method, because it was possible to unlock the CPU without permanently modifying bridges. A user could simply put one wire (or some more for a new multiplier/Vcore) into the socket to unlock the CPU. More recently however, notably with Intel's Skylake architecture, Intel had a bug with the Skylake (6th gen Core) processors where the base clock could be increased past 102.7 MHz, however functionality of certain features would not work. Intel intended to block base clock (BCLK) overclocking of locked processors when designing the Skylake architecture to prevent consumers from purchasing cheaper components and overclocking to previously-unseen heights (since the CPU's BCLK was no longer tied to the PCI buses), however for LGA1151, the 6th generation \"Skylake\" processors were able to be overclocked past 102.7 MHz (which was the intended limit by Intel, and was later mandated through later BIOS updates). All other unlocked processors from LGA1151 and v2 (including 7th, 8th, and 9th generation) and BGA1440 allow for BCLK overclocking (as long as the OEM allows it), while all other locked processors from 7th, 8th, and 9th gen were not able to go past 102.7 MHz on the BCLK.\n\n== Advantages ==\n\n{{Original research|section|date=December 2011}}\n* Higher '''performance''' in games, en-/decoding, video editing and system tasks at no additional direct monetary expense, but with increased electrical consumption and thermal output.\n* System '''optimization''': Some systems have \"[[Bottleneck (software)|bottlenecks]]\", where small overclocking of one component can help realize the full potential of another component to a greater percentage than when just the limiting hardware itself is overclocked. For instance: many [[motherboard]]s with [[Athlon 64|AMD Athlon 64]] processors limit the clock rate of four units of RAM to 333 [[Hertz|MHz]]. However, the memory performance is computed by dividing the processor clock rate (which is a base number times a [[CPU multiplier]], for instance 1.8&nbsp;GHz is most likely 9\u00d7200&nbsp;MHz) by a fixed [[integer]] such that, at a stock clock rate, the RAM would run at a clock rate near 333&nbsp;MHz. Manipulating elements of how the processor clock rate is set (usually adjusting the multiplier), it is often possible to overclock the processor a small amount, around 5-10%, and gain a small increase in RAM clock rate and/or reduction in RAM latency timings.\n* It can be '''cheaper''' to purchase a lower performance component and overclock it to the clock rate of a more expensive component.\n* Extending life on older equipment (through underclocking/undervolting).\n\n==Disadvantages==\n\n=== General ===\n\n{{Original       research|section|date=December 2011}}\n* Higher [[clock rate]]s and voltages increase '''power consumption''', also increasing '''electricity cost''' and '''heat production'''. The additional heat increases the ambient air temperature within the system case, which may affect other components. The hot air blown out of the case heats the room it's in.\n* Fan '''noise''': High-performance fans running at maximum speed used for the required degree of cooling of an overclocked machine can be noisy, some producing 50&nbsp;[[Decibel#Acoustics|dB]] or more of noise. When maximum cooling is not required, in any equipment, fan speeds can be reduced below the maximum: fan noise has been found to be roughly proportional to the fifth power of fan speed; halving speed reduces noise by about 15&nbsp;dB.<ref>[http://www.hse.gov.uk/pubns/top10noise.pdf UK Health and Safety Executive: Top 10 noise control techniques]</ref> Fan noise can be reduced by design improvements, e.g. with aerodynamically optimized blades for smoother airflow, reducing noise to around 20&nbsp;dB at approximately 1 metre{{Citation needed|date=December 2011}} or larger fans rotating more slowly, which produce less noise than smaller, faster fans with the same airflow. Acoustical insulation inside the case e.g. acoustic foam can reduce noise. Additional cooling methods which do not use fans can be used, such as liquid and phase-change cooling.\n* An overclocked computer may become '''unreliable'''. For example: [[Microsoft Windows]] may appear to work with no problems, but when it is re-installed or upgraded, error messages may be received such as a \"file copy error\" during Windows Setup.<ref>[http://support.microsoft.com/kb/310064/en-us Article ID: 310064 \u2013 Last Review: May 7, 2007 \u2013 Revision: 6.2 How to troubleshoot problems during installation when you upgrade from Windows 98 or Windows Millennium Edition to Windows XP]</ref> Microsoft says this of errors in upgrading to Windows XP: \"Your computer [may be] over-clocked.\" Because installing Windows is very memory-intensive, decoding errors may occur when files are extracted from the Windows XP CD-ROM.\n* The '''lifespan''' of semiconductor components may be reduced by increased voltages and heat.\n* Warranties may be voided by overclocking.\n\n=== Risks of overclocking ===\n\n* Increasing the operation frequency of a component will usually increase its thermal output in a linear fashion, while an increase in voltage usually causes heat to increase exponentially. Excessive voltages or improper cooling may cause chip temperatures to rise to dangerous levels, causing the chip to be damaged or destroyed.\n* Exotic cooling methods used to facilitate overclocking such as water cooling are more likely to cause damage if they malfunction. Sub-ambient cooling methods such as [[Computer cooling#Phase-change cooling|phase-change cooling]] or [[liquid nitrogen]] will cause water [[condensation]], which will cause electrical damage unless controlled; some methods include using kneaded erasers or shop towels to catch the condensation.\n\n=== Limitations ===\n\nOverclocking components can only be of noticeable benefit if the component is on the [[Critical path method|critical path]] for a process, if it is a bottleneck. If disk access or the speed of an [[Internet]] connection limit the speed of a process, a 20% increase in processor speed is unlikely to be noticed, however there are some scenarios where increasing the clock speed of a processor actually allows an SSD to be read and written to faster.. Overclocking a CPU will not noticeably benefit a game when a graphics card's performance is the \"botleneck\" of the game.\n\n== Graphics cards ==\n\n[[File:Bfg geforce 6800 gs oc.jpg|thumb|200px|right|The BFG GeForce 6800GSOC ships with higher memory and [[clock rate]]s than the standard 6800GS.]]\nGraphics cards can also be overclocked. There are [[utility software|utilities]] to achieve this, such as [[EVGA Corporation|EVGA]]'s Precision, [[RivaTuner]], [[Advanced Micro Devices|AMD]] Overdrive (on [[Advanced Micro Devices|AMD]] cards only), [[Micro-Star International|MSI]] Afterburner, Zotac Firestorm, and the [[PEG Link Mode]] on [[Asus]] [[motherboard]]s. Overclocking a GPU will often yield a marked increase in performance in synthetic benchmarks, usually reflected in game performance<ref>[http://www.altesc.net/2013/06/15/gtx-780-overclocking/ Alt+Esc | GTX 780 Overclocking Guide<!-- Bot generated title -->]</ref>. It is sometimes possible to see that a graphics card is being pushed beyond its limits before any permanent damage is done by observing on-screen artifacts or unexpected system crashes. It is common to run into one of those problems when overclocking graphics cards; both symptoms at the same time usually means that the card is severely pushed beyond its heat, [[clock rate]], and/or voltage limits, however if seen when not overclocked, they indicate a faulty card. After a reboot, video settings are reset to standard values stored in the graphics card firmware, and the maximum [[clock rate]] of that specific card is now deducted.\n\nSome overclockers apply a [[potentiometer]] to the graphics card to manually adjust the voltage (which usually invalidates the warranty). This allows for finer adjustments, as overclocking software for graphics cards can only go so far. Excessive voltage increases may damage or destroy components on the graphics card or the entire graphics card itself (practically speaking).\n\n=== Alternatives ===\n\nFlashing and unlocking can be used to improve the performance of a [[Graphics card|video card]], without technically overclocking (but is much riskier than overclocking just through software).\n\n'''''Flashing''''' refers to using the [[firmware]] of a different card with the same (or sometimes similar) core and compatible firmware, effectively making it a higher model card; it can be difficult, and may be irreversible. Sometimes [[Computer software|standalone software]] to modify the firmware files can be found, e.g. [[NiBiTor]] (GeForce 6/7 series are well regarded in this aspect), without using firmware for a better model video card. For example, video cards with 3D accelerators (most, {{As of|2011|lc=on}}) have two voltage and [[clock rate]] settings, one for 2D and one for 3D, but were designed to operate with ''three'' voltage stages, the third being somewhere between the aforementioned two, serving as a fallback when the card overheats or as a middle-stage when going from 2D to 3D operation mode. Therefore, it could be wise to set this middle-stage prior to \"serious\" overclocking, specifically because of this fallback ability; the card can drop down to this [[clock rate]], reducing by a few (or sometimes a few dozen, depending on the setting) percent of its efficiency and cool down, without dropping out of 3D mode (and afterwards return to the desired high performance clock and voltage settings).\n\nSome cards have abilities not directly connected with overclocking. For example, Nvidia's [[GeForce|GeForce 6600GT]] (AGP flavor) has a temperature monitor used internally by the card, invisible to the user if standard firmware is used. Modifying the firmware can display a 'Temperature' tab.\n\n'''''Unlocking''''' refers to enabling extra [[Graphics pipeline|pipelines]] or [[pixel shader]]s.  The [[GeForce 6 Series|6800LE]], the [[GeForce 6 Series|6800GS]] and [[GeForce 6 Series|6800]] ([[Accelerated Graphics Port|AGP]] models only) were some of the first cards to benefit from unlocking.  While these  models have either 8 or 12 pipes enabled, they share the same 16x6 [[Graphics processing unit|GPU]] core as a [[GeForce 6 Series|6800GT]] or Ultra, but  pipelines and shaders beyond those specified are disabled; the GPU may be fully functional, or may have been found to have faults which do not affect operation at the lower specification. GPUs found to be fully functional can be unlocked successfully, although it is not possible to be sure that there are undiscovered faults; in the worst case the card may become [[Brick (electronics)|permanently unusable]].\n\n== History ==\n\nOverclocked processors first became commercially available in 1983, when AMD sold an overclocked version of the [[Intel 8088]] CPU. In 1984, some consumers were overclocking IBM's version of the [[Intel 80286]] CPU by replacing the clock crystal.\n\n== See also ==\n\n{{Portal|Electronics}}\n\n{{Div col|colwidth=20em}}\n* [[Clock rate]]\n* [[CPU-Z]]\n* [[Double boot]]\n* [[Dynamic voltage scaling]]\n* [[POWER8 on-chip controller]] (OCC)\n* [[Serial presence detect]] (SPD)\n* [[Super PI]]\n* [[Underclocking]]\n* [[UNIVAC I#Instructions and data|UNIVAC I Overdrive, 1952 unofficial modification]]\n{{div col end}}\n\n== References==\n\n{{Reflist|33em}}\n;Notes\n*{{cite journal | first = Bob | last = Colwell | authorlink = Bob Colwell | title = The Zen of Overclocking | journal =  Computer | volume = 37 | issue = 3 | pages = 9\u201312 |date=March 2004 | doi = 10.1109/MC.2004.1273994}}\n\n== External links ==\n\n{{wikibooks|How To Build A Computer|Optimizing and Overclocking}}\n{{Commons category|Overclocking}}\n<!--PLEASE NO FORUMS, LINKS WITHOUT DISCUSSION OR COMMERCIAL SITES, THEY WILL BE REMOVED-->\n* [http://www.ocinside.de/html/workshop/amd_socketa_overclock.html OverClocked inside]\n* [http://www.wikihow.com/Overclock-a-PC How to Overclock a PC], WikiHow\n* [http://www.ethernetworks.de/imac_g4_usb2_overclocking.html Overclocking guide for the Apple iMac G4 main logic board]\n\n=== Overclocking and benchmark databases ===\n\n*[http://www.xtremesystems.org OC Database of all PC hardware for the past decade] (applications, modifications and more)\n*[http://www.hwbot.org HWBOT: Worldwide Overclocking League \u2013 Overclocking competition and data]\n*[http://www.forum-inside.de/cgi-bin/forum/ocdatabase_e.cgi Comprehensive CPU OC Database]\n* [https://web.archive.org/web/20110624071633/http://imperiogamer.com/index.php/juegos/noticias/item/2367-segunda-convencion-nacional-de-oc-overclocking-extremo- Segunda Convencion Nacional de OC: Overclocking Extremo] by Imperio Gamer\n*[http://www.hwmaster.com/forum/tools-utili-per-loverclock-t168.html Tool for overclock]\n{{Computer processor power management technologies}}\n\n[[Category:Computer hardware tuning]]\n[[Category:Clock signal]]\n[[Category:Hobbies]]\n[[Category:IBM PC compatibles]]\n", "text_old": "''Not to be confused with [[Odometer#Clocking.2FBusting miles and legality|overclocking (mileometer/odometer)]]''\n\n[[Image:Overclock.jpg|thumb|upright=1.5|Overclocking [[BIOS]] setup on an ABIT NF7-S [[motherboard]] with an AMD [[Athlon&nbsp;XP]] processor. [[Front side bus]] (FSB) frequency (external clock) has been increased from 133&nbsp;[[Hertz|MHz]] to 148&nbsp;MHz, and the CPU [[clock multiplier]] factor has been changed from 13.5 to 16.5. This corresponds to an overclocking of the FSB by 11.3% and of the CPU by 36%.]]\n\nIn [[computing]], '''overclocking''' is the practice of increasing the [[clock rate]] of a computer to exceed that certified by the manufacturer. Commonly operating voltage is also increased to maintain a component's operational stability at accelerated speeds. [[Semiconductor device]]s operated at higher frequencies and voltages increase power consumption and heat.<ref>{{cite web|url=https://software.intel.com/en-us/blogs/2014/02/19/why-has-cpu-frequency-ceased-to-grow|author= Victoria Zhislina|date=2014-02-19|title=Why has CPU frequency ceased to grow?|publisher=Intel}}</ref> An overclocked device may be unreliable or fail completely if the additional heat load is not removed or power delivery components cannot meet increased power demands. Many device warranties state that overclocking and/or over-specification voids any warranty, however there are an increasing number of manufacturers that will allow overclocking as long as performed [relatively] safely.\n\n== Overview ==\n\nThe purpose of overclocking is to increase the operating speed of a given component. Normally, on modern systems, the target of overclocking is increasing the performance of a major chip or subsystem, such as the main processor or graphics controller, but other components, such as system memory ([[Random-access memory|RAM]]) or [[Bus (computing)|system buses]] (generally on the [[motherboard]]), are commonly involved. The trade-offs are an increase in power consumption (heat), fan noise (cooling), and shortened lifespan for the targeted components. Most components are designed with a margin of safety to deal with operating conditions outside of a manufacturer's control; examples are ambient temperature and fluctuations in operating voltage. Overclocking techniques in general aim to trade this safety margin by setting the device to run in the higher end of the margin, with the understanding that temperature and voltage must be more strictly monitored and controlled by the user. Examples are that operating temperature would need to be more strictly controlled with increased cooling, as the part will be less tolerant of increased temperatures at the higher speeds. Also base operating voltage may be increased to compensate for unexpected voltage drops and to strengthen signalling and timing signals, as low-voltage excursions are more likely to cause malfunctions at higher operating speeds.\n\nWhile most modern devices are fairly tolerant of overclocking, all devices have finite limits. Generally for any given voltage most parts will have a maximum \"stable\" speed where they still operate correctly. Past this speed the device starts giving incorrect results, which can cause malfunctions and sporadic behavior in any system depending on it. While in a PC context the usual result is a system crash, more subtle errors can go undetected, which over a long enough time can give unpleasant surprises such as [[data corruption]] (incorrectly calculated results, or worse ''writing to storage'' incorrectly) or the system failing only during certain specific tasks (general usage such as internet browsing and [[word processing]] appear fine, but any application wanting advanced graphics crashes the system).\n\nAt this point an increase in operating voltage of a part may allow more headroom for further increases in clock speed, but the increased voltage can also significantly increase heat output, as well as shorten the lifespan further. At some point there will be a limit imposed by the ability to supply the device with sufficient power, the user's ability to cool the part, and the device's own maximum voltage tolerance before it achieves [[Failure of electronic components|destructive failure]]. Overzealous use of voltage and/or inadequate cooling can rapidly degrade a device's performance to the point of failure, or in extreme cases outright [[Thermal runaway|destroy it]].\n\nThe speed gained by overclocking depends largely upon the applications and workloads being run on the system, and what components are being overclocked by the user; [[Benchmark (computing)|benchmark]]s for different purposes are published.\n\n===Underclocking===\n{{Main|Underclocking}}\nConversely, the primary goal of [[underclocking]] is to reduce power consumption and the resultant heat generation of a device, with the trade-offs being lower clock speeds and reductions in performance. Reducing the cooling requirements needed to keep hardware at a given operational temperature has knock-on benefits such as lowering the number and speed of fans to allow [[Quiet PC|quieter operation]], and in mobile devices increase the length of battery life per charge. Some manufacturers underclock components of battery-powered equipment to improve battery life, or implement systems that detect when a device is operating under battery power and reduce clock frequency accordingly.\n\nUnderclocking is almost always involved in the latter stages of [[Undervolting]], which seeks to find the highest clock speed that a processor will stably operate at a given voltage. That is, while overclocking seeks to maximize clock speed with temperature and power as constraints, underclocking seeks to find the highest clock speed that a device can reliably operate at a fixed, arbitrary power limit. A given device may operate correctly at its stock speed even when undervolted, in which case underclocking would only be employed after further reductions in voltage finally destabilizes the part. At that point the user would need to determine if the last working voltage and speed have satisfactorily lowered power consumption for their needs \u2013 if not then performance must be sacrificed, a lower clock is chosen (the underclock) and testing at progressively lower voltages would continue from that point. A lower bound is where the device itself fails to function and/or the supporting circuitry cannot reliably communicate with the part.\n\nUnderclocking and undervolting would be attempted on a desktop system to have it operate silently (such as for a home entertainment center) while potentially offering higher performance than currently offered by low-voltage processor offerings. This would use a \"standard-voltage\" part and attempt to run with lower voltages (while attempting to keep the desktop speeds) to meet an acceptable performance/noise target for the build. This was also attractive as using a \"standard voltage\" processor in a \"low voltage\" application avoided paying the traditional price premium for an officially certified low voltage version. However again like overclocking there is no guarantee of success, and the builder's time researching given system/processor combinations and especially the time and tedium of performing many iterations of stability testing need to be considered. The usefulness of underclocking (again like overclocking) is determined by what processor offerings, prices, and availability are at the specific time of the build. Underclocking is also sometimes used when [[troubleshooting]].\n\n===Enthusiast culture===\n\nOverclocking has become more accessible with motherboard makers offering overclocking as a marketing feature on their mainstream product lines. However, the practice is embraced more by [[enthusiast computing|enthusiasts]] than professional users, as overclocking carries a risk of reduced reliability, accuracy and damage to data and equipment. Additionally, most manufacturer warranties and service agreements do not cover overclocked components nor any incidental damages caused by their use. While overclocking can still be an option for increasing personal computing capacity, and thus workflow productivity for professional users, the importance of stability testing components thoroughly ''before'' employing them into a production environment cannot be overstated.\n\nOverclocking offers several draws for overclocking enthusiasts. Overclocking allows testing of components at speeds not currently offered by the manufacturer, or at speeds only officially offered on specialized, higher-priced versions of the product. A general trend in the computing industry is that new technologies tend to debut in the high-end market first, then later trickle down to the performance and mainstream market. If the high-end part only differs by an increased clock speed, an enthusiast can attempt to overclock a mainstream part to simulate the high-end offering. This can give insight on how over-the-horizon technologies will perform before they are officially available on the mainstream market, which can be especially helpful for other users considering if they should plan ahead to purchase or upgrade to the new feature when it is officially released.\n\nSome hobbyists enjoy building, tuning, and \"Hot-Rodding\" their systems in competitive benchmarking competitions, competing with other like-minded users for high scores in standardized computer benchmark suites. Others will purchase a low-cost model of a component in a given product line, and attempt to overclock that part to match a more expensive model's stock performance. Another approach is overclocking older components to attempt to keep pace with increasing [[system requirements]] and extend the useful service life of the older part or at least delay a purchase of new hardware solely for performance reasons. Another rationale for overclocking older equipment is even if overclocking stresses equipment to the point of failure earlier, little is lost as it is already [[Depreciation|depreciated]], and would have needed to be replaced in any case.<ref>{{cite book | title = The Book of Overclocking | first = Scott | last = Wainner | author2 = Robert Richmond | pages = [https://archive.org/details/bookofoverclocki0000wain/page/1 1\u20132] | isbn = 978-1-886411-76-0 | publisher = No Starch Press | year = 2003 | url = https://archive.org/details/bookofoverclocki0000wain/page/1 }}</ref>\n\n===Components===\n\nTechnically any component that uses a timer (or clock) to synchronize its internal operations can be overclocked. Most efforts for computer components however focus on specific components, such as, [[Central processing unit|processors]] (a.k.a. CPU), [[video card]]s, [[motherboard]] [[chipset]]s, and [[random-access memory|RAM]]. Most modern processors derive their effective operating speeds by multiplying a base clock (processor bus speed) by an internal multiplier within the processor (the [[CPU multiplier]]) to attain their final speed.\n\nComputer processors generally are overclocked by manipulating the [[CPU multiplier]] if that option is available, but the processor and other components can also be overclocked by increasing the base speed of the [[front-side bus|bus clock]]. Some systems allow additional tuning of other clocks (such as a [[Clock rate|system clock]]) that influence the bus clock speed that, again is multiplied by the processor to allow for finer adjustments of the final processor speed.\n\nMost [[OEM systems|OEM]] systems do not expose to the user the adjustments needed to change processor clock speed or voltage in the BIOS of the OEM's motherboard, which precludes overclocking (for warranty and support reasons). The same processor installed on a different motherboard offering adjustments will allow the user to change them.\n\nAny given component will ultimately stop operating reliably past a certain clock speed. Components will generally show some sort of malfunctioning behavior or other indication of compromised stability that alerts the user that a given speed is not stable, but there is always a possibility that a component will permanently fail without warning, even if voltages are kept within some pre-determined safe values. The maximum speed is determined by overclocking to the point of first instability, then accepting the last stable slower setting. Components are only guaranteed to operate correctly up to their rated values; beyond that different samples may have different overclocking potential. The end-point of a given overclock is determined by parameters such as available CPU multipliers, bus dividers, [[voltage]]s; the user's ability to manage thermal loads, cooling techniques; and several other factors of the individual devices themselves such as semiconductor clock and thermal tolerances, interaction with other components and the rest of the system.\n\n==Considerations==\nThere are several things to be considered when overclocking. First is to ensure that the component is supplied with adequate power at a voltage sufficient to operate at the new [[clock rate]]. Supplying the power with improper settings or applying excessive [[voltage]] can permanently damage a component.\n\nIn a professional production environment, overclocking is only likely to be used where the increase in speed justifies the cost of the expert support required, the possibly reduced reliability, the consequent effect on maintenance contracts and warranties, and the higher power consumption. If faster speed is required it is often cheaper when all costs are considered to buy faster hardware.\n\n=== Cooling ===\n{{Main|Computer cooling}}\n[[Image:Copper heat sink with pipes.jpg|thumb|High quality [[heat sink]]s are often made of [[copper]].]]\n\nAll [[Electrical network|electronic circuits]] produce heat generated by the movement of electric current. As clock frequencies in [[digital circuit]]s and voltage applied increase, the heat generated by components running at the higher performance levels also increases. The relationship between clock frequencies and [[thermal design power]] (TDP) are linear. However, there is a limit to the maximum frequency which is called a \"wall\". To overcome this issue, overclockers raise the chip voltage to increase the overclocking potential. Voltage increases power consumption and consequently heat generation significantly (proportionally to the square of the voltage in a linear circuit, for example); this requires more cooling to avoid damaging the hardware by overheating. In addition, some digital circuits slow down at high temperatures due to changes in [[MOSFET]] device characteristics. Conversely, the overclocker may decide to ''decrease'' the chip voltage while overclocking (a process known as undervolting), to reduce heat emissions while performance remains optimal.\n\nStock cooling systems are designed for the amount of power produced during non-overclocked use; overclocked circuits can require more cooling, such as by powerful [[fan (mechanical)|fans]], larger [[heat sink]]s, [[heat pipe]]s and [[water cooling]]. Mass, shape, and material all influence the ability of a heatsink to dissipate heat. Efficient heatsinks are often made entirely of [[copper]], which has high [[thermal conductivity]], but is expensive.<ref name=Wainner38>{{cite book | title = The Book of Overclocking | first = Scott | last = Wainner | author2 = Robert Richmond | page = [https://archive.org/details/bookofoverclocki0000wain/page/38 38] | isbn = 978-1-886411-76-0 | publisher = No Starch Press | year = 2003 | url = https://archive.org/details/bookofoverclocki0000wain/page/38 }}</ref> [[Aluminium]] is more widely used; it has good thermal characteristics, though not as good as copper, and is significantly cheaper. Cheaper materials such as steel do not have good thermal characteristics. [[Heat pipe]]s can be used to improve conductivity. Many heatsinks combine two or more materials to achieve a balance between performance and cost.<ref name=Wainner38/>\n\n[[File:DIY PC watercooling T-Line.JPG|Interior of a water-cooled computer, showing CPU [[water block]], tubing, and pump|left|thumb]]\n\nWater cooling carries [[waste heat]] to a [[radiator]]. [[Thermoelectric cooling]] devices which actually refrigerate using the [[Peltier effect]] can help with high [[thermal design power]] (TDP) processors made by Intel and AMD in the early twenty-first century. Thermoelectric cooling devices create temperature differences between two plates by running an [[electric current]] through the plates. This method of cooling is highly effective, but itself generates significant heat elsewhere which must be carried away, often by a convection-based heatsink or a [[water cooling#Computer usage|water cooling]] system.\n\n[[Image:2007TaipeiITMonth IntelOCLiveTest Overclocking-6.jpg|right|thumb|[[Liquid nitrogen]] may be used for cooling an overclocked system, when an extreme measure of cooling is needed.]]\n\nOther cooling methods are [[forced convection]] and [[phase transition]] cooling which is used in [[refrigerator]]s and can be adapted for computer use. [[Liquid nitrogen]], [[liquid helium]], and [[dry ice]] are used as coolants in extreme cases,<ref name=Wainner44>{{cite book | title = The Book of Overclocking | first = Scott | last = Wainner | author2 = Robert Richmond | page = [https://archive.org/details/bookofoverclocki0000wain/page/44 44] | isbn = 978-1-886411-76-0 | publisher = No Starch Press | year = 2003 | url = https://archive.org/details/bookofoverclocki0000wain/page/44 }}</ref> such as record-setting attempts or one-off experiments rather than cooling an everyday system. In June 2006, [[IBM]] and [[Georgia Institute of Technology]] jointly announced a new record in silicon-based chip [[clock rate]] (the rate a transistor can be switched at, not the CPU clock rate<ref>{{cite web|last=Stokes|first=Jon|title=IBM's 500GHz processor? Not so fast\u2026|url=https://arstechnica.com/uncategorized/2006/06/7117-2/|website=Ars Technica}}</ref>) above 500&nbsp;GHz, which was done by cooling the chip to {{Convert|4.5|K|C F|1|lk=on}} using liquid helium.<ref>{{cite web| last = Toon| first = John| date = 20 June 2006| url = http://gtresearchnews.gatech.edu/georgia-techibm-team-demonstrates-first-500-ghz-silicon-germanium-transistors/| title = Georgia Tech/IBM Announce New Chip Speed Record| publisher = Georgia Institute of Technology| accessdate = 2 February 2009| url-status = dead| archiveurl = https://web.archive.org/web/20100701230256/http://gtresearchnews.gatech.edu/georgia-techibm-team-demonstrates-first-500-ghz-silicon-germanium-transistors/| archivedate = 1 July 2010}}</ref> CPU Frequency World Record is 8.794&nbsp;GHz as of November 2012.<ref>{{cite web|url=http://valid.x86.fr/lpza4n|access-date=2018-03-02|title=AMD FX-8350 Breaks CPU Frequency World Record}}</ref> These extreme methods are generally impractical in the long term, as they require refilling reservoirs of vaporizing coolant, and [[condensation]] can form on chilled components.<ref name=Wainner44/> Moreover, [[silicon]]-based [[junction gate field-effect transistor]]s (JFET) will degrade below temperatures of roughly {{convert|100|K|C F|0}} and eventually cease to function or \"freeze out\" at {{convert|40|K|C F|0}} since the silicon ceases to be semiconducting,<ref>{{cite web | title = Extreme-Temperature Electronics: Tutorial \u2013 Part 3 | url = http://www.extremetemperatureelectronics.com/tutorial3.html | year = 2003 | accessdate = 2007-11-04}}</ref> so using extremely cold coolants may cause devices to fail.\n\nSubmersion cooling, used by the [[Cray-2]] [[supercomputer]], involves sinking a part of computer system directly into a chilled liquid that is thermally conductive but has low [[electrical conductivity]]. The advantage of this technique is that no condensation can form on components.<ref name=Wainner48/> A good submersion liquid is [[Fluorinert]] made by [[3M]], which is expensive. Another option is [[mineral oil]], but impurities such as those in water might cause it to conduct electricity.<ref name=Wainner48>{{cite book | title = The Book of Overclocking | first = Scott | last = Wainner | author2 = Robert Richmond | page = [https://archive.org/details/bookofoverclocki0000wain/page/48 48] | isbn = 978-1-886411-76-0 | publisher = No Starch Press | year = 2003 | url = https://archive.org/details/bookofoverclocki0000wain/page/48 }}</ref>\n\nAmateur overclocking enthusiasts have used a mixture of [[dry ice]] and [[acetone]] (or some other liquid with low freezing point, such as [[isopropyl alcohol]]).<ref>[https://www.techpowerup.com/forums/threads/overclocking-with-dry-ice.101545/]</ref>  This [[cooling bath]], often used in laboratries, achieves a temperature of \u221278 \u00b0C.<ref>[http://chemwiki.ucdavis.edu/VV_Lab_Techniques/Cooling_baths Cooling baths \u2013 ChemWiki]. Chemwiki.ucdavis.edu. Retrieved on 2013-06-17.</ref>  However, this practice is discouraged since acetone is extremely flammable and volatile.\n\n=== Stability and functional correctness ===\n\n{{See also| Stress testing#Hardware }}\n\nAs an overclocked component operates outside of the manufacturer's recommended operating conditions, it may function incorrectly, leading to system instability. Another risk is [[Reliability, availability and serviceability (computer hardware)|silent data corruption]] by undetected errors.  Such failures might never be correctly diagnosed and may instead be incorrectly attributed to software bugs in applications, [[device drivers]], or the operating system. Overclocked use may permanently damage components enough to cause them to misbehave (even under normal operating conditions) without becoming totally unusable.\n\nA large-scale 2011 field study of hardware faults causing a system crash for consumer PCs and laptops showed a four to 20 times increase (depending on CPU manufacturer) in system crashes due to CPU failure for overclocked computers over an eight-month period.<ref>{{cite web|url=http://research.microsoft.com/pubs/144888/eurosys84-nightingale.pdf|title=Cycles, cells and platters: an empirical analysis of hardware failures on a million consumer PCs. Proceedings of the sixth conference on Computer systems (EuroSys '11). pp 343-356|year=2011}}</ref>\n\nIn general, overclockers claim that testing can ensure that an overclocked system is stable and functioning correctly. Although software tools are available for testing hardware stability, it is generally impossible for any private individual to thoroughly test the functionality of a processor.<ref>{{cite web | citeseerx = 10.1.1.62.9086 | title = Coverage Metrics for Functional Validation of Hardware Designs | publisher = IEEE Design & Test of Computers | year = 2001 | first = Charles M. | last = Kurt Keutzer }}</ref> Achieving good [[fault coverage]] requires immense engineering effort; even with all of the resources dedicated to validation by manufacturers, faulty components and even design faults are not always detected.\n\nA particular \"stress test\" can verify only the functionality of the specific instruction sequence used in combination with the data and may not detect faults in those operations. For example, an arithmetic operation may produce the correct result but incorrect [[status register|flags]]; if the flags are not checked, the error will go undetected.\n\nTo further complicate matters, in process technologies such as [[silicon on insulator]] (SOI), devices display [[hysteresis]]&mdash;a circuit's performance is affected by the events of the past, so without carefully targeted tests it is possible for a particular sequence of state changes to work at overclocked rates in one situation but not another even if the voltage and temperature are the same.  Often, an overclocked system which passes stress tests experiences instabilities in other programs.<ref>{{cite web | url = http://blogs.msdn.com/oldnewthing/archive/2005/04/12/407562.aspx | first = Raymond | last = Chen | title = The Old New Thing: There's an awful lot of overclocking out there | date = April 12, 2005 | accessdate = 2007-03-17 }}</ref>\n\nIn overclocking circles, \"stress tests\" or \"torture tests\" are used to check for correct operation of a component.  These workloads are selected as they put a very high load on the component of interest (e.g. a graphically intensive application for testing video cards, or different math-intensive applications for testing general CPUs).  Popular stress tests include [[Prime95]], [[Lavalys|Everest]], [[Superpi]], OCCT, AIDA64, [[Linpack]] (via the LinX and IntelBurnTest [[GUI]]s), [[Sisoft Sandra|SiSoftware Sandra]], [[BOINC]], Intel Thermal Analysis Tool and [[Memtest86]].  The hope is that any functional-correctness issues with the overclocked component will show up during these tests, and if no errors are detected during the test, the component is then deemed \"stable\". Since fault coverage is important in [[Software testing|stability testing]], the tests are often run for long periods of time, hours or even days. An overclocked computer is sometimes described using the number of hours and the stability program used, such as \"prime 12 hours stable\".\n\n===Factors allowing overclocking===\nOverclockability arises in part due to the economics of the manufacturing processes of CPUs and other components. In many cases components are manufactured by the same process, and tested after manufacture to determine their actual maximum ratings. Components are then marked with a rating chosen by the market needs of the semiconductor manufacturer.  If [[Semiconductor device fabrication#Device test|manufacturing yield]] is high, more higher-rated components than required may be produced, and the manufacturer may mark and sell higher-performing components as lower-rated for marketing reasons.  In some cases, the true maximum rating of the component may exceed even the highest rated component sold.  Many devices sold with a lower rating may behave in all ways as higher-rated ones, while in the worst case operation at the higher rating may be more problematical.\n\nNotably, higher clocks must always mean greater waste heat generation, as semiconductors set to high must dump to ground more often.  In some cases, this means that the chief drawback of the overclocked part is far more heat dissipated than the maximums published by the manufacturer.  Pentium architect [[Bob Colwell]] calls overclocking an \"uncontrolled experiment in better-than-worst-case system operation\".<ref>{{cite journal|first1=Bob|last1=Colwell|title=The Zen of Overclocking|journal=[[Computer (magazine)|Computer]]|volume=37|issue=3|date=March 2004|pages=9\u201312|publisher=[[Institute of Electrical and Electronics Engineers]]|doi=10.1109/MC.2004.1273994}}</ref>\n\n=== Measuring effects of overclocking ===\n\n[[Benchmark (computing)|Benchmarks]] are used to evaluate performance, and they can become a kind of \"sport\" in which users compete for the highest scores.  As discussed above, stability and functional correctness may be compromised when overclocking, and meaningful benchmark results depend on the correct execution of the benchmark.  Because of this, benchmark scores may be qualified with stability and correctness notes (e.g. an overclocker may report a score, noting that the benchmark only runs to completion 1 in 5 times, or that signs of incorrect execution such as display corruption are visible while running the benchmark). A widely used test of stability is Prime95, which has built-in error checking that fails if the computer is unstable.\n\nUsing only the benchmark scores, it may be difficult to judge the difference overclocking makes to the overall performance of a computer. For example, some benchmarks test only one aspect of the system, such as memory [[Bandwidth (computing)|bandwidth]], without taking into consideration how higher [[clock rate]]s in this aspect will improve the system performance as a whole. Apart from demanding applications such as video encoding, high-demand [[database]]s and [[scientific computing]], [[memory bandwidth]] is typically not a [[bottleneck (engineering)|bottleneck]], so a great increase in memory bandwidth may be unnoticeable to a user depending on the applications used. Other benchmarks, such as [[3D Mark|3DMark]], attempt to replicate game conditions.\n\n== Manufacturer and vendor overclocking ==\n\nCommercial system builders or component resellers sometimes overclock to sell items at higher profit margins. The seller makes more money by overclocking lower-priced components which are found to operate correctly and selling equipment at prices appropriate for higher-rated components. While the equipment will normally operate correctly, this practice may be considered [[fraud]]ulent if the buyer is unaware of it.\n\nOverclocking is sometimes offered as a legitimate service or feature for consumers, in which a manufacturer or retailer tests the overclocking capability of processors, memory, video cards, and other hardware products. Several video card manufactures now offer factory-overclocked versions of their graphics accelerators, complete with a warranty, usually at a price intermediate between that of the standard product and a non-overclocked product of higher performance.\n\nIt is speculated that manufacturers implement overclocking prevention mechanisms such as [[CPU locking|CPU multiplier locking]] to prevent users from buying lower-priced items and overclocking them. These measures are sometimes marketed as a [[consumer protection]] benefit, but are often criticized by buyers.\n\nMany motherboards are sold, and advertised, with extensive facilities for overclocking implemented in hardware and controlled by [[BIOS]] settings.<ref>[http://www.asus.com/Motherboards/AMD_AM3Plus/M5A78LUSB3/ Web page for a typical motherboard claiming overclocking support]</ref>\n\n== CPU multiplier locking ==\n\n'''CPU multiplier locking''' is the process of permanently setting a [[Central processing unit|CPU]]'s [[clock multiplier]].  [[AMD]] CPUs are unlocked in early editions of a model and locked in later editions, but nearly all [[Intel]] CPUs are locked and recent models are very resistant to unlocking to prevent overclocking by users. AMD ships unlocked CPUs with their Opteron, FX, Ryzen and Black Series line-up, while Intel uses the monikers of \"Extreme Edition\" and \"K-Series.\" Intel usually has one or two Extreme Edition CPUs on the market as well as X series and K series CPUs analogous to AMD's Black Edition. AMD has the majority of their desktop range in a Black Edition.\n\nUsers usually unlock CPUs to allow overclocking, but sometimes to allow for [[underclocking]] in order to maintain the [[front side bus]] speed (on older CPUs) compatibility with certain motherboards. Unlocking generally invalidates the manufacturer's warranty, and mistakes can cripple or destroy a CPU. Locking a chip's clock multiplier does not necessarily prevent users from overclocking, as the speed of the front-side bus or PCI multiplier (on newer CPUs) may still be changed to provide a performance increase. AMD Athlon and Athlon XP CPUs are generally unlocked by connecting bridges ([[jumper (computing)|jumper]]-like points) on the top of the CPU with [[electrical conduction|conductive]] paint or [[Graphite|pencil lead]].  Other CPU models may require different procedures.\n\nIncreasing front-side bus and/or northbridge/PCI clocks can overclock locked CPUs, but this throws many system frequencies out of sync, since the RAM and PCI frequencies are modified as well.\n\nOne of the easiest ways to unlock older AMD Athlon XP CPUs was called the ''pin mod'' method, because it was possible to unlock the CPU without permanently modifying bridges. A user could simply put one wire (or some more for a new multiplier/Vcore) into the socket to unlock the CPU. More recently however, notably with Intel's Skylake architecture, Intel had a bug with the Skylake (6th gen Core) processors where the base clock could be increased past 102.7 MHz, however functionality of certain features would not work. Intel intended to block base clock (BCLK) overclocking of locked processors when designing the Skylake architecture to prevent consumers from purchasing cheaper components and overclocking to previously-unseen heights (since the CPU's BCLK was no longer tied to the PCI buses), however for LGA1151, the 6th generation \"Skylake\" processors were able to be overclocked past 102.7 MHz (which was the intended limit by Intel, and was later mandated through later BIOS updates). All other unlocked processors from LGA1151 and v2 (including 7th, 8th, and 9th generation) and BGA1440 allow for BCLK overclocking (as long as the OEM allows it), while all other locked processors from 7th, 8th, and 9th gen were not able to go past 102.7 MHz on the BCLK.\n\n== Advantages ==\n\n{{Original research|section|date=December 2011}}\n* Higher '''performance''' in games, en-/decoding, video editing and system tasks at no additional direct monetary expense, but with increased electrical consumption and thermal output.\n* System '''optimization''': Some systems have \"[[Bottleneck (software)|bottlenecks]]\", where small overclocking of one component can help realize the full potential of another component to a greater percentage than when just the limiting hardware itself is overclocked. For instance: many [[motherboard]]s with [[Athlon 64|AMD Athlon 64]] processors limit the clock rate of four units of RAM to 333 [[Hertz|MHz]]. However, the memory performance is computed by dividing the processor clock rate (which is a base number times a [[CPU multiplier]], for instance 1.8&nbsp;GHz is most likely 9\u00d7200&nbsp;MHz) by a fixed [[integer]] such that, at a stock clock rate, the RAM would run at a clock rate near 333&nbsp;MHz. Manipulating elements of how the processor clock rate is set (usually adjusting the multiplier), it is often possible to overclock the processor a small amount, around 5-10%, and gain a small increase in RAM clock rate and/or reduction in RAM latency timings.\n* It can be '''cheaper''' to purchase a lower performance component and overclock it to the clock rate of a more expensive component.\n* Extending life on older equipment (through underclocking/undervolting).\n\n==Disadvantages==\n\n=== General ===\n\n{{Original       research|section|date=December 2011}}\n* Higher [[clock rate]]s and voltages increase '''power consumption''', also increasing '''electricity cost''' and '''heat production'''. The additional heat increases the ambient air temperature within the system case, which may affect other components. The hot air blown out of the case heats the room it's in.\n* Fan '''noise''': High-performance fans running at maximum speed used for the required degree of cooling of an overclocked machine can be noisy, some producing 50&nbsp;[[Decibel#Acoustics|dB]] or more of noise. When maximum cooling is not required, in any equipment, fan speeds can be reduced below the maximum: fan noise has been found to be roughly proportional to the fifth power of fan speed; halving speed reduces noise by about 15&nbsp;dB.<ref>[http://www.hse.gov.uk/pubns/top10noise.pdf UK Health and Safety Executive: Top 10 noise control techniques]</ref> Fan noise can be reduced by design improvements, e.g. with aerodynamically optimized blades for smoother airflow, reducing noise to around 20&nbsp;dB at approximately 1 metre{{Citation needed|date=December 2011}} or larger fans rotating more slowly, which produce less noise than smaller, faster fans with the same airflow. Acoustical insulation inside the case e.g. acoustic foam can reduce noise. Additional cooling methods which do not use fans can be used, such as liquid and phase-change cooling.\n* An overclocked computer may become '''unreliable'''. For example: [[Microsoft Windows]] may appear to work with no problems, but when it is re-installed or upgraded, error messages may be received such as a \"file copy error\" during Windows Setup.<ref>[http://support.microsoft.com/kb/310064/en-us Article ID: 310064 \u2013 Last Review: May 7, 2007 \u2013 Revision: 6.2 How to troubleshoot problems during installation when you upgrade from Windows 98 or Windows Millennium Edition to Windows XP]</ref> Microsoft says this of errors in upgrading to Windows XP: \"Your computer [may be] over-clocked.\" Because installing Windows is very memory-intensive, decoding errors may occur when files are extracted from the Windows XP CD-ROM.\n* The '''lifespan''' of semiconductor components may be reduced by increased voltages and heat.\n* Warranties may be voided by overclocking.\n\n=== Risks of overclocking ===\n\n* Increasing the operation frequency of a component will usually increase its thermal output in a linear fashion, while an increase in voltage usually causes heat to increase exponentially. Excessive voltages or improper cooling may cause chip temperatures to rise to dangerous levels, causing the chip to be damaged or destroyed.\n* Exotic cooling methods used to facilitate overclocking such as water cooling are more likely to cause damage if they malfunction. Sub-ambient cooling methods such as [[Computer cooling#Phase-change cooling|phase-change cooling]] or [[liquid nitrogen]] will cause water [[condensation]], which will cause electrical damage unless controlled; some methods include using kneaded erasers or shop towels to catch the condensation.\n\n=== Limitations ===\n\nOverclocking components can only be of noticeable benefit if the component is on the [[Critical path method|critical path]] for a process, if it is a bottleneck. If disk access or the speed of an [[Internet]] connection limit the speed of a process, a 20% increase in processor speed is unlikely to be noticed, however there are some scenarios where increasing the clock speed of a processor actually allows an SSD to be read and written to faster.. Overclocking a CPU will not noticeably benefit a game when a graphics card's performance is the \"botleneck\" of the game.\n\n== Graphics cards ==\n\n[[File:Bfg geforce 6800 gs oc.jpg|thumb|200px|right|The BFG GeForce 6800GSOC ships with higher memory and [[clock rate]]s than the standard 6800GS.]]\nGraphics cards can also be overclocked. There are [[utility software|utilities]] to achieve this, such as [[EVGA Corporation|EVGA]]'s Precision, [[RivaTuner]], [[Advanced Micro Devices|AMD]] Overdrive (on [[Advanced Micro Devices|AMD]] cards only), [[Micro-Star International|MSI]] Afterburner, Zotac Firestorm, and the [[PEG Link Mode]] on [[Asus]] [[motherboard]]s. Overclocking a GPU will often yield a marked increase in performance in synthetic benchmarks, usually reflected in game performance<ref>[http://www.altesc.net/2013/06/15/gtx-780-overclocking/ Alt+Esc | GTX 780 Overclocking Guide<!-- Bot generated title -->]</ref>. It is sometimes possible to see that a graphics card is being pushed beyond its limits before any permanent damage is done by observing on-screen artifacts or unexpected system crashes. It is common to run into one of those problems when overclocking graphics cards; both symptoms at the same time usually means that the card is severely pushed beyond its heat, [[clock rate]], and/or voltage limits, however if seen when not overclocked, they indicate a faulty card. After a reboot, video settings are reset to standard values stored in the graphics card firmware, and the maximum [[clock rate]] of that specific card is now deducted.\n\nSome overclockers apply a [[potentiometer]] to the graphics card to manually adjust the voltage (which usually invalidates the warranty). This allows for finer adjustments, as overclocking software for graphics cards can only go so far. Excessive voltage increases may damage or destroy components on the graphics card or the entire graphics card itself (practically speaking).\n\n=== Alternatives ===\n\nFlashing and unlocking can be used to improve the performance of a [[Graphics card|video card]], without technically overclocking (but is much riskier than overclocking just through software).\n\n'''''Flashing''''' refers to using the [[firmware]] of a different card with the same (or sometimes similar) core and compatible firmware, effectively making it a higher model card; it can be difficult, and may be irreversible. Sometimes [[Computer software|standalone software]] to modify the firmware files can be found, e.g. [[NiBiTor]] (GeForce 6/7 series are well regarded in this aspect), without using firmware for a better model video card. For example, video cards with 3D accelerators (most, {{As of|2011|lc=on}}) have two voltage and [[clock rate]] settings, one for 2D and one for 3D, but were designed to operate with ''three'' voltage stages, the third being somewhere between the aforementioned two, serving as a fallback when the card overheats or as a middle-stage when going from 2D to 3D operation mode. Therefore, it could be wise to set this middle-stage prior to \"serious\" overclocking, specifically because of this fallback ability; the card can drop down to this [[clock rate]], reducing by a few (or sometimes a few dozen, depending on the setting) percent of its efficiency and cool down, without dropping out of 3D mode (and afterwards return to the desired high performance clock and voltage settings).\n\nSome cards have abilities not directly connected with overclocking. For example, Nvidia's [[GeForce|GeForce 6600GT]] (AGP flavor) has a temperature monitor used internally by the card, invisible to the user if standard firmware is used. Modifying the firmware can display a 'Temperature' tab.\n\n'''''Unlocking''''' refers to enabling extra [[Graphics pipeline|pipelines]] or [[pixel shader]]s.  The [[GeForce 6 Series|6800LE]], the [[GeForce 6 Series|6800GS]] and [[GeForce 6 Series|6800]] ([[Accelerated Graphics Port|AGP]] models only) were some of the first cards to benefit from unlocking.  While these  models have either 8 or 12 pipes enabled, they share the same 16x6 [[Graphics processing unit|GPU]] core as a [[GeForce 6 Series|6800GT]] or Ultra, but  pipelines and shaders beyond those specified are disabled; the GPU may be fully functional, or may have been found to have faults which do not affect operation at the lower specification. GPUs found to be fully functional can be unlocked successfully, although it is not possible to be sure that there are undiscovered faults; in the worst case the card may become [[Brick (electronics)|permanently unusable]].\n\n== History ==\n\nOverclocked processors first became commercially available in 1983, when AMD sold an overclocked version of the [[Intel 8088]] CPU. In 1984, some consumers were overclocking IBM's version of the [[Intel 80286]] CPU by replacing the clock crystal.\n\n== See also ==\n\n{{Portal|Electronics}}\n\n{{Div col|colwidth=20em}}\n* [[Clock rate]]\n* [[CPU-Z]]\n* [[Double boot]]\n* [[Dynamic voltage scaling]]\n* [[POWER8 on-chip controller]] (OCC)\n* [[Serial presence detect]] (SPD)\n* [[Super PI]]\n* [[Underclocking]]\n* [[UNIVAC I#Instructions and data|UNIVAC I Overdrive, 1952 unofficial modification]]\n{{div col end}}\n\n== References==\n\n{{Reflist|33em}}\n;Notes\n*{{cite journal | first = Bob | last = Colwell | authorlink = Bob Colwell | title = The Zen of Overclocking | journal =  Computer | volume = 37 | issue = 3 | pages = 9\u201312 |date=March 2004 | doi = 10.1109/MC.2004.1273994}}\n\n== External links ==\n\n{{wikibooks|How To Build A Computer|Optimizing and Overclocking}}\n{{Commons category|Overclocking}}\n<!--PLEASE NO FORUMS, LINKS WITHOUT DISCUSSION OR COMMERCIAL SITES, THEY WILL BE REMOVED-->\n* [http://www.ocinside.de/html/workshop/amd_socketa_overclock.html OverClocked inside]\n* [http://www.wikihow.com/Overclock-a-PC How to Overclock a PC], WikiHow\n* [http://www.ethernetworks.de/imac_g4_usb2_overclocking.html Overclocking guide for the Apple iMac G4 main logic board]\n\n=== Overclocking and benchmark databases ===\n\n*[http://www.xtremesystems.org OC Database of all PC hardware for the past decade] (applications, modifications and more)\n*[http://www.hwbot.org HWBOT: Worldwide Overclocking League \u2013 Overclocking competition and data]\n*[http://www.forum-inside.de/cgi-bin/forum/ocdatabase_e.cgi Comprehensive CPU OC Database]\n* [https://web.archive.org/web/20110624071633/http://imperiogamer.com/index.php/juegos/noticias/item/2367-segunda-convencion-nacional-de-oc-overclocking-extremo- Segunda Convencion Nacional de OC: Overclocking Extremo] by Imperio Gamer\n*[http://www.hwmaster.com/forum/tools-utili-per-loverclock-t168.html Tool for overclock]\n{{Computer processor power management technologies}}\n\n[[Category:Computer hardware tuning]]\n[[Category:Clock signal]]\n[[Category:Hobbies]]\n[[Category:IBM PC compatibles]]\n", "name_user": "Terrorist96", "label": "safe", "comment": "fix link", "url_page": "//en.wikipedia.org/wiki/Overclocking"}
