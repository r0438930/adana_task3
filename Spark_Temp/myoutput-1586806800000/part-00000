{"title_page": "Laplace transform", "text_new": "{{redirect|\u2112|the Lagrangian|Lagrangian mechanics}}\nIn [[mathematics]], the '''Laplace transform''' is an [[integral transform]] named after its inventor [[Pierre-Simon Laplace]] ({{IPAc-en|l|\u0259|\u02c8|p|l|\u0251:|s}}).  It transforms a function of a real variable {{math|''t''}} (often time) to a function of a [[complex analysis|complex variable]] {{mvar|s}} ([[complex frequency]]). The transform has many applications in science and engineering.\n\nThe Laplace transform is similar to the [[Fourier transform]].  While the Fourier transform of a function is a [[complex function]] of a ''real'' variable (frequency), the Laplace transform of a function is a complex function of a ''complex'' variable. The Laplace transform is usually restricted to transformation of functions of {{math|''t''}} with {{math|''t'' \u2265 0}}.  A consequence of this restriction is that the Laplace transform of a function is a [[holomorphic function]] of the variable {{math|''s''}}.  Unlike the Fourier transform, the Laplace transform of a [[distribution (mathematics)|distribution]] is generally a [[well-behaved]] function.  Techniques of complex variables can also be used to  directly study Laplace transforms.  As a holomorphic function, the Laplace transform has a [[power series]] representation.  This power series expresses a function as a linear superposition of [[moment (mathematics)|moments]] of the function.  This perspective has applications in [[probability theory]].\n\nThe Laplace transform is invertible on a large class of functions. The inverse Laplace transform takes a function of a complex variable {{math|''s''}} (often frequency) and yields a function of a real variable {{math|''t''}} (often time).  Given a simple mathematical or functional description of an input or output to a [[system]], the Laplace transform provides an alternative functional description that often simplifies the process of analyzing the behavior of the system, or in synthesizing a new system based on a set of specifications.<ref>{{harvnb|Korn|Korn|1967|loc=\u00a78.1}}</ref>  So, for example, the Laplace transformation from the [[time domain]] to the [[frequency domain]] transforms [[Differential equation|differential equations]] into algebraic equations and [[convolution]] into multiplication.\n\nLaplace wrote extensively about the use of [[Generating function|generating functions]] in ''Essai philosophique sur les probabilit\u00e9s'' (1814) and the integral form of the Laplace transform evolved naturally as a result.<ref>{{Cite book|title=Probability theory : the logic of science|last=Jaynes, E. T. (Edwin T.)|date=2003|publisher=Cambridge University Press|others=Bretthorst, G. Larry|isbn=0511065892|location=Cambridge, UK|oclc=57254076}}</ref>\n\n== History ==\nThe Laplace transform is named after mathematician and astronomer Pierre-Simon Laplace, who used a similar transform in his work on probability theory.<ref>{{citation |url=https://archive.org/details/thorieanalytiqu01laplgoog |title=Th\u00e9orie analytique des Probabilit\u00e9s |location=Paris |date=1814 |edition=2nd |at=chap.I sect.2-20 |chapter=Des Fonctions g\u00e9n\u00e9ratrices |trans-title=Analytical Probability Theory |trans-chapter=On generating functions |language=fr}}</ref> Laplace's use of generating functions was similar to what is now known as the [[z-transform]] and he gave little attention to the continuous variable case which was discussed by [[Niels Henrik Abel]].<ref>{{citation |first=Niels H. |last=Abel|authorlink=Niels Henrik Abel |chapter=Sur les fonctions g\u00e9n\u00e9ratrices et leurs d\u00e9terminantes |date=1820 |title=\u0152uvres Compl\u00e8tes |language=fr |publication-date=1839 |volume=II |pages=77\u201388}} [https://books.google.com/books?id=6FtDAQAAMAAJ&pg=RA2-PA67&lpg=RA2-PA67 1881 edition]</ref> The theory was further developed in the 19th and early 20th centuries by [[Mathias Lerch]],<ref>{{citation |first=Mathias |last=Lerch |author-link=Mathias Lerch |title=Sur un point de la th\u00e9orie des fonctions g\u00e9n\u00e9ratrices d'Abel |journal=[[Acta Mathematica]] |volume=27 |date=1903 |pages=339\u2013351 |doi=10.1007/BF02421315 |trans-title=Proof of the inversion formula |language=fr}}</ref> [[Oliver Heaviside]],<ref>{{citation |first=Oliver |last=Heaviside |author-link=Oliver Heaviside |chapter=The solution of definite integrals by differential transformation |title=Electromagnetic Theory |location=London |at=section 526 |volume=III |chapter-url=https://books.google.com/books?id=y9auR0L6ZRcC&pg=PA234&lpg=PA234|isbn=9781605206189 |date=January 2008 }}</ref> and [[Thomas John I'Anson Bromwich|Thomas Bromwich]].<ref>{{citation |first=Thomas J. |last=Bromwich |author-link=Thomas John I'Anson Bromwich |title=Normal coordinates in dynamical systems |journal=[[Proceedings of the London Mathematical Society]] |volume=15 |pages=401\u2013448 |date=1916 |doi=10.1112/plms/s2-15.1.401|url=https://zenodo.org/record/2319588 }}</ref> The current widespread use of the transform (mainly in engineering) came about during and soon after World War II<ref>An influential book was: {{citation |first=Murray F. |last=Gardner |first2=John L. |last2=Barnes |title=Transients in Linear Systems studied by the Laplace Transform |date=1942 |location=New York |publisher=Wiley}}</ref> replacing the earlier Heaviside operational calculus. The advantages of the Laplace transform had been emphasized by [[Gustav Doetsch]]<ref>{{citation |first=Gustav |last=Doetsch |title=Theorie und Anwendung der Laplacesche Transformation |location=Berlin |date=1937 |publisher=Springer |language=de |trans-title=Theory and Application of the Laplace Transform}} translation 1943</ref> to whom the name Laplace Transform is apparently due.  \n\nFrom 1744, [[Leonhard Euler]] investigated integrals of the form\n: <math> z = \\int X(x) e^{ax}\\, dx \\quad\\text{ and }\\quad z = \\int X(x) x^A \\, dx</math>\nas solutions of differential equations but did not pursue the matter very far.<ref>{{harvnb|Euler|1744}}, {{harvnb|Euler|1753}}, {{harvnb|Euler|1769}}</ref> [[Joseph Louis Lagrange]] was an admirer of Euler and, in his work on integrating [[probability density function]]s, investigated expressions of the form\n: <math> \\int X(x) e^{- a x } a^x\\, dx,</math>\nwhich some modern historians have interpreted within modern Laplace transform theory.<ref>{{harvnb|Lagrange|1773}}</ref><ref>{{harvnb|Grattan-Guinness| 1997|p=260}}</ref>{{Clarify|date=May 2010}}\n\nThese types of integrals seem first to have attracted Laplace's attention in 1782 where he was following in the spirit of Euler in using the integrals themselves as solutions of equations.<ref>{{harvnb|Grattan-Guinness|1997|p=261}}</ref> However, in 1785, Laplace took the critical step forward when, rather than just looking for a solution in the form of an integral, he started to apply the transforms in the sense that was later to become popular. He used an integral of the form\n: <math> \\int x^s \\varphi (x)\\, dx,</math>\nakin to a [[Mellin transform]], to transform the whole of a [[difference equation]], in order to look for solutions of the transformed equation. He then went on to apply the Laplace transform in the same way and started to derive some of its properties, beginning to appreciate its potential power.<ref>{{harvnb|Grattan-Guinness|1997|pp=261\u2013262}}</ref>\n\nLaplace also recognised that [[Joseph Fourier]]'s method of [[Fourier series]] for solving the [[diffusion equation]] could only apply to a limited region of space because those solutions were [[Periodic function|periodic]]. In 1809, Laplace applied his transform to find solutions that diffused indefinitely in space.<ref>{{harvnb|Grattan-Guinness|1997|pp=262&ndash;266}}</ref>\n\n== Formal definition ==\nThe Laplace transform of a [[function (mathematics)|function]] {{math|''f''(''t'')}}, defined for all [[real number]]s {{math|''t'' \u2265 0}}, is the function {{math|''F''(''s'')}}, which is a unilateral transform defined by\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>F(s) =\\int_0^\\infty f(t)e^{-st} \\, dt</math>|{{EquationRef|Eq.1}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere ''s'' is a [[complex number]] frequency parameter\n: <math>s = \\sigma + i \\omega</math>, with real numbers {{math|''\u03c3''}} and {{math|''\u03c9''}}.\n\nAn alternate notation for the Laplace transform is <math>\\mathcal{L}\\{f\\}</math> instead of {{math|''F''}}.\n\nThe meaning of the integral depends on types of functions of interest.  A necessary condition for existence of the integral is that {{math|''f''}} must be [[locally integrable]] on {{closed-open|0, \u221e}}.  For locally integrable functions that decay at infinity or are of [[exponential type]], the integral can be understood to be a (proper) [[Lebesgue integral]]. However, for many applications it is necessary to regard it as a [[conditionally convergent]] [[improper integral]] at {{math|\u221e}}.  Still more generally, the integral can be understood in a [[distribution (mathematics)|weak sense]], and this is dealt with below.\n\nOne can define the Laplace transform of a finite [[Borel measure]] {{math|''\u03bc''}} by the Lebesgue integral<ref>{{harvnb|Feller|1971|loc=\u00a7XIII.1}}</ref>\n: <math>\\mathcal{L}\\{\\mu\\}(s) = \\int_{[0,\\infty)} e^{-st}\\, d\\mu(t).</math>\n\nAn important special case is where {{math|''\u03bc''}} is a [[probability measure]], for example, the [[Dirac delta function]]. In [[operational calculus]], the Laplace transform of a measure is often treated as though the measure came from a probability density function {{math|''f''}}.  In that case, to avoid potential confusion, one often writes\n: <math>\\mathcal{L}\\{f\\}(s) = \\int_{0^-}^\\infty f(t)e^{-st} \\, dt,</math>\nwhere the lower limit of {{math|0<sup>\u2212</sup>}} is shorthand notation for\n: <math>\\lim_{\\varepsilon\\rightarrow 0^+}\\int_{-\\varepsilon}^\\infty.</math>\n\nThis limit emphasizes that any point mass located at {{math|0}} is entirely captured by the Laplace transform. Although with the Lebesgue integral, it is not necessary to take such a limit, it does appear more naturally in connection with the [[Laplace\u2013Stieltjes transform]].\n\n=== Bilateral Laplace transform ===\n{{Main article|Two-sided Laplace transform}}\n\nWhen one says \"the Laplace transform\" without qualification, the unilateral or one-sided transform is normally intended. The Laplace transform can be alternatively defined as the ''bilateral Laplace transform'' or [[two-sided Laplace transform]] by extending the limits of integration to be the entire real axis.  If that is done the common unilateral transform simply becomes a special case of the bilateral transform where the definition of the function being transformed is multiplied by the [[Heaviside step function]].\nThe bilateral Laplace transform is defined as follows:\n{{math|''F''(''s'')}}, which is a bilateral transform defined by\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>F(s) = \\int_{-\\infty}^\\infty e^{-st} f(t)\\, dt</math>|{{EquationRef|Eq.2}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nAn alternate notation for the bilateral Laplace transform is <math>\\mathcal{B}\\{f\\}</math> instead of <math>F</math>.\n\n=== Inverse Laplace transform ===\n{{Main article|Inverse Laplace transform}}\nTwo integrable functions have the same Laplace transform only if they differ on a set of [[Lebesgue measure]] zero. This means that, on the range of the transform, there is an inverse transform. In fact, besides integrable functions, the Laplace transform is a [[one-to-one function|one-to-one]] mapping from one function space into another in many other function spaces as well, although there is usually no easy characterization of the range. Typical function spaces in which this is true include the spaces of bounded continuous functions, the space [[Lp space|{{math|''L''<sup>&infin;</sup>(0, &infin;)}}]], or more generally [[Distribution (mathematics)#Tempered distributions and Fourier transform|tempered distributions]] on {{open-open|0, &infin;}}.  The Laplace transform is also defined and injective for suitable spaces of tempered distributions.\n\nIn these cases, the image of the Laplace transform lives in a space of [[analytic function]]s in the [[#Region of convergence|region of convergence]].  The [[inverse Laplace transform]] is given by the following complex integral, which is known by various names (the '''Bromwich integral''', the '''Fourier\u2013Mellin integral''', and '''Mellin's inverse formula'''):\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>f(t) = \\mathcal{L}^{-1}\\{F\\}(t) = \\frac{1}{2 \\pi i} \\lim_{T\\to\\infty}\\oint_{\\gamma - i T}^{\\gamma + i T} e^{st} F(s)\\, ds</math>|{{EquationRef|Eq.3}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere {{math|''\u03b3''}} is a real number so that the contour path of integration is in the region of convergence of {{math|''F''(''s'')}}. An alternative formula for the inverse Laplace transform is given by [[Post's inversion formula]]. The limit here is interpreted in the [[weak-* topology#Weak-* topology|weak-* topology]].\n\nIn practice, it is typically more convenient to decompose a Laplace transform into known transforms of functions obtained from a table, and construct the inverse by inspection.\n\n=== Probability theory ===\nIn [[probability theory|pure]] and [[applied probability]], the Laplace transform is defined as an [[expected value]]. If {{math|''X''}} is a [[random variable]] with probability density function {{math|''f''}}, then the Laplace transform of {{math|''f''}} is given by the expectation\n: <math>\\mathcal{L}\\{f\\}(s) = \\operatorname{E}\\! \\left[e^{-sX} \\right]\\! .</math>\n\nBy [[abuse of notation|convention]], this is referred to as the Laplace transform of the random variable {{math|''X''}} itself. Replacing {{math|''s''}} by {{math|\u2212''t''}} gives the [[moment generating function]] of {{math|''X''}}. The Laplace transform has applications throughout probability theory, including [[first passage time]]s of [[stochastic processes]] such as [[Markov chain]]s, and [[renewal theory]].\n\nOf particular use is the ability to recover the [[cumulative distribution function]] of a continuous random variable {{math|''X''}} by means of the Laplace transform as follows<ref>The cumulative distribution function is the integral of the probability density function.</ref>\n: <math>F_X(x) = \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}\\operatorname{E}\\left[e^{-sX}\\right]\\right\\}\\! (x) = \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}\\mathcal{L}\\{f\\}(s)\\right\\}\\! (x).</math>\n\n== Region of convergence ==\nIf {{math|''f''}} is a locally integrable function (or more generally a Borel measure locally of bounded variation), then the Laplace transform {{math|''F''(''s'')}} of {{math|''f''}} converges provided that the limit\n: <math>\\lim_{R\\to\\infty}\\int_0^R f(t)e^{-st}\\,dt</math>\nexists.\n\nThe Laplace transform converges absolutely if the integral\n: <math>\\int_0^\\infty \\left|f(t)e^{-st}\\right|\\,dt</math>\nexists (as a proper Lebesgue integral).  The Laplace transform is usually understood as conditionally convergent, meaning that it converges in the former instead of the latter sense.\n\nThe set of values for which {{math|''F''(''s'')}} converges absolutely is either of the form {{math|Re(''s'') > ''a''}} or else {{math|Re(''s'') \u2265 ''a''}}, where {{math|''a''}} is an [[extended real number|extended real constant]], {{math|\u2212\u221e \u2264 ''a'' \u2264 \u221e}}.  (This follows from the [[dominated convergence theorem]].) The constant {{math|''a''}} is known as the abscissa of absolute convergence, and depends on the growth behavior of {{math|''f''(''t'')}}.<ref>{{harvnb|Widder|1941|loc=Chapter II, \u00a71}}</ref> Analogously, the two-sided transform converges absolutely in a strip of the form  {{math|''a'' < Re(''s'') < ''b''}}, and possibly including the lines {{math|1=Re(''s'') = ''a''}} or {{math|1=Re(''s'') = ''b''}}.<ref>{{harvnb|Widder|1941|loc=Chapter VI, \u00a72}}</ref>  The subset of values of {{math|''s''}} for which the Laplace transform converges absolutely is called the region of absolute convergence or the domain of absolute convergence.  In the two-sided case, it is sometimes called the strip of absolute convergence. The Laplace transform is analytic in the region of absolute convergence: this is a consequence of [[Fubini's theorem]] and [[Morera's theorem]]. \n\nSimilarly, the set of values for which {{math|''F''(''s'')}} converges (conditionally or absolutely) is known as the region of conditional convergence, or simply the '''region of convergence''' (ROC).  If the Laplace transform converges (conditionally) at {{math|1=''s'' = ''s''<sub>0</sub>}}, then it automatically converges for all {{math|''s''}} with {{math|Re(''s'') > Re(''s''<sub>0</sub>)}}.  Therefore, the region of convergence is a half-plane of the form {{math|Re(''s'') > ''a''}}, possibly including some points of the boundary line {{math|1=Re(''s'') = ''a''}}.\n\nIn the region of convergence {{math|Re(''s'') > Re(''s''<sub>0</sub>)}}, the Laplace transform of {{math|''f''}} can be expressed by [[integration by parts|integrating by parts]] as the integral\n: <math>F(s) = (s-s_0)\\int_0^\\infty e^{-(s-s_0)t}\\beta(t)\\,dt,\\quad \\beta(u) = \\int_0^u e^{-s_0t}f(t)\\,dt.</math>\n\nThat is, in the region of convergence {{math|''F''(''s'')}} can effectively be expressed as the absolutely convergent Laplace transform of some other function.  In particular, it is analytic.\n\nThere are several [[Paley\u2013Wiener theorem]]s concerning the relationship between the decay properties of {{math|''f''}} and the properties of the Laplace transform within the region of convergence.\n\nIn engineering applications, a function corresponding to a [[LTI system|linear time-invariant (LTI) system]] is ''stable'' if every bounded input produces a bounded output.  This is equivalent to the absolute convergence of the Laplace transform of the impulse response function in the region {{math|Re(''s'') \u2265 0}}.  As a result, LTI systems are stable provided the poles of the Laplace transform of the impulse response function have negative real part.\n\nThis ROC is used in knowing about the causality and stability of a system.\n\n== Properties and theorems ==\nThe Laplace transform has a number of properties that make it useful for analyzing linear [[dynamical system]]s. The most significant advantage is that [[derivative|differentiation]] becomes multiplication, and [[integral|integration]] becomes division, by  {{math|''s''}} (similarly to [[logarithm]]s changing multiplication of numbers to addition of their logarithms).\n\nBecause of this property, the Laplace variable {{math|''s''}} is also known as ''operator variable'' in the {{math|''L''}} domain: either ''derivative operator'' or (for {{math|''s''<sup>\u22121</sup>)}} ''integration operator''. The transform turns [[integral equation]]s and [[differential equation]]s to [[polynomial equation]]s, which are much easier to solve.  Once solved, use of the inverse Laplace transform reverts to the original domain.\n\nGiven the functions {{math|''f''(''t'')}} and {{math|''g''(''t'')}}, and their respective Laplace transforms {{math|''F''(''s'')}} and {{math|''G''(''s'')}},\n: <math>\\begin{align}\nf(t) &= \\mathcal{L}^{-1}\\{F(s)\\},\\\\\ng(t) &= \\mathcal{L}^{-1}\\{G(s)\\},\n\\end{align}</math>\n\nThe following '''table''' is a list of properties of unilateral Laplace transform:<ref>{{harvnb|Korn|Korn|1967|pp=226&ndash;227}}</ref>\n\n{| class=\"wikitable\" id=\"291017_tableid\"\n|+ Properties of the unilateral Laplace transform\n|-\n !\n ! Time domain\n ! {{math|''s''}} domain\n ! Comment\n|-\n ! [[Linearity]]\n | <math> a f(t) + b g(t) \\ </math>\n | <math> a F(s) + b G(s) \\ </math>\n | Can be proved using basic rules of integration.\n|-\n ! Frequency-domain derivative\n | <math> t f(t) \\ </math>\n | <math> -F'(s) \\ </math>\n | {{math|''F''\u2032}} is the first derivative of {{math|''F''}} with respect to {{math|''s''}}.\n|-\n ! Frequency-domain general derivative\n | <math> t^{n} f(t) \\ </math>\n | <math> (-1)^{n} F^{(n)}(s) \\ </math>\n | More general form, {{math|''n''}}th derivative of {{math|''F''(''s'')}}.\n|-\n ! [[Derivative]]\n | <math> f'(t) \\ </math>\n | <math> s F(s) - f(0^{+}) \\ </math>\n | {{math|''f''}} is assumed to be a [[differentiable function]], and its derivative is assumed to be of exponential type.  This can then be obtained by integration by parts\n|-\n ! Second derivative\n | <math> f''(t) \\ </math>\n | <math> s^2 F(s) - s f(0^{+}) - f'(0^{+}) \\ </math>\n | {{math|''f''}} is assumed twice differentiable and the second derivative to be of exponential type. Follows by applying the Differentiation property to {{math|''f''\u2032(''t'')}}.\n|-\n ! General derivative\n | <math> f^{(n)}(t)  \\ </math>\n | <math> s^n F(s) - \\sum_{k=1}^{n} s^{n-k} f^{(k-1)}(0^{+}) \\ </math>\n | {{math|''f''}} is assumed to be {{math|''n''}}-times differentiable, with {{math|''n''}}th derivative of exponential type.  Follows by [[mathematical induction]].\n|-\n ! [[Frequency|Frequency-domain integration]]\n | <math> \\frac{1}{t}f(t)  \\ </math>\n | <math> \\int_s^\\infty F(\\sigma)\\, d\\sigma \\ </math>\n | This is deduced using the nature of frequency differentiation and conditional convergence.\n|-\n ! Time-domain [[integral|integration]]\n | <math> \\int_0^t f(\\tau)\\, d\\tau  =  (u * f)(t)</math>\n | <math> {1 \\over s} F(s) </math>\n | {{math|''u''(''t'')}} is the Heaviside step function and {{math|(''u''&nbsp;\u2217&nbsp;''f'')(''t'')}} is the [[convolution]] of {{math|''u''(''t'')}} and {{math|''f''(''t'')}}.\n|-\n ! Frequency shifting\n | <math> e^{at} f(t)  \\ </math>\n | <math> F(s - a) \\ </math>\n |\n|-\n ! Time shifting\n | <math> f(t - a) u(t - a) \\ </math>\n | <math> e^{-as} F(s) \\ </math>\n | {{math|''u''(''t'')}} is the Heaviside step function\n|-\n ! Time scaling\n | <math>f(at)</math>\n | <math> \\frac{1}{a} F \\left ( {s \\over a} \\right )</math>\n | <math> a > 0 \\ </math>\n|-\n ! [[Multiplication]]\n | <math>f(t)g(t)</math>\n | <math> \\frac{1}{2\\pi i}\\lim_{T\\to\\infty}\\int_{c - iT}^{c + iT}F(\\sigma)G(s - \\sigma)\\,d\\sigma \\ </math>\n | The integration is done along the vertical line {{nowrap|1=Re(''\u03c3'') = ''c''}} that lies entirely within the region of convergence of {{math|''F''}}.<ref>{{harvnb|Bracewell|2000|loc=Table 14.1, p. 385}}</ref>\n|-\n ! [[Convolution]]\n | <math> (f * g)(t) = \\int_{0}^{t} f(\\tau)g(t - \\tau)\\,d\\tau</math>\n | <math> F(s) \\cdot G(s) \\ </math>\n | \n|-\n ! [[Complex conjugation]]\n | <math> f^*(t) </math>\n | <math> F^*(s^*) </math>\n |\n|-\n ! [[Cross-correlation]]\n | <math> f(t)\\star g(t) </math>\n | <math> F^*(-s^*)\\cdot G(s) </math>\n |\n|-\n ! [[Periodic function]]\n | <math>f(t)</math>\n | <math>{1 \\over 1 - e^{-Ts}} \\int_0^T e^{-st} f(t)\\,dt </math>\n | {{math|''f''(''t'')}} is a periodic function of period {{math|''T''}} so that {{math|1=''f''(''t'') = ''f''(''t'' + ''T'')}}, for all {{math|''t'' \u2265 0}}. This is the result of the time shifting property and the [[geometric series]].\n|}\n\n* '''[[Initial value theorem]]''':\n: <math>f(0^+)=\\lim_{s\\to \\infty}{sF(s)}.</math>\n* '''[[Final value theorem]]''':\n: <math>f(\\infty)=\\lim_{s\\to 0}{sF(s)}</math>, if all [[Pole (complex analysis)|poles]] of ''sF''(''s'') are in the left half-plane.\n: The final value theorem is useful because it gives the long-term behaviour without having to perform [[partial fraction]] decompositions or other difficult algebra. If {{math|''F''(''s'')}} has a pole in the right-hand plane or poles on the imaginary axis (e.g., if <math>f(t) = e^t</math> or <math>f(t) = \\sin(t)</math>), the behaviour of this formula is undefined.\n\n=== Relation to power series ===\nThe Laplace transform can be viewed as a [[continuous function|continuous]] analogue of a [[power series]].<ref>{{cite web |last1=Mattuck |first1=Arthur |title=Where the Laplace Transform comes from |url=https://www.youtube.com/watch?v=zvbdoSeGAgI}}</ref> If  {{math|''a''(''n'')}} is a discrete function of a positive integer {{math|''n''}}, then the power series associated to  {{math|''a''(''n'')}} is the series\n:<math>\\sum_{n=0}^{\\infty} a(n) x^n</math>\nwhere  {{math|''x''}} is a real variable (see [[Z transform]]). Replacing summation over {{math|''n''}} with integration over  {{math|''t''}}, a continuous version of the power series becomes\n:<math>\\int_{0}^{\\infty} f(t) x^t\\, dt</math>\nwhere the discrete function {{math|''a''(''n'')}} is replaced by the continuous one {{math|''f''(''t'')}}. \n\nChanging the base of the power from {{math|''x''}} to {{math|''e''}} gives\n:<math>\\int_{0}^{\\infty} f(t) \\left(e^{\\ln{x}}\\right)^t\\, dt</math>\n\nFor this to converge for, say, all bounded functions {{math|''f''}}, it is necessary to require that {{math|ln ''x'' < 0}}. Making the substitution {{math|1=&minus;''s'' = ln ''x''}} gives just the Laplace transform:\n:<math>\\int_{0}^{\\infty} f(t) e^{-st}\\, dt</math>\n\nIn other words, the Laplace transform is a continuous analog of a power series in which the discrete parameter {{math|''n''}} is replaced by the continuous parameter {{math|''t''}}, and {{math|''x''}} is replaced by {{math|''e''<sup>&minus;''s''</sup>}}.\n\n=== Relation to moments ===\n{{main article|Moment generating function}}\nThe quantities\n:<math>\\mu_n = \\int_0^\\infty t^nf(t)\\, dt</math>\n\nare the ''moments'' of the function {{math|''f''}}.  If the first {{math|''n''}} moments of {{math|''f''}} converge absolutely, then by repeated [[differentiation under the integral]], \n:<math>(-1)^n(\\mathcal L f)^{(n)}(0) = \\mu_n .</math>\nThis is of special significance in probability theory, where the moments of a random variable {{math|''X''}} are given by the expectation values <math>\\mu_n=\\operatorname{E}[X^n]</math>.  Then, the relation holds\n:<math>\\mu_n = (-1)^n\\frac{d^n}{ds^n}\\operatorname{E}\\left[e^{-sX}\\right](0).</math>\n\n=== Computation of the Laplace transform of a function's derivative ===\nIt is often convenient to use the differentiation property of the Laplace transform to find the transform of a function's derivative.  This can be derived from the basic expression for a Laplace transform as follows:\n\n: <math>\\begin{align}\n  \\mathcal{L} \\left\\{f(t)\\right\\} &= \\int_{0^-}^\\infty e^{-st} f(t)\\, dt \\\\[6pt]\n                                  &= \\left[\\frac{f(t)e^{-st}}{-s} \\right]_{0^-}^\\infty -\n                                       \\int_{0^-}^\\infty \\frac{e^{-st}}{-s} f'(t) \\, dt\\quad \\text{(by parts)} \\\\[6pt]\n                                  &= \\left[-\\frac{f(0^+)}{-s}\\right] + \\frac 1 s \\mathcal{L} \\left\\{f'(t)\\right\\},\n\\end{align}</math>\n\nyielding\n\n: <math>\\mathcal{L} \\{ f'(t) \\} = s\\cdot\\mathcal{L} \\{ f(t) \\}-f(0^+), </math>\n\nand in the bilateral case,\n\n: <math> \\mathcal{L} \\{ f'(t) \\} = s \\int_{-\\infty}^\\infty e^{-st} f(t)\\,dt  = s \\cdot \\mathcal{L} \\{ f(t) \\}. </math>\n\nThe general result\n\n: <math>\\mathcal{L} \\left\\{ f^{(n)}(t) \\right\\} = s^n \\cdot \\mathcal{L} \\{ f(t) \\} - s^{n - 1} f(0^+) - \\cdots - f^{(n - 1)}(0^+),</math>\n\nwhere <math>f^{(n)}</math> denotes the {{math|''n''}}<sup>th</sup> derivative of {{math|''f''}}, can then be established with an inductive argument.\n\n=== Evaluating integrals over the positive real axis ===\nA useful property of the Laplace transform is the following:\n\n: <math>\\int_0^\\infty f(x)g(x)\\,dx = \\int_0^\\infty(\\mathcal{L} f)(s)\\cdot(\\mathcal{L}^{-1}g)(s)\\,ds </math>\n\nunder suitable assumptions on the behaviour of <math>f,g</math> in a right neighbourhood of <math>0</math> and on the decay rate of <math>f,g</math> in a left neighbourhood of <math>\\infty</math>. The above formula is a variation of integration by parts, with the operators \n<math>\\frac{d}{dx}</math> and <math>\\int \\,dx</math> being replaced by <math>\\mathcal{L}</math> and <math>\\mathcal{L}^{-1}</math>. Let us prove the equivalent formulation:\n\n: <math>\\int_0^\\infty(\\mathcal{L} f)(x)g(x)\\,dx = \\int_0^\\infty f(s)(\\mathcal{L}g)(s)\\,ds. </math>\n\nBy plugging in <math>(\\mathcal{L}f)(x)=\\int_0^\\infty f(s)e^{-sx}\\,ds</math> the left-hand side turns into:\n\n: <math>\\int_0^\\infty\\int_0^\\infty f(s)g(x) e^{-sx}\\,ds\\,dx, </math>\n\nbut assuming Fubini's theorem holds, by reversing the order of integration we get the wanted right-hand side.\n\n=== Relationship to other transforms ===\n\n==== Laplace\u2013Stieltjes transform ====\nThe (unilateral) Laplace\u2013Stieltjes transform of a function {{math|''g'' : '''R''' \u2192 '''R'''}} is defined by the [[Lebesgue\u2013Stieltjes integral]]\n\n: <math>\\{\\mathcal{L}^*g\\}(s) = \\int_0^\\infty e^{-st} \\, dg(t).</math>\n\nThe function {{math|''g''}} is assumed to be of [[bounded variation]].  If {{math|''g''}} is the [[antiderivative]] of {{math|''f''}}:\n\n: <math>g(x) = \\int_0^x f(t)\\,dt</math>\n\nthen the Laplace\u2013Stieltjes transform of {{math|''g''}} and the Laplace transform of {{math|''f''}} coincide.  In general, the Laplace\u2013Stieltjes transform is the Laplace transform of the [[Stieltjes measure]] associated to {{math|''g''}}.  So in practice, the only distinction between the two transforms is that the Laplace transform is thought of as operating on the density function of the measure, whereas the Laplace\u2013Stieltjes transform is thought of as operating on its [[cumulative distribution function]].<ref>{{harvnb|Feller|1971|p=432}}</ref>\n\n==== Fourier transform ====\n{{Main|Fourier transform}}\nThe continuous Fourier transform is equivalent to evaluating the bilateral Laplace transform with imaginary argument {{math|1=''s'' = ''i\u03c9''}} or {{math|1=''s'' = 2''\u03c0fi''}}<ref>{{harvnb|Takacs|1953|p=93}}</ref> when the condition explained below is fulfilled, \n:<math>\\begin{align}\n  \\widehat{f}(\\omega) &= \\mathcal{F}\\{f(t)\\} \\\\[4pt]\n                  &= \\mathcal{L}\\{f(t)\\}|_{s = i\\omega}  =  F(s)|_{s = i \\omega} \\\\[4pt]\n                  &= \\int_{-\\infty}^\\infty e^{-i \\omega t} f(t)\\,dt~.\n\\end{align}</math>\n\nThis definition of the Fourier transform requires a prefactor of {{math|1/(2''\u03c0'')}} on the reverse Fourier transform. This relationship between the Laplace and Fourier transforms is often used to determine the [[frequency spectrum]] of a [[signal (information theory)|signal]] or dynamical system.\n\nThe above relation is valid as stated if and only if the region of convergence (ROC) of  {{math|''F''(''s'')}} contains the imaginary axis,  {{math|1=''\u03c3'' = 0}}.\n\nFor example, the function {{math|1=''f''(''t'') = cos(''\u03c9''<sub>0</sub>''t'')}} has a Laplace transform  {{math|1=''F''(''s'') =  ''s''/(''s''<sup>2</sup> + ''\u03c9''<sub>0</sub><sup>2</sup>)}} whose ROC is {{math|Re(''s'') > 0}}. As {{math|1=''s'' = ''i\u03c9''}} is a pole of  {{math|''F''(''s'')}}, substituting  {{math|1=''s'' = ''i\u03c9''}} in {{math|''F''(''s'')}} does not yield the Fourier transform of  {{math|''f''(''t'')''u''(''t'')}}, which is proportional to the [[Dirac delta-function]] {{math|''\u03b4''(''\u03c9'' \u2212 ''\u03c9''<sub>0</sub>)}}.\n\nHowever, a relation of the form\n: <math>\\lim_{\\sigma\\to 0^+} F(\\sigma+i\\omega) = \\widehat{f}(\\omega)</math>\nholds under much weaker conditions.  For instance, this holds for the above example provided that the limit is understood as a [[weak limit]] of measures (see [[vague topology]]).  General conditions relating the limit of the Laplace transform of a function on the boundary to the Fourier transform take the form of [[Paley\u2013Wiener theorem]]s.\n\n==== Mellin transform ====\n{{Main|Mellin transform}}\nThe Mellin transform and its inverse are related to the two-sided Laplace transform by a simple change of variables.\n\nIf in the Mellin transform\n: <math>G(s) = \\mathcal{M}\\{g(\\theta)\\} = \\int_0^\\infty \\theta^s g(\\theta) \\, \\frac{d\\theta} \\theta </math>\nwe set {{math|1=''\u03b8'' = ''e''<sup>\u2212''t''</sup>}} we get a two-sided Laplace transform.\n\n==== Z-transform ====\n{{Main|Z-transform}}\nThe unilateral or one-sided Z-transform is simply the Laplace transform of an ideally sampled signal with the substitution of\n: <math> z \\stackrel{\\mathrm{def}}{{}={}} e^{sT} ,</math>\nwhere {{math|1=''T'' = 1/''f<sub>s</sub>''}} is the [[Sampling theorem|sampling]] period (in units of time e.g., seconds) and  {{math|''f<sub>s</sub>''}} is the [[sampling rate]] (in [[sample (signal)|samples per second]] or [[hertz]]).\n\nLet\n: <math> \\Delta_T(t) \\ \\stackrel{\\mathrm{def}}{=}\\  \\sum_{n=0}^{\\infty}  \\delta(t - n T) </math>\nbe a sampling impulse train (also called a [[Dirac comb]]) and\n:<math>\\begin{align}\n  x_q(t) \\  &\\stackrel{\\mathrm{def}}{=}\\  x(t) \\Delta_T(t) = x(t) \\sum_{n=0}^{\\infty}  \\delta(t - n T) \\\\\n            &= \\sum_{n=0}^{\\infty} x(n T) \\delta(t - n T) = \\sum_{n=0}^{\\infty} x[n] \\delta(t - n T)\n\\end{align}</math>\nbe the sampled representation of the continuous-time {{math|''x''(''t'')}}\n: <math> x[n] \\stackrel{\\mathrm{def}}{{}={}}  x(nT) ~.</math>\n\nThe Laplace transform of the sampled signal {{math|''x''<sub>''q''</sub>(''t'') }} is\n: <math>\\begin{align}\n  X_q(s) &= \\int_{0^-}^\\infty x_q(t) e^{-s t} \\,dt \\\\\n         &= \\int_{0^-}^\\infty \\sum_{n=0}^\\infty x[n] \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &= \\sum_{n=0}^\\infty x[n] \\int_{0^-}^\\infty \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &= \\sum_{n=0}^\\infty x[n] e^{-n s T}~.\n\\end{align}</math>\n\nThis is the precise definition of the unilateral Z-transform of the discrete function {{math|''x''[''n'']}}\n\n: <math> X(z) = \\sum_{n=0}^{\\infty} x[n] z^{-n} </math>\nwith the substitution of {{math|''z'' \u2192 e<sup>''sT''</sup>}}.\n\nComparing the last two equations, we find the relationship between the unilateral Z-transform and the Laplace transform of the sampled signal,\n: <math>X_q(s) =  X(z) \\Big|_{z=e^{sT}}.</math>\n\nThe similarity between the {{math|''Z''}} and Laplace transforms is expanded upon in the theory of [[time scale calculus]].\n\n==== Borel transform ====\nThe integral form of the [[Borel summation|Borel transform]]\n\n: <math>F(s) = \\int_0^\\infty f(z)e^{-sz}\\, dz</math>\n\nis a special case of the Laplace transform for {{math|''f''}} an [[entire function]] of exponential type, meaning that\n\n: <math>|f(z)|\\le Ae^{B|z|}</math>\n\nfor some constants {{math|''A''}} and {{math|''B''}}.  The generalized Borel transform allows a different weighting function to be used, rather than the exponential function, to transform functions not of exponential type. [[Nachbin's theorem]] gives necessary and sufficient conditions for the Borel transform to be well defined.\n\n==== Fundamental relationships ====\nSince an ordinary Laplace transform can be written as a special case of a two-sided transform, and since the two-sided transform can be written as the sum of two one-sided transforms, the theory of the Laplace-, Fourier-, Mellin-, and Z-transforms are at bottom the same subject. However, a different point of view and different characteristic problems are associated with each of these four major integral transforms.\n\n== Table of selected Laplace transforms ==\n{{main article|List of Laplace transforms}}\n\nThe following table provides Laplace transforms for many common functions of a single variable.<ref>{{Citation |edition=3rd |page=455 |first1=K. F. |last1=Riley |first2=M. P. |last2=Hobson |first3=S. J. |last3=Bence |title=Mathematical methods for physics and engineering |publisher=Cambridge University Press |year=2010 |isbn=978-0-521-86153-3}}</ref><ref>{{Citation |first1=J. J. |last1=Distefano |first2=A. R. |last2=Stubberud |first3=I. J. |last3=Williams |page=78 |title=Feedback systems and control |edition=2nd |publisher=McGraw-Hill |series=Schaum's outlines |year=1995 |isbn=978-0-07-017052-0}}</ref> For definitions and explanations, see the ''Explanatory Notes'' at the end of the table.\n\nBecause the Laplace transform is a linear operator,\n\n* The Laplace transform of a sum is the sum of Laplace transforms of each term.\n\n:: <math>\\mathcal{L}\\{f(t) + g(t)\\}  = \\mathcal{L}\\{f(t)\\} + \\mathcal{L}\\{ g(t)\\}  </math>\n\n* The Laplace transform of a multiple of a function is that multiple times the Laplace transformation of that function.\n\n:: <math>\\mathcal{L}\\{a f(t)\\}  = a \\mathcal{L}\\{ f(t)\\}</math>\n\nUsing this linearity, and various [[List of trigonometric identities|trigonometric]], [[Hyperbolic function|hyperbolic]], and complex number (etc.) properties and/or identities, some Laplace transforms can be obtained from others more quickly than by using the definition directly.\n\nThe unilateral Laplace transform takes as input a function whose time domain is the [[non-negative]] reals, which is why all of the time domain functions in the table below are multiples of the Heaviside step function, {{math|''u''(''t'')}}.\n\nThe entries of the table that involve a time delay {{math|''\u03c4''}} are required to be [[causal system|causal]] (meaning that {{math|''\u03c4'' > 0}}).  A causal system is a system where the [[impulse response]] {{math|''h''(''t'')}} is zero for all time {{mvar|t}} prior to {{math|1=''t'' = 0}}. In general, the region of convergence for causal systems is not the same as that of [[anticausal system]]s.\n\n{| class=\"wikitable\"\n|-\n! Function\n! Time domain <br> <math>f(t) = \\mathcal{L}^{-1}\\{F(s)\\}</math> \n! Laplace {{math|s}}-domain <br> <math>F(s) = \\mathcal{L}\\{f(t)\\}</math> \n! Region of convergence \n! Reference\n\n|- style=\"text-align:center;\"\n| unit impulse\n|| <math> \\delta(t) \\ </math> \n|| <math> 1  </math> \n|| all {{math|''s''}}\n|| inspection\n\n|- style=\"text-align:center;\"\n| delayed impulse \n|| <math> \\delta(t - \\tau) \\ </math> \n|| <math> e^{-\\tau s} \\ </math> \n|| \n|| time shift of<br>unit impulse\n\n|- style=\"text-align:center;\"\n| unit step\n|| <math> u(t) \\ </math> \n|| <math> { 1 \\over s } </math> \n|| {{math|Re(''s'') > 0}}\n|| integrate unit impulse\n\n|- style=\"text-align:center;\"\n| delayed unit step \n|| <math> u(t - \\tau) \\ </math> \n|| <math> \\frac 1 s e^{-\\tau s} </math> \n|| {{math|Re(''s'') > 0}} \n|| time shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| [[ramp function|ramp]] \n|| <math> t \\cdot u(t)\\ </math> \n|| <math>\\frac 1 {s^2}</math> \n|| {{math|Re(''s'') > 0}}\n|| integrate unit<br>impulse twice\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th power <br /> (for integer {{math|''n''}}) \n|| <math> t^n \\cdot u(t) </math> \n|| <math> { n! \\over s^{n + 1} } </math> \n|| {{math|Re(''s'') > 0}}   <br /> ({{math|''n'' > \u22121}})\n|| Integrate unit<br>step {{math|''n''}} times\n\n|- style=\"text-align:center;\"\n| {{math|''q''}}th power <br /> (for complex {{math|''q''}}) \n|| <math> t^q \\cdot u(t) </math> \n|| <math> { \\Gamma(q + 1) \\over s^{q + 1} } </math> \n|| {{math|Re(''s'') > 0}} <br /> {{math|Re(''q'') > \u22121}} \n||<ref>{{citation |title=Mathematical Handbook of Formulas and Tables |edition=3rd |first1=S. |last1=Lipschutz |first2=M. R. |last2=Spiegel |first3=J. |last3=Liu |series=Schaum's Outline Series |publisher=McGraw-Hill |page=183 |year=2009 |isbn=978-0-07-154855-7}} \u2013 provides the case for real {{math|''q''}}.</ref><ref>http://mathworld.wolfram.com/LaplaceTransform.html \u2013 Wolfram Mathword provides case for complex {{math|''q''}}</ref>\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th root \n|| <math> \\sqrt[n]{t} \\cdot u(t) </math> \n|| <math> { 1 \\over s^{\\frac 1 n + 1} } \\Gamma\\left(\\frac 1 n + 1\\right) </math> \n|| {{math|Re(''s'') > 0}} \n|| Set {{math|1=''q'' = 1/''n''}} above.\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th power with frequency shift \n|| <math>t^{n} e^{-\\alpha t} \\cdot u(t) </math> \n|| <math>\\frac{n!}{(s+\\alpha)^{n+1}}</math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| Integrate unit step,<br>apply frequency shift\n\n|- style=\"text-align:center;\"\n| delayed {{math|''n''}}th power <br /> with frequency shift \n|| <math>(t-\\tau)^n e^{-\\alpha (t-\\tau)} \\cdot u(t-\\tau) </math> \n|| <math> \\frac{n! \\cdot e^{-\\tau s}}{(s+\\alpha)^{n+1}} </math>\n|| {{math|Re(''s'') > \u2212''\u03b1''}} \n|| Integrate unit step,<br>apply frequency shift,<br>apply time shift\n\n|- style=\"text-align:center;\"\n| [[exponential decay]] \n|| <math> e^{-\\alpha t} \\cdot u(t)   </math> \n|| <math> { 1 \\over s+\\alpha } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| Frequency shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| [[Two-sided Laplace transform|two-sided]] exponential decay <br>(only for bilateral transform)\n|| <math> e^{-\\alpha|t|}  \\ </math> \n|| <math> { 2\\alpha \\over \\alpha^2 - s^2 } </math> \n|| {{math|\u2212''\u03b1'' < Re(''s'') < ''\u03b1''}} \n|| Frequency shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| exponential approach \n|| <math>( 1-e^{-\\alpha t})  \\cdot u(t)  \\ </math> \n|| <math>\\frac{\\alpha}{s(s+\\alpha)} </math> \n|| {{math|Re(''s'') > 0}}\n|| Unit step minus<br>exponential decay\n\n|- style=\"text-align:center;\"\n| [[sine]] \n|| <math> \\sin(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { \\omega \\over s^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[cosine]] \n|| <math> \\cos(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { s \\over s^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[hyperbolic sine]] \n|| <math> \\sinh(\\alpha t) \\cdot u(t) \\ </math> \n|| <math> { \\alpha \\over s^2 - \\alpha^2 } </math> \n|| {{math|Re(''s'') > {{abs|''\u03b1''}}}} \n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| [[hyperbolic cosine]] \n|| <math> \\cosh(\\alpha t) \\cdot u(t) \\ </math> \n|| <math> { s \\over s^2 - \\alpha^2  } </math> \n|| {{math|Re(''s'') > {{abs|''\u03b1''}}}}\n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| exponentially decaying <br /> sine wave \n|| <math>e^{-\\alpha t}  \\sin(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { \\omega \\over (s+\\alpha )^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}} \n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| exponentially decaying <br /> cosine wave \n|| <math>e^{-\\alpha t}  \\cos(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { s+\\alpha \\over (s+\\alpha )^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[natural logarithm]] \n|| <math> \\ln (t) \\cdot u(t) </math> \n|| <math> - { 1 \\over s}\\, \\left[ \\ln(s)+\\gamma \\right] </math> \n|| {{math|Re(''s'') > 0}} \n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| [[Bessel function]] <br> of the first kind, <br /> of order ''n'' \n|| <math> J_n( \\omega t) \\cdot u(t)</math> \n|| <math>\\frac{ \\left(\\sqrt{s^2+ \\omega^2}-s\\right)^n}{\\omega^n \\sqrt{s^2 + \\omega^2}}</math> \n|| {{math|Re(''s'') > 0}}   <br /> ({{math|''n'' > \u22121}}) \n|| {{Harvnb|Williams|1973|p=89}}\n\n|- style=\"text-align:center;\"\n| [[Error function]] \n|| <math> \\operatorname{erf}(t) \\cdot u(t) </math> \n|| <math> \\frac 1 s e^{(1/4)s^2} \\left(1 - \\operatorname{erf} \\frac s 2 \\right)</math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Williams|1973|p=89}}\n\n|-\n| colspan=5|'''Explanatory notes:'''\n{{col-begin}}\n{{col-break}}\n\n* {{math|''u''(''t'')}} represents the [[Heaviside step function]].\n* {{math|''\u03b4''}}  represents the [[Dirac delta function]].\n* {{math|\u0393(''z'')}} represents the [[gamma function]].\n* {{math|''\u03b3''}} is the [[Euler&ndash;Mascheroni constant]].\n\n{{col-break}}\n\n*  {{math|''t''}}, a real number, typically represents ''time'', <br />although it can represent ''any'' independent dimension.\n*  {{math|''s''}} is the [[complex number|complex]] frequency domain parameter, and  {{math|Re(''s'')}} is its [[real part]].\n*  {{math|''\u03b1'', ''\u03b2'', ''\u03c4,'' and ''\u03c9''}} are [[real numbers]].\n*  {{math|''n''}} is an [[integer]].\n\n{{col-end}}\n|}\n\n== ''s''-domain equivalent circuits and impedances ==\nThe Laplace transform is often used in circuit analysis, and simple conversions to the {{math|''s''}}-domain of circuit elements can be made. Circuit elements can be transformed into [[Electrical impedance|impedance]]s, very similar to [[Phasor (sine waves)|phasor]] impedances.\n\nHere is a summary of equivalents:\n\n: [[File:S-Domain circuit equivalents.svg|alt={{math|''s''}}-domain equivalent circuits|centre|frameless|400x400px|{{math|''s''}}-domain equivalent circuits]]\n\nNote that the resistor is exactly the same in the time domain and the {{math|''s''}}-domain. The sources are put in if there are initial conditions on the circuit elements. For example, if a capacitor has an initial voltage across it, or if the inductor has an initial current through it, the sources inserted in the {{math|''s''}}-domain account for that.\n\nThe equivalents for current and voltage sources are simply derived from the transformations in the table above.\n\n== Examples and applications ==\n<!--A few worked examples are provided here to enable the reader to assess comprehension of the factual presentation.  Elaboration beyond the role of supporting factual comprehension belongs at [[v:|Wikiversity]] or [[b:|Wikibooks]].-->\n\nThe Laplace transform is used frequently in [[engineering]] and [[physics]]; the output of a [[linear time-invariant]] system can be calculated by convolving its unit impulse response with the input signal. Performing this calculation in Laplace space turns the convolution into a multiplication; the latter being easier to solve because of its algebraic form. For more information, see [[control theory]].\n\nThe Laplace transform can also be used to solve differential equations and is used extensively in [[mechanical engineering]] and [[electrical engineering]].  The Laplace transform reduces a linear differential equation to an algebraic equation, which can then be solved by the formal rules of algebra.  The original differential equation can then be solved by applying the inverse Laplace transform.  The English electrical engineer Oliver Heaviside first proposed a similar scheme, although without using the Laplace transform; and the resulting operational calculus is credited as the Heaviside calculus.\n\n=== Evaluating improper integrals ===\nLet <math>\\mathcal{L}\\left\\{f(t)\\right\\} = F(s)</math>. Then (see the table above)\n\n:<math>\\mathcal{L} \\left\\{\\frac{f(t)} t \\right\\} = \\int_0^\\infty \\frac{f(t)}{t}e^{-st}\\, dt = \\int_s^\\infty F(p)\\, dp.</math>\n\nIn the limit <math>s \\rightarrow 0</math>, one gets\n\n:<math>\\int_0^\\infty \\frac{f(t)} t \\, dt = \\int_0^\\infty F(p)\\, dp,</math>\n\nprovided that the interchange of limits can be justified. Even when the interchange cannot be justified the calculation can be suggestive. For example, with ''a''&nbsp;\u2260&nbsp;0&nbsp;\u2260&nbsp;''b'', proceeding formally one has\n\n:<math>\n\\begin{align}\n\\lim_{p \\rightarrow 0} \\int_0^\\infty \\frac{ \\cos(at) - \\cos(bt) }{t} \\, dt \n&= \\lim_{p \\rightarrow 0} \\int_0^\\infty \\left(\\frac p {p^2 + a^2} - \\frac{p}{p^2 + b^2}\\right)\\, dp \\\\[6pt]\n&= \\lim_{p \\rightarrow 0} \\Biggl[ \\frac 1 2 \\left. \\ln\\frac{p^2 + a^2}{p^2 + b^2} \\right|_{0}^\\infty \\Biggl] = \\frac{1}{2} \\ln \\frac{a^2}{b^2} = \\ln \\Biggl| \\frac {a}{b} \\Biggl|.\n\\end{align}\n</math>\n\nThe validity of this identity can be proved by other means. It is an example of a [[Frullani integral]].\n\nAnother example is [[Dirichlet integral]].\n\n=== Complex impedance of a capacitor ===\nIn the theory of [[electrical circuit]]s, the current flow in a [[capacitor]] is proportional to the capacitance and rate of change in the electrical potential (in [[International System of Units|SI]] units). Symbolically, this is expressed by the differential equation\n\n: <math>i = C { dv \\over dt} ,</math>\n\nwhere {{math|''C''}} is the capacitance (in [[farad]]s) of the capacitor, {{math|1=''i'' = ''i''(''t'')}} is the [[electric current]] (in [[ampere]]s) through the capacitor as a function of time, and {{math|1=''v'' = ''v''(''t'')}} is the [[electrostatic potential|voltage]] (in [[volt]]s) across the terminals of the capacitor, also as a function of time.\n\nTaking the Laplace transform of this equation, we obtain\n\n: <math>I(s) = C(s V(s) - V_0),</math>\n\nwhere\n\n: <math>\\begin{align}\n  I(s) &= \\mathcal{L} \\{ i(t) \\},\\\\\n  V(s) &= \\mathcal{L} \\{ v(t) \\},\n\\end{align}</math>\n\nand\n\n: <math>V_0 = v(t)\\Big|_{t=0}. \\, </math>\n\nSolving for {{math|''V''(''s'')}} we have\n\n: <math>V(s) = { I(s) \\over sC } + { V_0 \\over s }.</math>\n\nThe definition of the complex impedance {{math|''Z''}} (in [[ohm]]s) is the ratio of the complex voltage {{math|''V''}} divided by the complex current {{math|''I''}} while holding the initial state {{math|''V''<sub>0</sub>}} at zero:\n\n: <math>Z(s) = \\left. { V(s) \\over I(s) } \\right|_{V_0 = 0}.</math>\n\nUsing this definition and the previous equation, we find:\n\n: <math>Z(s) = \\frac{1}{sC}, </math>\n\nwhich is the correct expression for the complex impedance of a capacitor. \nIn addition, the Laplace transform has large applications in control theory.\n\n=== Partial fraction expansion ===\n<!-- [[Partial fractions in Laplace transforms]] redirect here -->\nConsider a linear time-invariant system with [[transfer function]]\n: <math>H(s) = \\frac{1}{(s + \\alpha)(s + \\beta)}.</math>\n\nThe [[impulse response]] is simply the inverse Laplace transform of this transfer function:\n: <math>h(t) = \\mathcal{L}^{-1}\\{H(s)\\}.</math>\n\nTo evaluate this inverse transform, we begin by expanding {{math|''H''(''s'')}} using the method of partial fraction expansion,\n\n: <math>\\frac{1}{(s + \\alpha)(s + \\beta)} = { P \\over s + \\alpha } + { R \\over s+\\beta }.</math>\n\nThe unknown constants {{math|''P''}} and {{math|''R''}} are the [[residue (complex analysis)|residue]]s located at the corresponding poles of the transfer function. Each residue represents the relative contribution of that [[mathematical singularity|singularity]] to the transfer function's overall shape.\n\nBy the [[residue theorem]], the inverse Laplace transform depends only upon the poles and their residues. To find the residue {{math|''P''}}, we multiply both sides of the equation by {{math|''s'' + ''\u03b1''}} to get\n: <math>\\frac{1}{s + \\beta} = P  + { R (s + \\alpha) \\over s + \\beta }.</math>\n\nThen by letting {{math|1=''s'' = \u2212''\u03b1''}}, the contribution from {{math|''R''}} vanishes and all that is left is\n: <math>P = \\left.{1 \\over s+\\beta}\\right|_{s=-\\alpha} = {1 \\over \\beta - \\alpha}.</math>\n\nSimilarly, the residue {{math|''R''}} is given by\n: <math>R = \\left.{1 \\over s + \\alpha}\\right|_{s=-\\beta} = {1 \\over \\alpha - \\beta}.</math>\n\nNote that\n: <math>R = {-1 \\over \\beta - \\alpha} = - P</math>\nand so the substitution of {{math|''R''}} and {{math|''P''}} into the expanded expression for {{math|''H''(''s'')}} gives\n: <math>H(s)  = \\left( \\frac{1}{\\beta - \\alpha} \\right) \\cdot \\left(  { 1 \\over s + \\alpha } - { 1  \\over s + \\beta }  \\right).</math>\n\nFinally, using the linearity property and the known transform for exponential decay (see ''Item'' #''3'' in the ''Table of Laplace Transforms'', above), we can take the inverse Laplace transform of {{math|''H''(''s'')}} to obtain\n: <math>h(t) = \\mathcal{L}^{-1}\\{H(s)\\} = \\frac{1}{\\beta - \\alpha}\\left(e^{-\\alpha t} - e^{-\\beta t}\\right),</math>\nwhich is the impulse response of the system.\n\n;Convolution\nThe same result can be achieved using the [[Convolution theorem|convolution property]] as if the system is a series of filters with transfer functions of {{math|1/(''s'' + ''a'')}} and {{math|1/(''s'' + ''b'')}}. That is, the inverse of\n\n: <math>H(s) = \\frac{1}{(s + a)(s + b)} = \\frac{1}{s+a} \\cdot \\frac{1}{s + b}</math>\n\nis\n\n: <math> \\mathcal{L}^{-1}\\! \\left\\{ \\frac{1}{s + a} \\right\\} * \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s + b} \\right\\} = e^{-at} * e^{-bt} = \\int_0^t e^{-ax}e^{-b(t - x)}\\, dx = \\frac{e^{-a t}-e^{-b t}}{b - a}.</math>\n\n=== Phase delay ===\n{| class=\"wikitable\"\n|-\n! Time function\n! Laplace transform\n|-\n| <math>\\sin{(\\omega t + \\varphi)}</math>\n| <math>\\frac{s\\sin(\\varphi) + \\omega \\cos(\\varphi)}{s^2 + \\omega^2}</math>\n|-\n| <math>\\cos{(\\omega t + \\varphi)}</math>\n| <math>\\frac{s\\cos(\\varphi) - \\omega \\sin(\\varphi)}{s^2 + \\omega^2}.</math>\n|}\n\nStarting with the Laplace transform,\n\n: <math>X(s) = \\frac{s\\sin(\\varphi) + \\omega \\cos(\\varphi)}{s^2 + \\omega^2}</math>\n\nwe find the inverse by first rearranging terms in the fraction:\n\n: <math>\\begin{align}\n  X(s) &= \\frac{s \\sin(\\varphi)}{s^2 + \\omega^2} + \\frac{\\omega \\cos(\\varphi)}{s^2 + \\omega^2} \\\\\n       &= \\sin(\\varphi) \\left(\\frac{s}{s^2 + \\omega^2} \\right) + \\cos(\\varphi) \\left(\\frac{\\omega}{s^2 + \\omega^2} \\right).\n\\end{align}</math>\n\nWe are now able to take the inverse Laplace transform of our terms:\n\n: <math>\\begin{align}\n  x(t) &= \\sin(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{s}{s^2 + \\omega^2} \\right\\} + \\cos(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{\\omega}{s^2 + \\omega^2} \\right\\} \\\\\n       &= \\sin(\\varphi)\\cos(\\omega t) + \\sin(\\omega t)\\cos(\\varphi).\n\\end{align}</math>\n\nThis is just the [[Trigonometric identity#Angle sum and difference identities|sine of the sum]] of the arguments, yielding:\n\n:<math>x(t) = \\sin (\\omega t + \\varphi).</math>\n\nWe can apply similar logic to find that\n\n: <math>\\mathcal{L}^{-1} \\left\\{ \\frac{s\\cos\\varphi - \\omega \\sin\\varphi}{s^2 + \\omega^2} \\right\\} = \\cos{(\\omega t + \\varphi)}.</math>\n\n=== {{Anchor|Inferring spatial structure from spectrum}}Determining structure of astronomical object from spectrum ===\nThe wide and general applicability of the Laplace transform and its inverse is illustrated by an application in astronomy which provides some information on the ''spatial distribution'' of matter of an [[Astronomy|astronomical]] source of [[Radio frequency|radio-frequency]] [[thermal radiation]] too distant to [[Angular resolution|resolve]] as more than a point, given its [[flux density]] [[spectrum]], rather than relating the ''time'' domain with the spectrum (frequency domain).\n\nAssuming certain properties of the object, e.g. spherical shape and constant temperature, calculations based on carrying out an inverse Laplace transformation on the spectrum of the object can produce the only possible [[Mathematical model|model]] of the distribution of matter in it (density as a function of distance from the center) consistent with the spectrum.<ref>{{citation |first1=M. |last1=Salem |first2=M. J. |last2=Seaton |year=1974 |title=I. Continuum spectra and brightness contours |journal=[[Monthly Notices of the Royal Astronomical Society]] |volume=167 |issue=3 |pages=493\u2013510 |doi=10.1093/mnras/167.3.493 |bibcode=1974MNRAS.167..493S}}, and<br/>{{citation |first1=M. |last1=Salem |year=1974 |title=II. Three-dimensional models |journal=Monthly Notices of the Royal Astronomical Society |volume=167 |issue=3 |pages=511\u2013516 |doi=10.1093/mnras/167.3.511 |bibcode=1974MNRAS.167..511S}}</ref> When independent information on the structure of an object is available, the inverse Laplace transform method has been found to be in good agreement.\n\n=== Statistical mechanics ===\nIn [[statistical mechanics]], the Laplace transform of the density of states <math>g(E)dE</math> defines the [[partition function (statistical mechanics)|partition function]].<ref>{{cite book|author1=RK Pathria|author2=Paul Beal|title=Statistical mechanics|edition=2nd|publisher=Butterworth-Heinemann|year=1996|page=56}}</ref> That is, the partition function <math>Z(\\beta)</math> is given by\n:<math> Z(\\beta) = \\int_0^\\infty e^{-\\beta E}g(E)dE</math>\nand the inverse is given by\n:<math> g(E) = \\frac{1}{2\\pi i} \\int_{\\beta_0-i\\infty}^{\\beta_0+i\\infty} e^{\\beta E}Z(\\beta) d\\beta</math>\n\n==Gallery==\n{{Gallery|width=265 | height=150 |lines=2 |align=center|File:Graph of e^t cos(10t).png|An example curve of e^t cos(10t) that is added together with similar curves to form a Laplace Transform.|File:Laplace animation of Cubic Polynomial.gif|Animation showing how adding together curves can approximate a function.}}\n\n== See also ==\n{{Portal|Mathematics}}\n{{div col}}\n* [[Analog signal processing]]\n* [[Bernstein's theorem on monotone functions]]\n* [[Continuous-repayment mortgage#Mortgage difference and differential equation|Continuous-repayment mortgage]]\n* [[Hamburger moment problem]]\n* [[Hardy\u2013Littlewood tauberian theorem]]\n* [[Laplace\u2013Carson transform]]\n* [[Moment-generating function]]\n* [[Nonlocal operator]]\n* [[Post's inversion formula]]\n* [[Signal-flow graph]]\n{{div col end}}\n\n== Notes ==\n{{Reflist|30em}}\n\n== References ==\n\n=== Modern ===\n* {{Citation |last=Bracewell |first=Ronald N. |title=The Fourier Transform and its Applications |edition=2nd |year=1978 |publisher=McGraw-Hill Kogakusha |isbn=978-0-07-007013-4 }}<!-- This edition is used for pinpoint citations in the transform table. -->\n* {{citation|first=R. N.|last=Bracewell|title=The Fourier Transform and Its Applications|edition=3rd|location=Boston|publisher=McGraw-Hill|year=2000|isbn=978-0-07-116043-8}}\n* {{Citation | last1=Feller | first1=William | author1-link=William Feller | title=An introduction to probability theory and its applications. Vol. II. | publisher=[[John Wiley & Sons]] | location=New York | series=Second edition | mr=0270403  | year=1971}}\n* {{citation |first1=G. A. |last1=Korn |first2=T. M. |last2=Korn |title=Mathematical Handbook for Scientists and Engineers |publisher=McGraw-Hill Companies |edition=2nd |year=1967 |isbn=978-0-07-035370-1 }}\n* {{Citation | last1=Widder | first1=David Vernon | title=The Laplace Transform | publisher=[[Princeton University Press]] | series=Princeton Mathematical Series, v. 6 | mr=0005923  | year=1941}}\n* {{Citation | last=Williams |first=J. |title=Laplace Transforms |series=Problem Solvers |volume= |publisher=George Allen & Unwin |year=1973 |isbn= 978-0-04-512021-5 }}\n* {{Citation | last=Takacs | first= J.|title=Fourier amplitudok meghatarozasa operatorszamitassal | year=1953 | journal=Magyar Hiradastechnika | volume=IV | issue=7\u20138|pages=93\u201396 |language=Hungarian }}\n\n=== Historical ===\n<!-- Citations to Opera omnia [The Complete Works] are wrong. Opera omnia was published 1911 and after, so the citations should be |origyear=17xx |year=1992... Handling of Euler's volume number and Opera omnia volume is problematic -->\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |year=1744 |title=De constructione aequationum |trans-title=The Construction of Equations |language=la |journal=Opera Omnia |series=1st series |volume=22 |pages=150\u2013161}}\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |year=1753 |title=Methodus aequationes differentiales |trans-title=A Method for Solving Differential Equations |language=la |journal=Opera Omnia |series=1st series |volume=22 |pages=181\u2013213}}\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |origyear=1769 |title=Institutiones calculi integralis, Volume 2 |trans-title=Institutions of Integral Calculus |language=la |journal=Opera Omnia |series=1st series |volume=12 |year=1992 |location=Basel |publisher=Birkh\u00e4user |isbn=978-3764314743 <!-- isbn for the entire first series-->}}, Chapters 3\u20135\n* {{citation |last=Euler |first=Leonhard |authorlink=Leonhard Euler |year=1769 |title=Institutiones calculi integralis |trans-title=Institutions of Integral Calculus |language=la |volume=II <!--Secundum--> |at=ch. 3\u20135, pp. 57\u2013153 |location=Paris |publisher=Petropoli |url=https://books.google.com/books?id=BFqWNwpfqo8C }}\n* {{citation|last=Grattan-Guinness|first=I|authorlink=Ivor Grattan-Guinness|year=1997|contribution=Laplace's integral solutions to partial differential equations|editor=Gillispie, C. C.|title=Pierre Simon Laplace 1749\u20131827: A Life in Exact Science|location=Princeton|publisher=Princeton University Press|isbn=978-0-691-01185-1}}\n* {{citation|last=Lagrange|first=J. L.|authorlink=Joseph Louis Lagrange|year=1773|title=M\u00e9moire sur l'utilit\u00e9 de la m\u00e9thode|series=\u0152uvres de Lagrange|volume=2|pages=171\u2013234}}\n\n==Further reading==\n* {{citation|first1=Wolfgang|last1=Arendt|first2=Charles J.K.|last2=Batty|first3=Matthias|last3=Hieber|first4=Frank|last4=Neubrander|title=Vector-Valued Laplace Transforms and Cauchy Problems|publisher=Birkh\u00e4user Basel|year=2002|isbn=978-3-7643-6549-3 |ref=none}}.\n* {{citation|last=Davies|first=Brian|title=Integral transforms and their applications|edition=Third|publisher=Springer|location=New York|year=2002|isbn= 978-0-387-95314-4 |ref=none}}\n* {{citation | last=Deakin|first= M. A. B. | year=1981 | title=The development of the Laplace transform | journal=Archive for History of Exact Sciences | volume=25 | pages=343\u2013390 | doi=10.1007/BF01395660 | issue=4 |ref=none}}\n* {{citation | last=Deakin|first= M. A. B. | year=1982 | title=The development of the Laplace transform | journal=Archive for History of Exact Sciences | volume=26 | pages=351\u2013381 | doi=10.1007/BF00418754 | issue=4 |ref=none}}\n* {{citation |last=Doetsch |first=Gustav |authorlink=Gustav Doetsch |date=1974 |title=Introduction to the Theory and Application of the Laplace Transformation |publisher=Springer |isbn=978-0-387-06407-9 |ref=none}}\n* Mathews, Jon; Walker, Robert L. (1970), ''Mathematical methods of physics'' (2nd ed.), New York: W. A. Benjamin, {{isbn|0-8053-7002-1}}\n* {{citation|first1=A. D.|last1=Polyanin|first2=A. V.|last2=Manzhirov|title=Handbook of Integral Equations|publisher=CRC Press|location=Boca Raton|year=1998|isbn=978-0-8493-2876-3 |ref=none}}\n* {{Citation | last1=Schwartz | first1=Laurent | author-link=Laurent Schwartz | title=Transformation de Laplace des distributions | mr=0052555  | year=1952 | journal=Comm. S\u00e9m. Math. Univ. Lund [Medd. Lunds Univ. Mat. Sem.] | volume=1952 | pages=196\u2013206 |language=French |ref=none}}\n* {{Citation |last=Schwartz |first=Laurent |author-link=Laurent Schwartz |year=2008 |origyear=1966 |title=Mathematics for the Physical Sciences |publisher=Dover Publications |location=New York |series=Dover Books on Mathematics |pages=215\u2013241 |isbn=978-0-486-46662-0 |url={{Google books|-_AuDQAAQBAJ|Mathematics for the Physical Sciences|page=215|plainurl=yes}} |ref=none}} - See Chapter VI. The Laplace transform.\n* {{citation|first=William McC.|last=Siebert|title=Circuits, Signals, and Systems|publisher=MIT Press|location=Cambridge, Massachusetts|year=1986|isbn=978-0-262-19229-3 |ref=none}}\n* {{Citation | last1=Widder | first1=David Vernon | title=What is the Laplace transform? | mr=0013447  | year=1945 | journal=[[American Mathematical Monthly|The American Mathematical Monthly]] | issn=0002-9890 |volume=52 |issue=8 | pages=419\u2013425 | doi=10.2307/2305640 | jstor=2305640 |ref=none}}\n\n== External links ==\n{{wikiquote}}\n{{commons category|Laplace transformation}}\n* {{springer|title=Laplace transform|id=p/l057540}}\n* [http://wims.unice.fr/wims/wims.cgi?lang=en&+module=tool%2Fanalysis%2Ffourierlaplace Online Computation] of the transform or inverse transform, wims.unice.fr\n* [http://eqworld.ipmnet.ru/en/auxiliary/aux-inttrans.htm Tables of Integral Transforms] at EqWorld: The World of Mathematical Equations.\n* {{MathWorld|title=Laplace Transform|urlname=LaplaceTransform}}\n* [http://fourier.eng.hmc.edu/e102/lectures/Laplace_Transform/ Good explanations of the initial and final value theorems]\n* [http://www.mathpages.com/home/kmath508/kmath508.htm Laplace Transforms] at MathPages\n* [http://www.wolframalpha.com/input/?i=laplace+transform+example Computational Knowledge Engine] allows to easily calculate Laplace Transforms and its inverse Transform.\n* [http://www.laplacetransformcalculator.com/easy-laplace-transform-calculator/ Laplace Calculator] to calculate Laplace Transforms online easily.\n* [https://johnflux.com/2019/02/12/laplace-transform-visualized/ Code to visualize Laplace Transforms] and many example videos.\n\n{{Authority control}}\n\n{{DEFAULTSORT:Laplace Transform}}\n[[Category:Laplace transforms| ]]\n[[Category:Differential equations]]\n[[Category:Fourier analysis]]\n[[Category:Mathematical physics]]\n", "text_old": "{{redirect|\u2112|the Lagrangian|Lagrangian mechanics}}\nIn [[mathematics]], the '''Laplace transform''' is an [[integral transform]] named after its inventor [[Pierre-Simon Laplace]] ({{IPAc-en|l|\u0259|\u02c8|p|l|\u0251:|s}}).  It transforms a function of a real variable {{math|''t''}} (often time) to a function of a [[complex analysis|complex variable]] {{mvar|s}} ([[complex frequency]]). The transform has many applications in science and engineering.\n\nThe Laplace transform is similar to the [[Fourier transform]].  While the Fourier transform of a function is a [[complex function]] of a ''real'' variable (frequency), the Laplace transform of a function is a complex function of a ''complex'' variable. The Laplace transform is usually restricted to transformation of functions of {{math|''t''}} with {{math|''t'' \u2265 0}}.  A consequence of this restriction is that the Laplace transform of a function is a [[holomorphic function]] of the variable {{math|''s''}}.  Unlike the Fourier transform, the Laplace transform of a [[distribution (mathematics)|distribution]] is generally a [[well-behaved]] function.  Techniques of complex variables can also be used to  directly study Laplace transforms.  As a holomorphic function, the Laplace transform has a [[power series]] representation.  This power series expresses a function as a linear superposition of [[moment (mathematics)|moments]] of the function.  This perspective has applications in [[probability theory]].\n\nThe Laplace transform is invertible on a large class of functions. The inverse Laplace transform takes a function of a complex variable {{math|''s''}} (often frequency) and yields a function of a real variable {{math|''t''}} (often time).  Given a simple mathematical or functional description of an input or output to a [[system]], the Laplace transform provides an alternative functional description that often simplifies the process of analyzing the behavior of the system, or in synthesizing a new system based on a set of specifications.<ref>{{harvnb|Korn|Korn|1967|loc=\u00a78.1}}</ref>  So, for example, the Laplace transformation from the [[time domain]] to the [[frequency domain]] transforms [[Differential equation|differential equations]] into algebraic equations and [[convolution]] into multiplication.\n\nLaplace wrote extensively about the use of [[Generating function|generating functions]] in ''Essai philosophique sur les probabilit\u00e9s'' (1814) and the integral form of the Laplace transform evolved naturally as a result.<ref>{{Cite book|title=Probability theory : the logic of science|last=Jaynes, E. T. (Edwin T.)|date=2003|publisher=Cambridge University Press|others=Bretthorst, G. Larry|isbn=0511065892|location=Cambridge, UK|oclc=57254076}}</ref>\n\n== History ==\nThe Laplace transform is named after mathematician and astronomer Pierre-Simon Laplace, who used a similar transform in his work on probability theory.<ref>{{citation |url=https://archive.org/details/thorieanalytiqu01laplgoog |title=Th\u00e9orie analytique des Probabilit\u00e9s |location=Paris |date=1814 |edition=2nd |at=chap.I sect.2-20 |chapter=Des Fonctions g\u00e9n\u00e9ratrices |trans-title=Analytical Probability Theory |trans-chapter=On generating functions |language=fr}}</ref> Laplace's use of generating functions was similar to what is now known as the [[z-transform]] and he gave little attention to the continuous variable case which was discussed by [[Niels Henrik Abel]].<ref>{{citation |first=Niels H. |last=Abel|authorlink=Niels Henrik Abel |chapter=Sur les fonctions g\u00e9n\u00e9ratrices et leurs d\u00e9terminantes |date=1820 |title=\u0152uvres Compl\u00e8tes |language=fr |publication-date=1839 |volume=II |pages=77\u201388}} [https://books.google.com/books?id=6FtDAQAAMAAJ&pg=RA2-PA67&lpg=RA2-PA67 1881 edition]</ref> The theory was further developed in the 19th and early 20th centuries by [[Mathias Lerch]],<ref>{{citation |first=Mathias |last=Lerch |author-link=Mathias Lerch |title=Sur un point de la th\u00e9orie des fonctions g\u00e9n\u00e9ratrices d'Abel |journal=[[Acta Mathematica]] |volume=27 |date=1903 |pages=339\u2013351 |doi=10.1007/BF02421315 |trans-title=Proof of the inversion formula |language=fr}}</ref> [[Oliver Heaviside]],<ref>{{citation |first=Oliver |last=Heaviside |author-link=Oliver Heaviside |chapter=The solution of definite integrals by differential transformation |title=Electromagnetic Theory |location=London |at=section 526 |volume=III |chapter-url=https://books.google.com/books?id=y9auR0L6ZRcC&pg=PA234&lpg=PA234|isbn=9781605206189 |date=January 2008 }}</ref> and [[Thomas John I'Anson Bromwich|Thomas Bromwich]].<ref>{{citation |first=Thomas J. |last=Bromwich |author-link=Thomas John I'Anson Bromwich |title=Normal coordinates in dynamical systems |journal=[[Proceedings of the London Mathematical Society]] |volume=15 |pages=401\u2013448 |date=1916 |doi=10.1112/plms/s2-15.1.401|url=https://zenodo.org/record/2319588 }}</ref> The current widespread use of the transform (mainly in engineering) came about during and soon after World War II<ref>An influential book was: {{citation |first=Murray F. |last=Gardner |first2=John L. |last2=Barnes |title=Transients in Linear Systems studied by the Laplace Transform |date=1942 |location=New York |publisher=Wiley}}</ref> replacing the earlier Heaviside operational calculus. The advantages of the Laplace transform had been emphasized by [[Gustav Doetsch]]<ref>{{citation |first=Gustav |last=Doetsch |title=Theorie und Anwendung der Laplacesche Transformation |location=Berlin |date=1937 |publisher=Springer |language=de |trans-title=Theory and Application of the Laplace Transform}} translation 1943</ref> to whom the name Laplace Transform is apparently due.  \n\nFrom 1744, [[Leonhard Euler]] investigated integrals of the form\n: <math> z = \\int X(x) e^{ax}\\, dx \\quad\\text{ and }\\quad z = \\int X(x) x^A \\, dx</math>\nas solutions of differential equations but did not pursue the matter very far.<ref>{{harvnb|Euler|1744}}, {{harvnb|Euler|1753}}, {{harvnb|Euler|1769}}</ref> [[Joseph Louis Lagrange]] was an admirer of Euler and, in his work on integrating [[probability density function]]s, investigated expressions of the form\n: <math> \\int X(x) e^{- a x } a^x\\, dx,</math>\nwhich some modern historians have interpreted within modern Laplace transform theory.<ref>{{harvnb|Lagrange|1773}}</ref><ref>{{harvnb|Grattan-Guinness| 1997|p=260}}</ref>{{Clarify|date=May 2010}}\n\nThese types of integrals seem first to have attracted Laplace's attention in 1782 where he was following in the spirit of Euler in using the integrals themselves as solutions of equations.<ref>{{harvnb|Grattan-Guinness|1997|p=261}}</ref> However, in 1785, Laplace took the critical step forward when, rather than just looking for a solution in the form of an integral, he started to apply the transforms in the sense that was later to become popular. He used an integral of the form\n: <math> \\int x^s \\varphi (x)\\, dx,</math>\nakin to a [[Mellin transform]], to transform the whole of a [[difference equation]], in order to look for solutions of the transformed equation. He then went on to apply the Laplace transform in the same way and started to derive some of its properties, beginning to appreciate its potential power.<ref>{{harvnb|Grattan-Guinness|1997|pp=261\u2013262}}</ref>\n\nLaplace also recognised that [[Joseph Fourier]]'s method of [[Fourier series]] for solving the [[diffusion equation]] could only apply to a limited region of space because those solutions were [[Periodic function|periodic]]. In 1809, Laplace applied his transform to find solutions that diffused indefinitely in space.<ref>{{harvnb|Grattan-Guinness|1997|pp=262&ndash;266}}</ref>\n\n== Formal definition ==\nThe Laplace transform of a [[function (mathematics)|function]] {{math|''f''(''t'')}}, defined for all [[real number]]s {{math|''t'' \u2265 0}}, is the function {{math|''F''(''s'')}}, which is a unilateral transform defined by\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>F(s) =\\int_0^\\infty f(t)e^{-st} \\, dt</math>|{{EquationRef|Eq.1}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere ''s'' is a [[complex number]] frequency parameter\n: <math>s = \\sigma + i \\omega</math>, with real numbers {{math|''\u03c3''}} and {{math|''\u03c9''}}.\n\nAn alternate notation for the Laplace transform is <math>\\mathcal{L}\\{f\\}</math> instead of {{math|''F''}}.\n\nThe meaning of the integral depends on types of functions of interest.  A necessary condition for existence of the integral is that {{math|''f''}} must be [[locally integrable]] on {{closed-open|0, \u221e}}.  For locally integrable functions that decay at infinity or are of [[exponential type]], the integral can be understood to be a (proper) [[Lebesgue integral]]. However, for many applications it is necessary to regard it as a [[conditionally convergent]] [[improper integral]] at {{math|\u221e}}.  Still more generally, the integral can be understood in a [[distribution (mathematics)|weak sense]], and this is dealt with below.\n\nOne can define the Laplace transform of a finite [[Borel measure]] {{math|''\u03bc''}} by the Lebesgue integral<ref>{{harvnb|Feller|1971|loc=\u00a7XIII.1}}</ref>\n: <math>\\mathcal{L}\\{\\mu\\}(s) = \\int_{[0,\\infty)} e^{-st}\\, d\\mu(t).</math>\n\nAn important special case is where {{math|''\u03bc''}} is a [[probability measure]], for example, the [[Dirac delta function]]. In [[operational calculus]], the Laplace transform of a measure is often treated as though the measure came from a probability density function {{math|''f''}}.  In that case, to avoid potential confusion, one often writes\n: <math>\\mathcal{L}\\{f\\}(s) = \\int_{0^-}^\\infty f(t)e^{-st} \\, dt,</math>\nwhere the lower limit of {{math|0<sup>\u2212</sup>}} is shorthand notation for\n: <math>\\lim_{\\varepsilon\\rightarrow 0^+}\\int_{-\\varepsilon}^\\infty.</math>\n\nThis limit emphasizes that any point mass located at {{math|0}} is entirely captured by the Laplace transform. Although with the Lebesgue integral, it is not necessary to take such a limit, it does appear more naturally in connection with the [[Laplace\u2013Stieltjes transform]].\n\n=== Bilateral Laplace transform ===\n{{Main article|Two-sided Laplace transform}}\n\nWhen one says \"the Laplace transform\" without qualification, the unilateral or one-sided transform is normally intended. The Laplace transform can be alternatively defined as the ''bilateral Laplace transform'' or [[two-sided Laplace transform]] by extending the limits of integration to be the entire real axis.  If that is done the common unilateral transform simply becomes a special case of the bilateral transform where the definition of the function being transformed is multiplied by the [[Heaviside step function]].\nThe bilateral Laplace transform is defined as follows:\n{{math|''F''(''s'')}}, which is a bilateral transform defined by\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>F(s) = \\int_{-\\infty}^\\infty e^{-st} f(t)\\, dt</math>|{{EquationRef|Eq.2}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nAn alternate notation for the bilateral Laplace transform is <math>\\mathcal{B}\\{f\\}</math> instead of <math>F</math>.\n\n=== Inverse Laplace transform ===\n{{Main article|Inverse Laplace transform}}\nTwo integrable functions have the same Laplace transform only if they differ on a set of [[Lebesgue measure]] zero. This means that, on the range of the transform, there is an inverse transform. In fact, besides integrable functions, the Laplace transform is a [[one-to-one function|one-to-one]] mapping from one function space into another in many other function spaces as well, although there is usually no easy characterization of the range. Typical function spaces in which this is true include the spaces of bounded continuous functions, the space [[Lp space|{{math|''L''<sup>&infin;</sup>(0, &infin;)}}]], or more generally [[Distribution (mathematics)#Tempered distributions and Fourier transform|tempered distributions]] on {{open-open|0, &infin;}}.  The Laplace transform is also defined and injective for suitable spaces of tempered distributions.\n\nIn these cases, the image of the Laplace transform lives in a space of [[analytic function]]s in the [[#Region of convergence|region of convergence]].  The [[inverse Laplace transform]] is given by the following complex integral, which is known by various names (the '''Bromwich integral''', the '''Fourier\u2013Mellin integral''', and '''Mellin's inverse formula'''):\n{{Equation box 1\n|indent =\n|title=\n|equation = {{NumBlk||<math>f(t) = \\mathcal{L}^{-1}\\{F\\}(t) = \\frac{1}{2 \\pi i} \\lim_{T\\to\\infty}\\oint_{\\gamma - i T}^{\\gamma + i T} e^{st} F(s)\\, ds</math>|{{EquationRef|Eq.3}}}}\n|cellpadding= 6\n|border\n|border colour = #0073CF\n|background colour=#F5FFFA}}\nwhere {{math|''\u03b3''}} is a real number so that the contour path of integration is in the region of convergence of {{math|''F''(''s'')}}. An alternative formula for the inverse Laplace transform is given by [[Post's inversion formula]]. The limit here is interpreted in the [[weak-* topology#Weak-* topology|weak-* topology]].\n\nIn practice, it is typically more convenient to decompose a Laplace transform into known transforms of functions obtained from a table, and construct the inverse by inspection.\n\n=== Probability theory ===\nIn [[probability theory|pure]] and [[applied probability]], the Laplace transform is defined as an [[expected value]]. If {{math|''X''}} is a [[random variable]] with probability density function {{math|''f''}}, then the Laplace transform of {{math|''f''}} is given by the expectation\n: <math>\\mathcal{L}\\{f\\}(s) = \\operatorname{E}\\! \\left[e^{-sX} \\right]\\! .</math>\n\nBy [[abuse of notation|convention]], this is referred to as the Laplace transform of the random variable {{math|''X''}} itself. Replacing {{math|''s''}} by {{math|\u2212''t''}} gives the [[moment generating function]] of {{math|''X''}}. The Laplace transform has applications throughout probability theory, including [[first passage time]]s of [[stochastic processes]] such as [[Markov chain]]s, and [[renewal theory]].\n\nOf particular use is the ability to recover the [[cumulative distribution function]] of a continuous random variable {{math|''X''}} by means of the Laplace transform as follows<ref>The cumulative distribution function is the integral of the probability density function.</ref>\n: <math>F_X(x) = \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}\\operatorname{E}\\left[e^{-sX}\\right]\\right\\}\\! (x) = \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s}\\mathcal{L}\\{f\\}(s)\\right\\}\\! (x).</math>\n\n== Region of convergence ==\nIf {{math|''f''}} is a locally integrable function (or more generally a Borel measure locally of bounded variation), then the Laplace transform {{math|''F''(''s'')}} of {{math|''f''}} converges provided that the limit\n: <math>\\lim_{R\\to\\infty}\\int_0^R f(t)e^{-st}\\,dt</math>\nexists.\n\nThe Laplace transform converges absolutely if the integral\n: <math>\\int_0^\\infty \\left|f(t)e^{-st}\\right|\\,dt</math>\nexists (as a proper Lebesgue integral).  The Laplace transform is usually understood as conditionally convergent, meaning that it converges in the former instead of the latter sense.\n\nThe set of values for which {{math|''F''(''s'')}} converges absolutely is either of the form {{math|Re(''s'') > ''a''}} or else {{math|Re(''s'') \u2265 ''a''}}, where {{math|''a''}} is an [[extended real number|extended real constant]], {{math|\u2212\u221e \u2264 ''a'' \u2264 \u221e}}.  (This follows from the [[dominated convergence theorem]].) The constant {{math|''a''}} is known as the abscissa of absolute convergence, and depends on the growth behavior of {{math|''f''(''t'')}}.<ref>{{harvnb|Widder|1941|loc=Chapter II, \u00a71}}</ref> Analogously, the two-sided transform converges absolutely in a strip of the form  {{math|''a'' < Re(''s'') < ''b''}}, and possibly including the lines {{math|1=Re(''s'') = ''a''}} or {{math|1=Re(''s'') = ''b''}}.<ref>{{harvnb|Widder|1941|loc=Chapter VI, \u00a72}}</ref>  The subset of values of {{math|''s''}} for which the Laplace transform converges absolutely is called the region of absolute convergence or the domain of absolute convergence.  In the two-sided case, it is sometimes called the strip of absolute convergence. The Laplace transform is analytic in the region of absolute convergence: this is a consequence of [[Fubini's theorem]] and [[Morera's theorem]]. \n\nSimilarly, the set of values for which {{math|''F''(''s'')}} converges (conditionally or absolutely) is known as the region of conditional convergence, or simply the '''region of convergence''' (ROC).  If the Laplace transform converges (conditionally) at {{math|1=''s'' = ''s''<sub>0</sub>}}, then it automatically converges for all {{math|''s''}} with {{math|Re(''s'') > Re(''s''<sub>0</sub>)}}.  Therefore, the region of convergence is a half-plane of the form {{math|Re(''s'') > ''a''}}, possibly including some points of the boundary line {{math|1=Re(''s'') = ''a''}}.\n\nIn the region of convergence {{math|Re(''s'') > Re(''s''<sub>0</sub>)}}, the Laplace transform of {{math|''f''}} can be expressed by [[integration by parts|integrating by parts]] as the integral\n: <math>F(s) = (s-s_0)\\int_0^\\infty e^{-(s-s_0)t}\\beta(t)\\,dt,\\quad \\beta(u) = \\int_0^u e^{-s_0t}f(t)\\,dt.</math>\n\nThat is, in the region of convergence {{math|''F''(''s'')}} can effectively be expressed as the absolutely convergent Laplace transform of some other function.  In particular, it is analytic.\n\nThere are several [[Paley\u2013Wiener theorem]]s concerning the relationship between the decay properties of {{math|''f''}} and the properties of the Laplace transform within the region of convergence.\n\nIn engineering applications, a function corresponding to a [[LTI system|linear time-invariant (LTI) system]] is ''stable'' if every bounded input produces a bounded output.  This is equivalent to the absolute convergence of the Laplace transform of the impulse response function in the region {{math|Re(''s'') \u2265 0}}.  As a result, LTI systems are stable provided the poles of the Laplace transform of the impulse response function have negative real part.\n\nThis ROC is used in knowing about the causality and stability of a system.\n\n== Properties and theorems ==\nThe Laplace transform has a number of properties that make it useful for analyzing linear [[dynamical system]]s. The most significant advantage is that [[derivative|differentiation]] becomes multiplication, and [[integral|integration]] becomes division, by  {{math|''s''}} (similarly to [[logarithm]]s changing multiplication of numbers to addition of their logarithms).\n\nBecause of this property, the Laplace variable {{math|''s''}} is also known as ''operator variable'' in the {{math|''L''}} domain: either ''derivative operator'' or (for {{math|''s''<sup>\u22121</sup>)}} ''integration operator''. The transform turns [[integral equation]]s and [[differential equation]]s to [[polynomial equation]]s, which are much easier to solve.  Once solved, use of the inverse Laplace transform reverts to the original domain.\n\nGiven the functions {{math|''f''(''t'')}} and {{math|''g''(''t'')}}, and their respective Laplace transforms {{math|''F''(''s'')}} and {{math|''G''(''s'')}},\n: <math>\\begin{align}\nf(t) &= \\mathcal{L}^{-1}\\{F(s)\\},\\\\\ng(t) &= \\mathcal{L}^{-1}\\{G(s)\\},\n\\end{align}</math>\n\nThe following '''table''' is a list of properties of unilateral Laplace transform:<ref>{{harvnb|Korn|Korn|1967|pp=226&ndash;227}}</ref>\n\n{| class=\"wikitable\" id=\"291017_tableid\"\n|+ Properties of the unilateral Laplace transform\n|-\n !\n ! Time domain\n ! {{math|''s''}} domain\n ! Comment\n|-\n ! [[Linearity]]\n | <math> a f(t) + b g(t) \\ </math>\n | <math> a F(s) + b G(s) \\ </math>\n | Can be proved using basic rules of integration.\n|-\n ! Frequency-domain derivative\n | <math> t f(t) \\ </math>\n | <math> -F'(s) \\ </math>\n | {{math|''F''\u2032}} is the first derivative of {{math|''F''}} with respect to {{math|''s''}}.\n|-\n ! Frequency-domain general derivative\n | <math> t^{n} f(t) \\ </math>\n | <math> (-1)^{n} F^{(n)}(s) \\ </math>\n | More general form, {{math|''n''}}th derivative of {{math|''F''(''s'')}}.\n|-\n ! [[Derivative]]\n | <math> f'(t) \\ </math>\n | <math> s F(s) - f(0^{+}) \\ </math>\n | {{math|''f''}} is assumed to be a [[differentiable function]], and its derivative is assumed to be of exponential type.  This can then be obtained by integration by parts\n|-\n ! Second derivative\n | <math> f''(t) \\ </math>\n | <math> s^2 F(s) - s f(0^{+}) - f'(0^{+}) \\ </math>\n | {{math|''f''}} is assumed twice differentiable and the second derivative to be of exponential type. Follows by applying the Differentiation property to {{math|''f''\u2032(''t'')}}.\n|-\n ! General derivative\n | <math> f^{(n)}(t)  \\ </math>\n | <math> s^n F(s) - \\sum_{k=1}^{n} s^{n-k} f^{(k-1)}(0^{+}) \\ </math>\n | {{math|''f''}} is assumed to be {{math|''n''}}-times differentiable, with {{math|''n''}}th derivative of exponential type.  Follows by [[mathematical induction]].\n|-\n ! [[Frequency|Frequency-domain integration]]\n | <math> \\frac{1}{t}f(t)  \\ </math>\n | <math> \\int_s^\\infty F(\\sigma)\\, d\\sigma \\ </math>\n | This is deduced using the nature of frequency differentiation and conditional convergence.\n|-\n ! Time-domain [[integral|integration]]\n | <math> \\int_0^t f(\\tau)\\, d\\tau  =  (u * f)(t)</math>\n | <math> {1 \\over s} F(s) </math>\n | {{math|''u''(''t'')}} is the Heaviside step function and {{math|(''u''&nbsp;\u2217&nbsp;''f'')(''t'')}} is the [[convolution]] of {{math|''u''(''t'')}} and {{math|''f''(''t'')}}.\n|-\n ! Frequency shifting\n | <math> e^{at} f(t)  \\ </math>\n | <math> F(s - a) \\ </math>\n |\n|-\n ! Time shifting\n | <math> f(t - a) u(t - a) \\ </math>\n | <math> e^{-as} F(s) \\ </math>\n | {{math|''u''(''t'')}} is the Heaviside step function\n|-\n ! Time scaling\n | <math>f(at)</math>\n | <math> \\frac{1}{a} F \\left ( {s \\over a} \\right )</math>\n | <math> a > 0 \\ </math>\n|-\n ! [[Multiplication]]\n | <math>f(t)g(t)</math>\n | <math> \\frac{1}{2\\pi i}\\lim_{T\\to\\infty}\\int_{c - iT}^{c + iT}F(\\sigma)G(s - \\sigma)\\,d\\sigma \\ </math>\n | The integration is done along the vertical line {{nowrap|1=Re(''\u03c3'') = ''c''}} that lies entirely within the region of convergence of {{math|''F''}}.<ref>{{harvnb|Bracewell|2000|loc=Table 14.1, p. 385}}</ref>\n|-\n ! [[Convolution]]\n | <math> (f * g)(t) = \\int_{0}^{t} f(\\tau)g(t - \\tau)\\,d\\tau</math>\n | <math> F(s) \\cdot G(s) \\ </math>\n | \n|-\n ! [[Complex conjugation]]\n | <math> f^*(t) </math>\n | <math> F^*(s^*) </math>\n |\n|-\n ! [[Cross-correlation]]\n | <math> f(t)\\star g(t) </math>\n | <math> F^*(-s^*)\\cdot G(s) </math>\n |\n|-\n ! [[Periodic function]]\n | <math>f(t)</math>\n | <math>{1 \\over 1 - e^{-Ts}} \\int_0^T e^{-st} f(t)\\,dt </math>\n | {{math|''f''(''t'')}} is a periodic function of period {{math|''T''}} so that {{math|1=''f''(''t'') = ''f''(''t'' + ''T'')}}, for all {{math|''t'' \u2265 0}}. This is the result of the time shifting property and the [[geometric series]].\n|}\n\n* '''[[Initial value theorem]]''':\n: <math>f(0^+)=\\lim_{s\\to \\infty}{sF(s)}.</math>\n* '''[[Final value theorem]]''':\n: <math>f(\\infty)=\\lim_{s\\to 0}{sF(s)}</math>, if all [[Pole (complex analysis)|poles]] of ''sF''(''s'') are in the left half-plane.\n: The final value theorem is useful because it gives the long-term behaviour without having to perform [[partial fraction]] decompositions or other difficult algebra. If {{math|''F''(''s'')}} has a pole in the right-hand plane or poles on the imaginary axis (e.g., if <math>f(t) = e^t</math> or <math>f(t) = \\sin(t)</math>), the behaviour of this formula is undefined.\n\n=== Relation to power series ===\nThe Laplace transform can be viewed as a [[continuous function|continuous]] analogue of a [[power series]].<ref>{{cite web |last1=Mattuck |first1=Arthur |title=Where the Laplace Transform comes from |url=https://www.youtube.com/watch?v=zvbdoSeGAgI}}</ref> If  {{math|''a''(''n'')}} is a discrete function of a positive integer {{math|''n''}}, then the power series associated to  {{math|''a''(''n'')}} is the series\n:<math>\\sum_{n=0}^{\\infty} a(n) x^n</math>\nwhere  {{math|''x''}} is a real variable (see [[Z transform]]). Replacing summation over {{math|''n''}} with integration over  {{math|''t''}}, a continuous version of the power series becomes\n:<math>\\int_{0}^{\\infty} f(t) x^t\\, dt</math>\nwhere the discrete function {{math|''a''(''n'')}} is replaced by the continuous one {{math|''f''(''t'')}}. \n\nChanging the base of the power from {{math|''x''}} to {{math|''e''}} gives\n:<math>\\int_{0}^{\\infty} f(t) \\left(e^{\\ln{x}}\\right)^t\\, dt</math>\n\nFor this to converge for, say, all bounded functions {{math|''f''}}, it is necessary to require that {{math|ln ''x'' < 0}}. Making the substitution {{math|1=&minus;''s'' = ln ''x''}} gives just the Laplace transform:\n:<math>\\int_{0}^{\\infty} f(t) e^{-st}\\, dt</math>\n\nIn other words, the Laplace transform is a continuous analog of a power series in which the discrete parameter {{math|''n''}} is replaced by the continuous parameter {{math|''t''}}, and {{math|''x''}} is replaced by {{math|''e''<sup>&minus;''s''</sup>}}.\n\n=== Relation to moments ===\n{{main article|Moment generating function}}\nThe quantities\n:<math>\\mu_n = \\int_0^\\infty t^nf(t)\\, dt</math>\n\nare the ''moments'' of the function {{math|''f''}}.  If the first {{math|''n''}} moments of {{math|''f''}} converge absolutely, then by repeated [[differentiation under the integral]], \n:<math>(-1)^n(\\mathcal L f)^{(n)}(0) = \\mu_n .</math>\nThis is of special significance in probability theory, where the moments of a random variable {{math|''X''}} are given by the expectation values <math>\\mu_n=\\operatorname{E}[X^n]</math>.  Then, the relation holds\n:<math>\\mu_n = (-1)^n\\frac{d^n}{ds^n}\\operatorname{E}\\left[e^{-sX}\\right](0).</math>\n\n=== Computation of the Laplace transform of a function's derivative ===\nIt is often convenient to use the differentiation property of the Laplace transform to find the transform of a function's derivative.  This can be derived from the basic expression for a Laplace transform as follows:\n\n: <math>\\begin{align}\n  \\mathcal{L} \\left\\{f(t)\\right\\} &= \\int_{0^-}^\\infty e^{-st} f(t)\\, dt \\\\[6pt]\n                                  &= \\left[\\frac{f(t)e^{-st}}{-s} \\right]_{0^-}^\\infty -\n                                       \\int_{0^-}^\\infty \\frac{e^{-st}}{-s} f'(t) \\, dt\\quad \\text{(by parts)} \\\\[6pt]\n                                  &= \\left[-\\frac{f(0^+)}{-s}\\right] + \\frac 1 s \\mathcal{L} \\left\\{f'(t)\\right\\},\n\\end{align}</math>\n\nyielding\n\n: <math>\\mathcal{L} \\{ f'(t) \\} = s\\cdot\\mathcal{L} \\{ f(t) \\}-f(0^+), </math>\n\nand in the bilateral case,\n\n: <math> \\mathcal{L} \\{ f'(t) \\} = s \\int_{-\\infty}^\\infty e^{-st} f(t)\\,dt  = s \\cdot \\mathcal{L} \\{ f(t) \\}. </math>\n\nThe general result\n\n: <math>\\mathcal{L} \\left\\{ f^{(n)}(t) \\right\\} = s^n \\cdot \\mathcal{L} \\{ f(t) \\} - s^{n - 1} f(0^+) - \\cdots - f^{(n - 1)}(0^+),</math>\n\nwhere <math>f^{(n)}</math> denotes the {{math|''n''}}<sup>th</sup> derivative of {{math|''f''}}, can then be established with an inductive argument.\n\n=== Evaluating integrals over the positive real axis ===\nA useful property of the Laplace transform is the following:\n\n: <math>\\int_0^\\infty f(x)g(x)\\,dx = \\int_0^\\infty(\\mathcal{L} f)(s)\\cdot(\\mathcal{L}^{-1}g)(s)\\,ds </math>\n\nunder suitable assumptions on the behaviour of <math>f,g</math> in a right neighbourhood of <math>0</math> and on the decay rate of <math>f,g</math> in a left neighbourhood of <math>\\infty</math>. The above formula is a variation of integration by parts, with the operators \n<math>\\frac{d}{dx}</math> and <math>\\int \\,dx</math> being replaced by <math>\\mathcal{L}</math> and <math>\\mathcal{L}^{-1}</math>. Let us prove the equivalent formulation:\n\n: <math>\\int_0^\\infty(\\mathcal{L} f)(x)g(x)\\,dx = \\int_0^\\infty f(s)(\\mathcal{L}g)(s)\\,ds. </math>\n\nBy plugging in <math>(\\mathcal{L}f)(x)=\\int_0^\\infty f(s)e^{-sx}\\,ds</math> the left-hand side turns into:\n\n: <math>\\int_0^\\infty\\int_0^\\infty f(s)g(x) e^{-sx}\\,ds\\,dx, </math>\n\nbut assuming Fubini's theorem holds, by reversing the order of integration we get the wanted right-hand side.\n\n=== Relationship to other transforms ===\n\n==== Laplace\u2013Stieltjes transform ====\nThe (unilateral) Laplace\u2013Stieltjes transform of a function {{math|''g'' : '''R''' \u2192 '''R'''}} is defined by the [[Lebesgue\u2013Stieltjes integral]]\n\n: <math>\\{\\mathcal{L}^*g\\}(s) = \\int_0^\\infty e^{-st} \\, dg(t).</math>\n\nThe function {{math|''g''}} is assumed to be of [[bounded variation]].  If {{math|''g''}} is the [[antiderivative]] of {{math|''f''}}:\n\n: <math>g(x) = \\int_0^x f(t)\\,dt</math>\n\nthen the Laplace\u2013Stieltjes transform of {{math|''g''}} and the Laplace transform of {{math|''f''}} coincide.  In general, the Laplace\u2013Stieltjes transform is the Laplace transform of the [[Stieltjes measure]] associated to {{math|''g''}}.  So in practice, the only distinction between the two transforms is that the Laplace transform is thought of as operating on the density function of the measure, whereas the Laplace\u2013Stieltjes transform is thought of as operating on its [[cumulative distribution function]].<ref>{{harvnb|Feller|1971|p=432}}</ref>\n\n==== Fourier transform ====\n{{Main|Fourier transform}}\nThe continuous Fourier transform is equivalent to evaluating the bilateral Laplace transform with imaginary argument {{math|1=''s'' = ''i\u03c9''}} or {{math|1=''s'' = 2''\u03c0fi''}}<ref>{{harvnb|Takacs|1953|p=93}}</ref> when the condition explained below is fulfilled, \n:<math>\\begin{align}\n  \\widehat{f}(\\omega) &= \\mathcal{F}\\{f(t)\\} \\\\[4pt]\n                  &= \\mathcal{L}\\{f(t)\\}|_{s = i\\omega}  =  F(s)|_{s = i \\omega} \\\\[4pt]\n                  &= \\int_{-\\infty}^\\infty e^{-i \\omega t} f(t)\\,dt~.\n\\end{align}</math>\n\nThis definition of the Fourier transform requires a prefactor of {{math|1/(2''\u03c0'')}} on the reverse Fourier transform. This relationship between the Laplace and Fourier transforms is often used to determine the [[frequency spectrum]] of a [[signal (information theory)|signal]] or dynamical system.\n\nThe above relation is valid as stated if and only if the region of convergence (ROC) of  {{math|''F''(''s'')}} contains the imaginary axis,  {{math|1=''\u03c3'' = 0}}.\n\nFor example, the function {{math|1=''f''(''t'') = cos(''\u03c9''<sub>0</sub>''t'')}} has a Laplace transform  {{math|1=''F''(''s'') =  ''s''/(''s''<sup>2</sup> + ''\u03c9''<sub>0</sub><sup>2</sup>)}} whose ROC is {{math|Re(''s'') > 0}}. As {{math|1=''s'' = ''i\u03c9''}} is a pole of  {{math|''F''(''s'')}}, substituting  {{math|1=''s'' = ''i\u03c9''}} in {{math|''F''(''s'')}} does not yield the Fourier transform of  {{math|''f''(''t'')''u''(''t'')}}, which is proportional to the [[Dirac delta-function]] {{math|''\u03b4''(''\u03c9'' \u2212 ''\u03c9''<sub>0</sub>)}}.\n\nHowever, a relation of the form\n: <math>\\lim_{\\sigma\\to 0^+} F(\\sigma+i\\omega) = \\widehat{f}(\\omega)</math>\nholds under much weaker conditions.  For instance, this holds for the above example provided that the limit is understood as a [[weak limit]] of measures (see [[vague topology]]).  General conditions relating the limit of the Laplace transform of a function on the boundary to the Fourier transform take the form of [[Paley\u2013Wiener theorem]]s.\n\n==== Mellin transform ====\n{{Main|Mellin transform}}\nThe Mellin transform and its inverse are related to the two-sided Laplace transform by a simple change of variables.\n\nIf in the Mellin transform\n: <math>G(s) = \\mathcal{M}\\{g(\\theta)\\} = \\int_0^\\infty \\theta^s g(\\theta) \\, \\frac{d\\theta} \\theta </math>\nwe set {{math|1=''\u03b8'' = ''e''<sup>\u2212''t''</sup>}} we get a two-sided Laplace transform.\n\n==== Z-transform ====\n{{Main|Z-transform}}\nThe unilateral or one-sided Z-transform is simply the Laplace transform of an ideally sampled signal with the substitution of\n: <math> z \\stackrel{\\mathrm{def}}{{}={}} e^{sT} ,</math>\nwhere {{math|1=''T'' = 1/''f<sub>s</sub>''}} is the [[Sampling theorem|sampling]] period (in units of time e.g., seconds) and  {{math|''f<sub>s</sub>''}} is the [[sampling rate]] (in [[sample (signal)|samples per second]] or [[hertz]]).\n\nLet\n: <math> \\Delta_T(t) \\ \\stackrel{\\mathrm{def}}{=}\\  \\sum_{n=0}^{\\infty}  \\delta(t - n T) </math>\nbe a sampling impulse train (also called a [[Dirac comb]]) and\n:<math>\\begin{align}\n  x_q(t) \\  &\\stackrel{\\mathrm{def}}{=}\\  x(t) \\Delta_T(t) = x(t) \\sum_{n=0}^{\\infty}  \\delta(t - n T) \\\\\n            &= \\sum_{n=0}^{\\infty} x(n T) \\delta(t - n T) = \\sum_{n=0}^{\\infty} x[n] \\delta(t - n T)\n\\end{align}</math>\nbe the sampled representation of the continuous-time {{math|''x''(''t'')}}\n: <math> x[n] \\stackrel{\\mathrm{def}}{{}={}}  x(nT) ~.</math>\n\nThe Laplace transform of the sampled signal {{math|''x''<sub>''q''</sub>(''t'') }} is\n: <math>\\begin{align}\n  X_q(s) &= \\int_{0^-}^\\infty x_q(t) e^{-s t} \\,dt \\\\\n         &= \\int_{0^-}^\\infty \\sum_{n=0}^\\infty x[n] \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &= \\sum_{n=0}^\\infty x[n] \\int_{0^-}^\\infty \\delta(t - n T) e^{-s t} \\, dt \\\\\n         &= \\sum_{n=0}^\\infty x[n] e^{-n s T}~.\n\\end{align}</math>\n\nThis is the precise definition of the unilateral Z-transform of the discrete function {{math|''x''[''n'']}}\n\n: <math> X(z) = \\sum_{n=0}^{\\infty} x[n] z^{-n} </math>\nwith the substitution of {{math|''z'' \u2192 e<sup>''sT''</sup>}}.\n\nComparing the last two equations, we find the relationship between the unilateral Z-transform and the Laplace transform of the sampled signal,\n: <math>X_q(s) =  X(z) \\Big|_{z=e^{sT}}.</math>\n\nThe similarity between the {{math|''Z''}} and Laplace transforms is expanded upon in the theory of [[time scale calculus]].\n\n==== Borel transform ====\nThe integral form of the [[Borel summation|Borel transform]]\n\n: <math>F(s) = \\int_0^\\infty f(z)e^{-sz}\\, dz</math>\n\nis a special case of the Laplace transform for {{math|''f''}} an [[entire function]] of exponential type, meaning that\n\n: <math>|f(z)|\\le Ae^{B|z|}</math>\n\nfor some constants {{math|''A''}} and {{math|''B''}}.  The generalized Borel transform allows a different weighting function to be used, rather than the exponential function, to transform functions not of exponential type. [[Nachbin's theorem]] gives necessary and sufficient conditions for the Borel transform to be well defined.\n\n==== Fundamental relationships ====\nSince an ordinary Laplace transform can be written as a special case of a two-sided transform, and since the two-sided transform can be written as the sum of two one-sided transforms, the theory of the Laplace-, Fourier-, Mellin-, and Z-transforms are at bottom the same subject. However, a different point of view and different characteristic problems are associated with each of these four major integral transforms.\n\n== Table of selected Laplace transforms ==\n{{main article|List of Laplace transforms}}\n\nThe following table provides Laplace transforms for many common functions of a single variable.<ref>{{Citation |edition=3rd |page=455 |first1=K. F. |last1=Riley |first2=M. P. |last2=Hobson |first3=S. J. |last3=Bence |title=Mathematical methods for physics and engineering |publisher=Cambridge University Press |year=2010 |isbn=978-0-521-86153-3}}</ref><ref>{{Citation |first1=J. J. |last1=Distefano |first2=A. R. |last2=Stubberud |first3=I. J. |last3=Williams |page=78 |title=Feedback systems and control |edition=2nd |publisher=McGraw-Hill |series=Schaum's outlines |year=1995 |isbn=978-0-07-017052-0}}</ref> For definitions and explanations, see the ''Explanatory Notes'' at the end of the table.\n\nBecause the Laplace transform is a linear operator,\n\n* The Laplace transform of a sum is the sum of Laplace transforms of each term.\n\n:: <math>\\mathcal{L}\\{f(t) + g(t)\\}  = \\mathcal{L}\\{f(t)\\} + \\mathcal{L}\\{ g(t)\\}  </math>\n\n* The Laplace transform of a multiple of a function is that multiple times the Laplace transformation of that function.\n\n:: <math>\\mathcal{L}\\{a f(t)\\}  = a \\mathcal{L}\\{ f(t)\\}</math>\n\nUsing this linearity, and various [[List of trigonometric identities|trigonometric]], [[Hyperbolic function|hyperbolic]], and complex number (etc.) properties and/or identities, some Laplace transforms can be obtained from others more quickly than by using the definition directly.\n\nThe unilateral Laplace transform takes as input a function whose time domain is the [[non-negative]] reals, which is why all of the time domain functions in the table below are multiples of the Heaviside step function, {{math|''u''(''t'')}}.\n\nThe entries of the table that involve a time delay {{math|''\u03c4''}} are required to be [[causal system|causal]] (meaning that {{math|''\u03c4'' > 0}}).  A causal system is a system where the [[impulse response]] {{math|''h''(''t'')}} is zero for all time {{mvar|t}} prior to {{math|1=''t'' = 0}}. In general, the region of convergence for causal systems is not the same as that of [[anticausal system]]s.\n\n{| class=\"wikitable\"\n|-\n! Function\n! Time domain <br> <math>f(t) = \\mathcal{L}^{-1}\\{F(s)\\}</math> \n! Laplace {{math|s}}-domain <br> <math>F(s) = \\mathcal{L}\\{f(t)\\}</math> \n! Region of convergence \n! Reference\n\n|- style=\"text-align:center;\"\n| unit impulse\n|| <math> \\delta(t) \\ </math> \n|| <math> 1  </math> \n|| all {{math|''s''}}\n|| inspection\n\n|- style=\"text-align:center;\"\n| delayed impulse \n|| <math> \\delta(t - \\tau) \\ </math> \n|| <math> e^{-\\tau s} \\ </math> \n|| \n|| time shift of<br>unit impulse\n\n|- style=\"text-align:center;\"\n| unit step\n|| <math> u(t) \\ </math> \n|| <math> { 1 \\over s } </math> \n|| {{math|Re(''s'') > 0}}\n|| integrate unit impulse\n\n|- style=\"text-align:center;\"\n| delayed unit step \n|| <math> u(t - \\tau) \\ </math> \n|| <math> \\frac 1 s e^{-\\tau s} </math> \n|| {{math|Re(''s'') > 0}} \n|| time shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| [[ramp function|ramp]] \n|| <math> t \\cdot u(t)\\ </math> \n|| <math>\\frac 1 {s^2}</math> \n|| {{math|Re(''s'') > 0}}\n|| integrate unit<br>impulse twice\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th power <br /> (for integer {{math|''n''}}) \n|| <math> t^n \\cdot u(t) </math> \n|| <math> { n! \\over s^{n + 1} } </math> \n|| {{math|Re(''s'') > 0}}   <br /> ({{math|''n'' > \u22121}})\n|| Integrate unit<br>step {{math|''n''}} times\n\n|- style=\"text-align:center;\"\n| {{math|''q''}}th power <br /> (for complex {{math|''q''}}) \n|| <math> t^q \\cdot u(t) </math> \n|| <math> { \\Gamma(q + 1) \\over s^{q + 1} } </math> \n|| {{math|Re(''s'') > 0}} <br /> {{math|Re(''q'') > \u22121}} \n||<ref>{{citation |title=Mathematical Handbook of Formulas and Tables |edition=3rd |first1=S. |last1=Lipschutz |first2=M. R. |last2=Spiegel |first3=J. |last3=Liu |series=Schaum's Outline Series |publisher=McGraw-Hill |page=183 |year=2009 |isbn=978-0-07-154855-7}} \u2013 provides the case for real {{math|''q''}}.</ref><ref>http://mathworld.wolfram.com/LaplaceTransform.html \u2013 Wolfram Mathword provides case for complex {{math|''q''}}</ref>\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th root \n|| <math> \\sqrt[n]{t} \\cdot u(t) </math> \n|| <math> { 1 \\over s^{\\frac 1 n + 1} } \\Gamma\\left(\\frac 1 n + 1\\right) </math> \n|| {{math|Re(''s'') > 0}} \n|| Set {{math|1=''q'' = 1/''n''}} above.\n\n|- style=\"text-align:center;\"\n| {{math|''n''}}th power with frequency shift \n|| <math>t^{n} e^{-\\alpha t} \\cdot u(t) </math> \n|| <math>\\frac{n!}{(s+\\alpha)^{n+1}}</math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| Integrate unit step,<br>apply frequency shift\n\n|- style=\"text-align:center;\"\n| delayed {{math|''n''}}th power <br /> with frequency shift \n|| <math>(t-\\tau)^n e^{-\\alpha (t-\\tau)} \\cdot u(t-\\tau) </math> \n|| <math> \\frac{n! \\cdot e^{-\\tau s}}{(s+\\alpha)^{n+1}} </math>\n|| {{math|Re(''s'') > \u2212''\u03b1''}} \n|| Integrate unit step,<br>apply frequency shift,<br>apply time shift\n\n|- style=\"text-align:center;\"\n| [[exponential decay]] \n|| <math> e^{-\\alpha t} \\cdot u(t)   </math> \n|| <math> { 1 \\over s+\\alpha } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| Frequency shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| [[Two-sided Laplace transform|two-sided]] exponential decay <br>(only for bilateral transform)\n|| <math> e^{-\\alpha|t|}  \\ </math> \n|| <math> { 2\\alpha \\over \\alpha^2 - s^2 } </math> \n|| {{math|\u2212''\u03b1'' < Re(''s'') < ''\u03b1''}} \n|| Frequency shift of<br>unit step\n\n|- style=\"text-align:center;\"\n| exponential approach \n|| <math>( 1-e^{-\\alpha t})  \\cdot u(t)  \\ </math> \n|| <math>\\frac{\\alpha}{s(s+\\alpha)} </math> \n|| {{math|Re(''s'') > 0}}\n|| Unit step minus<br>exponential decay\n\n|- style=\"text-align:center;\"\n| [[sine]] \n|| <math> \\sin(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { \\omega \\over s^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[cosine]] \n|| <math> \\cos(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { s \\over s^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[hyperbolic sine]] \n|| <math> \\sinh(\\alpha t) \\cdot u(t) \\ </math> \n|| <math> { \\alpha \\over s^2 - \\alpha^2 } </math> \n|| {{math|Re(''s'') > {{abs|''\u03b1''}}}} \n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| [[hyperbolic cosine]] \n|| <math> \\cosh(\\alpha t) \\cdot u(t) \\ </math> \n|| <math> { s \\over s^2 - \\alpha^2  } </math> \n|| {{math|Re(''s'') > {{abs|''\u03b1''}}}}\n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| exponentially decaying <br /> sine wave \n|| <math>e^{-\\alpha t}  \\sin(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { \\omega \\over (s+\\alpha )^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}} \n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| exponentially decaying <br /> cosine wave \n|| <math>e^{-\\alpha t}  \\cos(\\omega t) \\cdot u(t) \\ </math> \n|| <math> { s+\\alpha \\over (s+\\alpha )^2 + \\omega^2  } </math> \n|| {{math|Re(''s'') > \u2212''\u03b1''}}\n|| {{Harvnb|Bracewell|1978|p=227}}\n\n|- style=\"text-align:center;\"\n| [[natural logarithm]] \n|| <math> \\ln (t) \\cdot u(t) </math> \n|| <math> - { 1 \\over s}\\, \\left[ \\ln(s)+\\gamma \\right] </math> \n|| {{math|Re(''s'') > 0}} \n|| {{Harvnb|Williams|1973|p=88}}\n\n|- style=\"text-align:center;\"\n| [[Bessel function]] <br> of the first kind, <br /> of order ''n'' \n|| <math> J_n( \\omega t) \\cdot u(t)</math> \n|| <math>\\frac{ \\left(\\sqrt{s^2+ \\omega^2}-s\\right)^n}{\\omega^n \\sqrt{s^2 + \\omega^2}}</math> \n|| {{math|Re(''s'') > 0}}   <br /> ({{math|''n'' > \u22121}}) \n|| {{Harvnb|Williams|1973|p=89}}\n\n|- style=\"text-align:center;\"\n| [[Error function]] \n|| <math> \\operatorname{erf}(t) \\cdot u(t) </math> \n|| <math> \\frac 1 s e^{(1/4)s^2} \\left(1 - \\operatorname{erf} \\frac s 2 \\right)</math> \n|| {{math|Re(''s'') > 0}}\n|| {{Harvnb|Williams|1973|p=89}}\n\n|-\n| colspan=5|'''Explanatory notes:'''\n{{col-begin}}\n{{col-break}}\n\n* {{math|''u''(''t'')}} represents the [[Heaviside step function]].\n* {{math|''\u03b4''}}  represents the [[Dirac delta function]].\n* {{math|\u0393(''z'')}} represents the [[gamma function]].\n* {{math|''\u03b3''}} is the [[Euler&ndash;Mascheroni constant]].\n\n{{col-break}}\n\n*  {{math|''t''}}, a real number, typically represents ''time'', <br />although it can represent ''any'' independent dimension.\n*  {{math|''s''}} is the [[complex number|complex]] frequency domain parameter, and  {{math|Re(''s'')}} is its [[real part]].\n*  {{math|''\u03b1'', ''\u03b2'', ''\u03c4,'' and ''\u03c9''}} are [[real numbers]].\n*  {{math|''n''}} is an [[integer]].\n\n{{col-end}}\n|}\n\n== ''s''-domain equivalent circuits and impedances ==\nThe Laplace transform is often used in circuit analysis, and simple conversions to the {{math|''s''}}-domain of circuit elements can be made. Circuit elements can be transformed into [[Electrical impedance|impedance]]s, very similar to [[Phasor (sine waves)|phasor]] impedances.\n\nHere is a summary of equivalents:\n\n: [[File:S-Domain circuit equivalents.svg|alt={{math|''s''}}-domain equivalent circuits|centre|frameless|400x400px|{{math|''s''}}-domain equivalent circuits]]\n\nNote that the resistor is exactly the same in the time domain and the {{math|''s''}}-domain. The sources are put in if there are initial conditions on the circuit elements. For example, if a capacitor has an initial voltage across it, or if the inductor has an initial current through it, the sources inserted in the {{math|''s''}}-domain account for that.\n\nThe equivalents for current and voltage sources are simply derived from the transformations in the table above.\n\n== Examples and applications ==\n<!--A few worked examples are provided here to enable the reader to assess comprehension of the factual presentation.  Elaboration beyond the role of supporting factual comprehension belongs at [[v:|Wikiversity]] or [[b:|Wikibooks]].-->\n\nThe Laplace transform is used frequently in [[engineering]] and [[physics]]; the output of a [[linear time-invariant]] system can be calculated by convolving its unit impulse response with the input signal. Performing this calculation in Laplace space turns the convolution into a multiplication; the latter being easier to solve because of its algebraic form. For more information, see [[control theory]].\n\nThe Laplace transform can also be used to solve differential equations and is used extensively in [[mechanical engineering]] and [[electrical engineering]].  The Laplace transform reduces a linear differential equation to an algebraic equation, which can then be solved by the formal rules of algebra.  The original differential equation can then be solved by applying the inverse Laplace transform.  The English electrical engineer Oliver Heaviside first proposed a similar scheme, although without using the Laplace transform; and the resulting operational calculus is credited as the Heaviside calculus.\n\n=== Evaluating improper integrals ===\nLet <math>\\mathcal{L}\\left\\{f(t)\\right\\} = F(s)</math>. Then (see the table above)\n\n:<math>\\mathcal{L} \\left\\{\\frac{f(t)} t \\right\\} = \\int_0^\\infty \\frac{f(t)}{t}e^{-st}\\, dt = \\int_s^\\infty F(p)\\, dp.</math>\n\nIn the limit <math>s \\rightarrow 0</math>, one gets\n\n:<math>\\int_0^\\infty \\frac{f(t)} t \\, dt = \\int_0^\\infty F(p)\\, dp,</math>\n\nprovided that the interchange of limits can be justified. Even when the interchange cannot be justified the calculation can be suggestive. For example, with ''a''&nbsp;\u2260&nbsp;0&nbsp;\u2260&nbsp;''b'', proceeding formally one has\n\n:<math>\n\\begin{align}\n\\lim_{p \\rightarrow 0} \\int_0^\\infty \\frac{ \\cos(at) - \\cos(bt) }{t} \\, dt \n&= \\lim_{p \\rightarrow 0} \\int_0^\\infty \\left(\\frac p {p^2 + a^2} - \\frac{p}{p^2 + b^2}\\right)\\, dp \\\\[6pt]\n&= \\lim_{p \\rightarrow 0} \\Biggl[ \\frac 1 2 \\left. \\ln\\frac{p^2 + a^2}{p^2 + b^2} \\right|_{0}^\\infty \\Biggl] = \\frac{1}{2} \\ln \\frac{a^2}{b^2} = \\ln \\Biggl| \\frac {a}{b} \\Biggl|.\n\\end{align}\n</math>\n\nThe validity of this identity can be proved by other means. It is an example of a [[Frullani integral]].\n\nAnother example is [[Dirichlet integral]].\n\n=== Complex impedance of a capacitor ===\nIn the theory of [[electrical circuit]]s, the current flow in a [[capacitor]] is proportional to the capacitance and rate of change in the electrical potential (in [[International System of Units|SI]] units). Symbolically, this is expressed by the differential equation\n\n: <math>i = C { dv \\over dt} ,</math>\n\nwhere {{math|''C''}} is the capacitance (in [[farad]]s) of the capacitor, {{math|1=''i'' = ''i''(''t'')}} is the [[electric current]] (in [[ampere]]s) through the capacitor as a function of time, and {{math|1=''v'' = ''v''(''t'')}} is the [[electrostatic potential|voltage]] (in [[volt]]s) across the terminals of the capacitor, also as a function of time.\n\nTaking the Laplace transform of this equation, we obtain\n\n: <math>I(s) = C(s V(s) - V_0),</math>\n\nwhere\n\n: <math>\\begin{align}\n  I(s) &= \\mathcal{L} \\{ i(t) \\},\\\\\n  V(s) &= \\mathcal{L} \\{ v(t) \\},\n\\end{align}</math>\n\nand\n\n: <math>V_0 = v(t)\\Big|_{t=0}. \\, </math>\n\nSolving for {{math|''V''(''s'')}} we have\n\n: <math>V(s) = { I(s) \\over sC } + { V_0 \\over s }.</math>\n\nThe definition of the complex impedance {{math|''Z''}} (in [[ohm]]s) is the ratio of the complex voltage {{math|''V''}} divided by the complex current {{math|''I''}} while holding the initial state {{math|''V''<sub>0</sub>}} at zero:\n\n: <math>Z(s) = \\left. { V(s) \\over I(s) } \\right|_{V_0 = 0}.</math>\n\nUsing this definition and the previous equation, we find:\n\n: <math>Z(s) = \\frac{1}{sC}, </math>\n\nwhich is the correct expression for the complex impedance of a capacitor. \nIn addition, the Laplace transform has large applications in control theory.\n\n=== Partial fraction expansion ===\n<!-- [[Partial fractions in Laplace transforms]] redirect here -->\nConsider a linear time-invariant system with [[transfer function]]\n: <math>H(s) = \\frac{1}{(s + \\alpha)(s + \\beta)}.</math>\n\nThe [[impulse response]] is simply the inverse Laplace transform of this transfer function:\n: <math>h(t) = \\mathcal{L}^{-1}\\{H(s)\\}.</math>\n\nTo evaluate this inverse transform, we begin by expanding {{math|''H''(''s'')}} using the method of partial fraction expansion,\n\n: <math>\\frac{1}{(s + \\alpha)(s + \\beta)} = { P \\over s + \\alpha } + { R \\over s+\\beta }.</math>\n\nThe unknown constants {{math|''P''}} and {{math|''R''}} are the [[residue (complex analysis)|residue]]s located at the corresponding poles of the transfer function. Each residue represents the relative contribution of that [[mathematical singularity|singularity]] to the transfer function's overall shape.\n\nBy the [[residue theorem]], the inverse Laplace transform depends only upon the poles and their residues. To find the residue {{math|''P''}}, we multiply both sides of the equation by {{math|''s'' + ''\u03b1''}} to get\n: <math>\\frac{1}{s + \\beta} = P  + { R (s + \\alpha) \\over s + \\beta }.</math>\n\nThen by letting {{math|1=''s'' = \u2212''\u03b1''}}, the contribution from {{math|''R''}} vanishes and all that is left is\n: <math>P = \\left.{1 \\over s+\\beta}\\right|_{s=-\\alpha} = {1 \\over \\beta - \\alpha}.</math>\n\nSimilarly, the residue {{math|''R''}} is given by\n: <math>R = \\left.{1 \\over s + \\alpha}\\right|_{s=-\\beta} = {1 \\over \\alpha - \\beta}.</math>\n\nNote that\n: <math>R = {-1 \\over \\beta - \\alpha} = - P</math>\nand so the substitution of {{math|''R''}} and {{math|''P''}} into the expanded expression for {{math|''H''(''s'')}} gives\n: <math>H(s)  = \\left( \\frac{1}{\\beta - \\alpha} \\right) \\cdot \\left(  { 1 \\over s + \\alpha } - { 1  \\over s + \\beta }  \\right).</math>\n\nFinally, using the linearity property and the known transform for exponential decay (see ''Item'' #''3'' in the ''Table of Laplace Transforms'', above), we can take the inverse Laplace transform of {{math|''H''(''s'')}} to obtain\n: <math>h(t) = \\mathcal{L}^{-1}\\{H(s)\\} = \\frac{1}{\\beta - \\alpha}\\left(e^{-\\alpha t} - e^{-\\beta t}\\right),</math>\nwhich is the impulse response of the system.\n\n;Convolution\nThe same result can be achieved using the [[Convolution theorem|convolution property]] as if the system is a series of filters with transfer functions of {{math|1/(''s'' + ''a'')}} and {{math|1/(''s'' + ''b'')}}. That is, the inverse of\n\n: <math>H(s) = \\frac{1}{(s + a)(s + b)} = \\frac{1}{s+a} \\cdot \\frac{1}{s + b}</math>\n\nis\n\n: <math> \\mathcal{L}^{-1}\\! \\left\\{ \\frac{1}{s + a} \\right\\} * \\mathcal{L}^{-1}\\! \\left\\{\\frac{1}{s + b} \\right\\} = e^{-at} * e^{-bt} = \\int_0^t e^{-ax}e^{-b(t - x)}\\, dx = \\frac{e^{-a t}-e^{-b t}}{b - a}.</math>\n\n=== Phase delay ===\n{| class=\"wikitable\"\n|-\n! Time function\n! Laplace transform\n|-\n| <math>\\sin{(\\omega t + \\varphi)}</math>\n| <math>\\frac{s\\sin(\\varphi) + \\omega \\cos(\\varphi)}{s^2 + \\omega^2}</math>\n|-\n| <math>\\cos{(\\omega t + \\varphi)}</math>\n| <math>\\frac{s\\cos(\\varphi) - \\omega \\sin(\\varphi)}{s^2 + \\omega^2}.</math>\n|}\n\nStarting with the Laplace transform,\n\n: <math>X(s) = \\frac{s\\sin(\\varphi) + \\omega \\cos(\\varphi)}{s^2 + \\omega^2}</math>\n\nwe find the inverse by first rearranging terms in the fraction:\n\n: <math>\\begin{align}\n  X(s) &= \\frac{s \\sin(\\varphi)}{s^2 + \\omega^2} + \\frac{\\omega \\cos(\\varphi)}{s^2 + \\omega^2} \\\\\n       &= \\sin(\\varphi) \\left(\\frac{s}{s^2 + \\omega^2} \\right) + \\cos(\\varphi) \\left(\\frac{\\omega}{s^2 + \\omega^2} \\right).\n\\end{align}</math>\n\nWe are now able to take the inverse Laplace transform of our terms:\n\n: <math>\\begin{align}\n  x(t) &= \\sin(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{s}{s^2 + \\omega^2} \\right\\} + \\cos(\\varphi) \\mathcal{L}^{-1}\\left\\{\\frac{\\omega}{s^2 + \\omega^2} \\right\\} \\\\\n       &= \\sin(\\varphi)\\cos(\\omega t) + \\sin(\\omega t)\\cos(\\varphi).\n\\end{align}</math>\n\nThis is just the [[Trigonometric identity#Angle sum and difference identities|sine of the sum]] of the arguments, yielding:\n\n:<math>x(t) = \\sin (\\omega t + \\varphi).</math>\n\nWe can apply similar logic to find that\n\n: <math>\\mathcal{L}^{-1} \\left\\{ \\frac{s\\cos\\varphi - \\omega \\sin\\varphi}{s^2 + \\omega^2} \\right\\} = \\cos{(\\omega t + \\varphi)}.</math>\n\n=== {{Anchor|Inferring spatial structure from spectrum}}Determining structure of astronomical object from spectrum ===\nThe wide and general applicability of the Laplace transform and its inverse is illustrated by an application in astronomy which provides some information on the ''spatial distribution'' of matter of an [[Astronomy|astronomical]] source of [[Radio frequency|radio-frequency]] [[thermal radiation]] too distant to [[Angular resolution|resolve]] as more than a point, given its [[flux density]] [[spectrum]], rather than relating the ''time'' domain with the spectrum (frequency domain).\n\nAssuming certain properties of the object, e.g. spherical shape and constant temperature, calculations based on carrying out an inverse Laplace transformation on the spectrum of the object can produce the only possible [[Mathematical model|model]] of the distribution of matter in it (density as a function of distance from the center) consistent with the spectrum.<ref>{{citation |first1=M. |last1=Salem |first2=M. J. |last2=Seaton |year=1974 |title=I. Continuum spectra and brightness contours |journal=[[Monthly Notices of the Royal Astronomical Society]] |volume=167 |issue=3 |pages=493\u2013510 |doi=10.1093/mnras/167.3.493 |bibcode=1974MNRAS.167..493S}}, and<br/>{{citation |first1=M. |last1=Salem |year=1974 |title=II. Three-dimensional models |journal=Monthly Notices of the Royal Astronomical Society |volume=167 |issue=3 |pages=511\u2013516 |doi=10.1093/mnras/167.3.511 |bibcode=1974MNRAS.167..511S}}</ref> When independent information on the structure of an object is available, the inverse Laplace transform method has been found to be in good agreement.\n\n=== Statistical mechanics ===\nIn [[statistical mechanics]], the Laplace transform of the density of states <math>g(E)dE</math> defines the [[partition function (statistical mechanics)|partition function]].<ref>{{cite book|author1=RK Pathria|author2=Paul Beal|title=Statistical mechanics|edition=2nd|publisher=Butterworth-Heinemann|year=1996|page=56}}</ref> That is, the partition function <math>Z(\\beta)</math> is given by\n:<math> Z(\\beta) = \\int_0^\\infty e^{-\\beta E}g(E)dE</math>\nand the inverse is given by\n:<math> g(E) = \\frac{1}{2\\pi i} \\int_{\\beta_0-i\\infty}^{\\beta_0+i\\infty} e^{\\beta E}Z(\\beta) d\\beta</math>\n\n==Gallery==\n{{Gallery|width=265 | height=150 |lines=2 |align=right|File:Graph of e^t cos(10t).png|An example curve of e^t cos(10t) that is added together with similar curves to form a Laplace Transform.|File:Laplace animation of Cubic Polynomial.gif|Animation showing how adding together curves can approximate a function.}}\n\n== See also ==\n{{Portal|Mathematics}}\n{{div col}}\n* [[Analog signal processing]]\n* [[Bernstein's theorem on monotone functions]]\n* [[Continuous-repayment mortgage#Mortgage difference and differential equation|Continuous-repayment mortgage]]\n* [[Hamburger moment problem]]\n* [[Hardy\u2013Littlewood tauberian theorem]]\n* [[Laplace\u2013Carson transform]]\n* [[Moment-generating function]]\n* [[Nonlocal operator]]\n* [[Post's inversion formula]]\n* [[Signal-flow graph]]\n{{div col end}}\n\n== Notes ==\n{{Reflist|30em}}\n\n== References ==\n\n=== Modern ===\n* {{Citation |last=Bracewell |first=Ronald N. |title=The Fourier Transform and its Applications |edition=2nd |year=1978 |publisher=McGraw-Hill Kogakusha |isbn=978-0-07-007013-4 }}<!-- This edition is used for pinpoint citations in the transform table. -->\n* {{citation|first=R. N.|last=Bracewell|title=The Fourier Transform and Its Applications|edition=3rd|location=Boston|publisher=McGraw-Hill|year=2000|isbn=978-0-07-116043-8}}\n* {{Citation | last1=Feller | first1=William | author1-link=William Feller | title=An introduction to probability theory and its applications. Vol. II. | publisher=[[John Wiley & Sons]] | location=New York | series=Second edition | mr=0270403  | year=1971}}\n* {{citation |first1=G. A. |last1=Korn |first2=T. M. |last2=Korn |title=Mathematical Handbook for Scientists and Engineers |publisher=McGraw-Hill Companies |edition=2nd |year=1967 |isbn=978-0-07-035370-1 }}\n* {{Citation | last1=Widder | first1=David Vernon | title=The Laplace Transform | publisher=[[Princeton University Press]] | series=Princeton Mathematical Series, v. 6 | mr=0005923  | year=1941}}\n* {{Citation | last=Williams |first=J. |title=Laplace Transforms |series=Problem Solvers |volume= |publisher=George Allen & Unwin |year=1973 |isbn= 978-0-04-512021-5 }}\n* {{Citation | last=Takacs | first= J.|title=Fourier amplitudok meghatarozasa operatorszamitassal | year=1953 | journal=Magyar Hiradastechnika | volume=IV | issue=7\u20138|pages=93\u201396 |language=Hungarian }}\n\n=== Historical ===\n<!-- Citations to Opera omnia [The Complete Works] are wrong. Opera omnia was published 1911 and after, so the citations should be |origyear=17xx |year=1992... Handling of Euler's volume number and Opera omnia volume is problematic -->\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |year=1744 |title=De constructione aequationum |trans-title=The Construction of Equations |language=la |journal=Opera Omnia |series=1st series |volume=22 |pages=150\u2013161}}\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |year=1753 |title=Methodus aequationes differentiales |trans-title=A Method for Solving Differential Equations |language=la |journal=Opera Omnia |series=1st series |volume=22 |pages=181\u2013213}}\n* {{citation |last=Euler |first=L. |authorlink=Leonhard Euler |origyear=1769 |title=Institutiones calculi integralis, Volume 2 |trans-title=Institutions of Integral Calculus |language=la |journal=Opera Omnia |series=1st series |volume=12 |year=1992 |location=Basel |publisher=Birkh\u00e4user |isbn=978-3764314743 <!-- isbn for the entire first series-->}}, Chapters 3\u20135\n* {{citation |last=Euler |first=Leonhard |authorlink=Leonhard Euler |year=1769 |title=Institutiones calculi integralis |trans-title=Institutions of Integral Calculus |language=la |volume=II <!--Secundum--> |at=ch. 3\u20135, pp. 57\u2013153 |location=Paris |publisher=Petropoli |url=https://books.google.com/books?id=BFqWNwpfqo8C }}\n* {{citation|last=Grattan-Guinness|first=I|authorlink=Ivor Grattan-Guinness|year=1997|contribution=Laplace's integral solutions to partial differential equations|editor=Gillispie, C. C.|title=Pierre Simon Laplace 1749\u20131827: A Life in Exact Science|location=Princeton|publisher=Princeton University Press|isbn=978-0-691-01185-1}}\n* {{citation|last=Lagrange|first=J. L.|authorlink=Joseph Louis Lagrange|year=1773|title=M\u00e9moire sur l'utilit\u00e9 de la m\u00e9thode|series=\u0152uvres de Lagrange|volume=2|pages=171\u2013234}}\n\n==Further reading==\n* {{citation|first1=Wolfgang|last1=Arendt|first2=Charles J.K.|last2=Batty|first3=Matthias|last3=Hieber|first4=Frank|last4=Neubrander|title=Vector-Valued Laplace Transforms and Cauchy Problems|publisher=Birkh\u00e4user Basel|year=2002|isbn=978-3-7643-6549-3 |ref=none}}.\n* {{citation|last=Davies|first=Brian|title=Integral transforms and their applications|edition=Third|publisher=Springer|location=New York|year=2002|isbn= 978-0-387-95314-4 |ref=none}}\n* {{citation | last=Deakin|first= M. A. B. | year=1981 | title=The development of the Laplace transform | journal=Archive for History of Exact Sciences | volume=25 | pages=343\u2013390 | doi=10.1007/BF01395660 | issue=4 |ref=none}}\n* {{citation | last=Deakin|first= M. A. B. | year=1982 | title=The development of the Laplace transform | journal=Archive for History of Exact Sciences | volume=26 | pages=351\u2013381 | doi=10.1007/BF00418754 | issue=4 |ref=none}}\n* {{citation |last=Doetsch |first=Gustav |authorlink=Gustav Doetsch |date=1974 |title=Introduction to the Theory and Application of the Laplace Transformation |publisher=Springer |isbn=978-0-387-06407-9 |ref=none}}\n* Mathews, Jon; Walker, Robert L. (1970), ''Mathematical methods of physics'' (2nd ed.), New York: W. A. Benjamin, {{isbn|0-8053-7002-1}}\n* {{citation|first1=A. D.|last1=Polyanin|first2=A. V.|last2=Manzhirov|title=Handbook of Integral Equations|publisher=CRC Press|location=Boca Raton|year=1998|isbn=978-0-8493-2876-3 |ref=none}}\n* {{Citation | last1=Schwartz | first1=Laurent | author-link=Laurent Schwartz | title=Transformation de Laplace des distributions | mr=0052555  | year=1952 | journal=Comm. S\u00e9m. Math. Univ. Lund [Medd. Lunds Univ. Mat. Sem.] | volume=1952 | pages=196\u2013206 |language=French |ref=none}}\n* {{Citation |last=Schwartz |first=Laurent |author-link=Laurent Schwartz |year=2008 |origyear=1966 |title=Mathematics for the Physical Sciences |publisher=Dover Publications |location=New York |series=Dover Books on Mathematics |pages=215\u2013241 |isbn=978-0-486-46662-0 |url={{Google books|-_AuDQAAQBAJ|Mathematics for the Physical Sciences|page=215|plainurl=yes}} |ref=none}} - See Chapter VI. The Laplace transform.\n* {{citation|first=William McC.|last=Siebert|title=Circuits, Signals, and Systems|publisher=MIT Press|location=Cambridge, Massachusetts|year=1986|isbn=978-0-262-19229-3 |ref=none}}\n* {{Citation | last1=Widder | first1=David Vernon | title=What is the Laplace transform? | mr=0013447  | year=1945 | journal=[[American Mathematical Monthly|The American Mathematical Monthly]] | issn=0002-9890 |volume=52 |issue=8 | pages=419\u2013425 | doi=10.2307/2305640 | jstor=2305640 |ref=none}}\n\n== External links ==\n{{wikiquote}}\n{{commons category|Laplace transformation}}\n* {{springer|title=Laplace transform|id=p/l057540}}\n* [http://wims.unice.fr/wims/wims.cgi?lang=en&+module=tool%2Fanalysis%2Ffourierlaplace Online Computation] of the transform or inverse transform, wims.unice.fr\n* [http://eqworld.ipmnet.ru/en/auxiliary/aux-inttrans.htm Tables of Integral Transforms] at EqWorld: The World of Mathematical Equations.\n* {{MathWorld|title=Laplace Transform|urlname=LaplaceTransform}}\n* [http://fourier.eng.hmc.edu/e102/lectures/Laplace_Transform/ Good explanations of the initial and final value theorems]\n* [http://www.mathpages.com/home/kmath508/kmath508.htm Laplace Transforms] at MathPages\n* [http://www.wolframalpha.com/input/?i=laplace+transform+example Computational Knowledge Engine] allows to easily calculate Laplace Transforms and its inverse Transform.\n* [http://www.laplacetransformcalculator.com/easy-laplace-transform-calculator/ Laplace Calculator] to calculate Laplace Transforms online easily.\n* [https://johnflux.com/2019/02/12/laplace-transform-visualized/ Code to visualize Laplace Transforms] and many example videos.\n\n{{Authority control}}\n\n{{DEFAULTSORT:Laplace Transform}}\n[[Category:Laplace transforms| ]]\n[[Category:Differential equations]]\n[[Category:Fourier analysis]]\n[[Category:Mathematical physics]]\n", "name_user": "Nerd271", "label": "safe", "comment": "\u2192\u200eGallery", "url_page": "//en.wikipedia.org/wiki/Laplace_transform"}
